Directory structure:
└── muratkeremozcan-pact-js-example-provider/
    ├── README.md
    ├── jest-pact.config.ts
    ├── jest.config.ts
    ├── nodemon.json
    ├── optic.yml
    ├── package.json
    ├── renovate.json
    ├── test.http
    ├── tsconfig.jest.json
    ├── tsconfig.json
    ├── wallaby.js
    ├── .env.example
    ├── .eslintignore
    ├── .eslintrc.js
    ├── .npmrc
    ├── .nvmrc
    ├── .prettierignore
    ├── .prettierrc
    ├── cypress/
    │   ├── index.ts
    │   ├── tsconfig.json
    │   ├── verification-result.txt
    │   ├── config/
    │   │   ├── base.config.ts
    │   │   └── local.config.ts
    │   ├── e2e/
    │   │   ├── crud-movie-event.cy.ts
    │   │   └── crud-movie.cy.ts
    │   ├── fixtures/
    │   │   └── example.json
    │   └── support/
    │       ├── commands.ts
    │       ├── e2e.ts
    │       ├── esbuild-preprocessor.ts
    │       ├── get-token.ts
    │       ├── log.ts
    │       ├── parse-kafka-event.ts
    │       ├── plugins.ts
    │       ├── retryable-before.ts
    │       └── tasks.ts
    ├── prisma/
    │   ├── client.ts
    │   ├── schema.prisma
    │   └── migrations/
    │       ├── migration_lock.toml
    │       └── 20240903112501_initial_setup/
    │           └── migration.sql
    ├── pw/
    │   ├── config/
    │   │   ├── base.config.ts
    │   │   └── playwright-local.config.ts
    │   ├── e2e/
    │   │   ├── auth-session-example.spec.ts
    │   │   ├── crud-movie-event.spec.ts
    │   │   ├── crud-movie.spec.ts
    │   │   └── get-token.spec.ts
    │   └── support/
    │       ├── custom-auth-provider.ts
    │       ├── fixtures.ts
    │       ├── global-setup.ts
    │       ├── parse-kafka-event.ts
    │       ├── auth/
    │       │   ├── core.ts
    │       │   ├── global-setup-helper.ts
    │       │   ├── index.ts
    │       │   ├── test-fixtures.ts
    │       │   └── internal/
    │       │       ├── auth-configure.ts
    │       │       ├── auth-global-setup.ts
    │       │       ├── auth-provider.ts
    │       │       ├── auth-session.ts
    │       │       ├── auth-storage-utils.ts
    │       │       ├── auth-types.ts
    │       │       └── url-utils.ts
    │       ├── fixture-helpers/
    │       │   └── plain-functions.ts
    │       ├── fixtures/
    │       │   ├── api-request-fixture.ts
    │       │   ├── auth-fixture.ts
    │       │   └── crud-helper-fixture.ts
    │       └── utils/
    │           ├── recurse-with-expect.ts
    │           └── run-command.ts
    ├── scripts/
    │   ├── can-i-deploy-provider.sh
    │   ├── env-setup.sh
    │   ├── global-setup.ts
    │   ├── global-teardown.ts
    │   ├── publish-pact-openapi.sh
    │   ├── record-bidirectional-deployment.sh
    │   ├── record-provider-deployment.sh
    │   ├── setup-after-env.ts
    │   ├── truncate-tables.ts
    │   └── one-time-scripts/
    │       ├── create-github-issue-test.sh
    │       └── create-pact-webhook.sh
    ├── src/
    │   ├── movie-adapter.test.ts
    │   ├── movie-adapter.ts
    │   ├── movie-repository.ts
    │   ├── movie-service.test.ts
    │   ├── movie-service.ts
    │   ├── provider-contract.pacttest.ts
    │   ├── provider-kafka.pacttest.ts
    │   ├── routes.ts
    │   ├── server-config.ts
    │   ├── server.ts
    │   ├── @types/
    │   │   ├── index.ts
    │   │   ├── movie-event-types.ts
    │   │   ├── movie-types.ts
    │   │   └── schema.ts
    │   ├── api-docs/
    │   │   ├── openapi-generator.ts
    │   │   ├── openapi-writer.ts
    │   │   ├── openapi.json
    │   │   └── openapi.yml
    │   ├── events/
    │   │   ├── kafka-cluster.yml
    │   │   ├── log-file-path.ts
    │   │   ├── movie-events.test.ts
    │   │   └── movie-events.ts
    │   ├── middleware/
    │   │   ├── auth-middleware.test.ts
    │   │   ├── auth-middleware.ts
    │   │   ├── validate-movie-id.test.ts
    │   │   └── validate-movie-id.ts
    │   ├── test-helpers/
    │   │   ├── factories.ts
    │   │   ├── message-providers.ts
    │   │   ├── state-handlers.ts
    │   │   └── pact-utils/
    │   │       ├── build-verifier-options.ts
    │   │       ├── handle-url-and-selectors.ts
    │   │       └── pact-request-filter.ts
    │   └── utils/
    │       └── format-response.ts
    └── .github/
        ├── PULL_REQUEST_TEMPLATE.md
        └── workflows/
            ├── contract-test-publish-openapi.yml
            ├── contract-test.yml
            ├── e2e-test-cy.yml
            ├── e2e-test-pw.yml
            ├── merge-gatekeeper.yml
            ├── pr-checks.yml
            ├── schema-validation.yml
            └── webhook.yml

================================================
FILE: README.md
================================================
# PactJS Contract Testing Example

[![API Documentation](https://img.shields.io/badge/API-DOCUMENTATION-blue?style=flat-square)](https://muratkeremozcan.github.io/pact-js-example-provider/api-docs.html)

An example test framework using Pact-js to validate contract testing between consumer and provider. The application that we are testing is a simple movies API that returns a list of movies.

The biggest selling point of Consumer Driven Contract Testing (CDCT) in simple terms is the entities do not have to be in a common deployment; the contract / pact / json file instead binds them together. Which means we can work on the consumer in isolation, we can work on the provider in isolation, and we can test their integration without having to have them both running on the same machine or the same deployment.

Provider service: https://github.com/muratkeremozcan/pact-js-example-provider

Consumer service: https://github.com/muratkeremozcan/pact-js-example-consumer

React consumer app for bi-directional contract testing: https://github.com/muratkeremozcan/pact-js-example-react-consumer

![Image description](https://dev-to-uploads.s3.amazonaws.com/uploads/articles/8qjfdsunkrdncqrcy3sw.png)

- [PactJS Contract Testing Example](#pactjs-contract-testing-example)
  - [Setup](#setup)
    - [Consumer flow](#consumer-flow)
    - [Provider flow](#provider-flow)
    - [Other scripts on both sides](#other-scripts-on-both-sides)
      - [Consumer specific scripts](#consumer-specific-scripts)
      - [Provider specific scripts](#provider-specific-scripts)
    - [Webhook setup](#webhook-setup)
      - [Provider selective testing](#provider-selective-testing)
      - [Handling Breaking Changes](#handling-breaking-changes)
      - [Breaking change - consumer flow](#breaking-change---consumer-flow)
      - [Breaking change - provider flow](#breaking-change---provider-flow)
  - [Consumer Tests](#consumer-tests)
  - [Provider Tests](#provider-tests)
      - [Execution](#execution)
  - [Message queue consumer tests in short](#message-queue-consumer-tests-in-short)
  - [Message queue provider tests in short](#message-queue-provider-tests-in-short)
    - [Execution (Same as traditional CDCT)](#execution-same-as-traditional-cdct)
  - [Can I Deploy?](#can-i-deploy)
  - [Record Deployments](#record-deployments)
  - [Webhooks](#webhooks)
  - [Nuances of the env vars \& scripts](#nuances-of-the-env-vars--scripts)
      - [Why `GITHUB_SHA` and `GITHUB_BRANCH`?](#why-github_sha-and-github_branch)
      - [What is the Pact Matrix?](#what-is-the-pact-matrix)
  - [Bi-directional contract testing](#bi-directional-contract-testing)
      - [Consumer flow for Pact Bi-directional contract testing](#consumer-flow-for-pact-bi-directional-contract-testing)
      - [Provider flow for Pact Bi-directional contract testing](#provider-flow-for-pact-bi-directional-contract-testing)
    - [How does it work in the CI](#how-does-it-work-in-the-ci)
  - [OpenAPI Documentation and Schema Validation](#openapi-documentation-and-schema-validation)
  - [Database Management](#database-management)

## Setup

```bash
npm i
```

We are using [Pactflow](https://pactflow.io/) as our broker. To use Pactflow, register for their free developer plan.

Use the sample `.env.example` file to create a `.env` file of your own. These values will also have to exist in your CI secrets.

```bash
# create a free pact broker at
# https://pactflow.io/try-for-free/
PACT_BROKER_TOKEN=***********
PACT_BROKER_BASE_URL=https://yourownorg.pactflow.io
# need this for Prisma
DATABASE_URL="file:./dev.db"
# the port the local server will run on. If you want to change it, just modify the .env file, and the yml files
PORT=3001
```

### Consumer flow

The numbers indicate the order the commands should occur when running them locally.

> For CI, check out the Webhooks section below.

```bash
npm run test:consumer # (1)
npm run publish:pact  # (2)
npm run can:i:deploy:consumer # (4)
# only on main
npm run record:consumer:deployment --env=dev # (5) change the env param as needed
```

### Provider flow

```bash
# start the provider service and run the tests
# npm run start #
# npm run test:provider #
npm run test:provider-ci # (3) # starts the provider service and runs the tests
npm run can:i:deploy:provider # (5)
# only on main
npm run record:provider:deployment --env=dev # (5) change the env param as needed
```

### Other scripts on both sides

```bash
npm run lint
npm run typecheck
npm run fix:format
npm run validate # all the above in parallel

npm run test # unit tests
npm run test:watch # watch mode

npm run cy:open-local # open mode
npm run cy:run-local  # run mode
npm run cy:run-local-fast  # no video or screen shots

# PW scripts
npm run pw:open-local       # open mode (local config)
npm run pw:open-local-debug # open with debug (local config)

npm run pw:run-local        # run mode (local config)
npm run pw:run-local-debug  # run with debug (local config)

npm run pw:trace            # inspect a trace.zip file
npm run pw:clear            # remove all temporary PW files
```

#### Consumer specific scripts

To exercise the e2e of the consumer side, we need a running backend.
If using the real backend, we can set the PORT at `.env` to the backend port (3001).
If using a back backend, we use `Mockoon` which runs on PORT 3000.

```bash
npm run mock:server # starts the mock backend/provider server
npm start # only used to demo kafka events on the consumer side
```

#### Provider specific scripts

Using Kafka and Docker is optional. The Kafka version of the CRUD e2e test checks whether Kafka events are being written to a file, in addition to the standard CRUD operations. This test will only run if Docker is started and the Kafka UI is available. Therefore, make sure to start Docker (e.g., Docker Desktop) before executing the `kafka:start` script and the e2e test `crud-movie-event.cy.ts`.

```bash
npm run kafka:start # start Docker first, and then run this
npm run kafka:stop # to stop when we are done

# these 2 run as a part of start, and reset the db
# you usually don't have to use them
npm run db:migrate
npm run reset:db

npm run optic:lint # verifies the OpenAPI doc
npm run optic:diff # compares the OpenAPI on the PR to main, to find breaking changes
npm run optic:verify # executes the e2e against the OpenAPI doc to gain API coverage and validate it
npm run optic:update # executes the e2e, and interactively update the OpenAPI doc
npm run optic:verify-ci # the above, but it also starts the server, in case you're not running it on the side

npm run generate:openapi # generates an OpenAPI doc from Zod schemas
npm run publish:pact-openapi # publishes the open api spec to Pact Broker for BDCT
npm run record:provider:bidirectional:deployment --env=dev # records the bi-directional provider deployment
```

### Webhook setup

For the webhook to test successfully:

- **You must have executed pact tests at the consumer and provider**; the Pact Broker has to know about them.

- You must create a yml with `repository_dispatch ` event at your provider (you can use this file https://github.com/muratkeremozcan/provider/blob/main/.github/workflows/webhook.yml at your provider, edit the test executions portion as you see fit).

Flow:

1. [Create a GitHub personal access token](https://docs.github.com/en/authentication/keeping-your-account-and-data-secure/managing-your-personal-access-tokens) with the public_repo access granted.

   You can test your GitHub token with the script `scripts/one-time-scripts/create-github-issue-test.sh`.
   Update the repo variables, give the file execution permissions and execute it. Do not check in the file with secrets in display.

   ```bash
   # give it execution permissions
   chmod +x ./scripts/one-time-scripts/create-github-issue-test.sh
   # execute it
   ./scripts/one-time-scripts/create-github-issue-test.sh
   ```

   ```bash
   #!/bin/bash

   # this file is a test for your GitHub Personal Access token
   # if you can create an issue, then Pact webhook will work

   # Set your GitHub credentials and repository details
   GITHUB_REPO_OWNER="Your_GITHUB_REPO_OWNER"                      # GitHub username or org
   GITHUB_REPO_NAME="Your_repo_name"                               # GitHub repository name
   GITHUB_AUTH_TOKEN="Your_GitHub_Personal_Access_Token"           # GitHub Personal Access Token with repo permissions

   # Issue details
   ISSUE_TITLE="Test issue"                                    # Title of the issue to be created
   ISSUE_BODY="This is a test issue created via API."          # Body of the issue

   # Step 1: Verify the GitHub Token
   echo "Verifying GitHub token..."
   TOKEN_VERIFICATION_RESPONSE=$(curl -s -o /dev/null -w "%{http_code}" -H "Authorization: Bearer $GITHUB_AUTH_TOKEN" https://api.github.com/users/$GITHUB_REPO_OWNER)

   if [ "$TOKEN_VERIFICATION_RESPONSE" -ne 200 ]; then
     echo "Error: Bad credentials. Please check your GitHub token and ensure it has the required permissions."
     exit 1
   else
     echo "GitHub token verified successfully."
   fi

   # GitHub API endpoint for creating an issue
   ISSUE_URL="https://api.github.com/repos/$GITHUB_REPO_OWNER/$GITHUB_REPO_NAME/issues"

   # Step 2: Run the curl command to create the issue
   echo "Creating a new GitHub issue..."
   curl -X POST "$ISSUE_URL" \
       -H "Accept: application/vnd.github.v3+json" \
       -H "Authorization: Bearer $GITHUB_AUTH_TOKEN" \
       -d "{\"title\": \"$ISSUE_TITLE\", \"body\": \"$ISSUE_BODY\"}"
   ```

2. Add the GitHub token to PactFlow (Settings>Secrets>Add Secret, name it `githubToken`).

3. Create the Pact web hook (Settings>Webhooks>Add Webhook).

   > There are no values under Authentication section.

   Headers:

   ```bash
   Content-Type: application/json
   Accept: application/vnd.github.everest-preview+json
   Authorization: Bearer ${user.githubToken}
   ```

   Body:

   ```bash
   {
     "event_type": "contract_requiring_verification_published",
     "client_payload": {
       "pact_url": "${pactbroker.pactUrl}",
       "sha": "${pactbroker.providerVersionNumber}",
       "branch": "${pactbroker.providerVersionBranch}",
       "message": "Verify changed pact for ${pactbroker.consumerName} version ${pactbroker.consumerVersionNumber} branch ${pactbroker.consumerVersionBranch} by ${pactbroker.providerVersionNumber} (${pactbroker.providerVersionDescriptions})"
     }
   }
   ```

![Image description](https://dev-to-uploads.s3.amazonaws.com/uploads/articles/be9ywm042qtxj9i5h6nu.png)

Alternatively, use the CLI to add the webhook. Prior to running the scripts:

- Ensure that you have pact-broker working; pact-broker version
  Get it at https://github.com/pact-foundation/pact-ruby-standalone/releases, per your OS

  > You may have to set the path with zshell:
  > `export PATH=$PATH:$(pwd)/pact/bin`
  > or with fish:
  > `set -x PATH $PATH (pwd)/pact/bin`
  >
  > Test with
  > `pact-broker version`
  >
  > Ensure that your target provider GitHub repository has a .yml workflow file in .github/workflows/
  > configured to respond to repository_dispatch events with an event type like "contract_requiring_verification_published".
  > Example: https://github.com/muratkeremozcan/pact-js-example-provider/blob/main/.github/workflows/webhook.yml

- Set the values of the variables in the beginning of the script. **Careful not to check in the file with secrets in display**.

```bash
#!/bin/bash

# Pre-setup:
# Ensure that you have pact-broker working; pact-broker version
# Get it at https://github.com/pact-foundation/pact-ruby-standalone/releases, per your OS
# You may have to set the path with
# export PATH=$PATH:$(pwd)/pact/bin
# or
# set -x PATH $PATH (pwd)/pact/bin
#
# Ensure that your target provider GitHub repository has a .yml workflow file in .github/workflows/
# configured to respond to repository_dispatch events with an event type like "contract_requiring_verification_published".
# Example: https://github.com/muratkeremozcan/pact-js-example-provider/blob/main/.github/workflows/webhook.yml

# Set the Pact Broker and GitHub tokens and URLs as environment variables
PACT_BROKER_BASE_URL="Your_PactFlow_Org_URL"
PACT_BROKER_TOKEN="Your_Pact_Token"
GITHUB_AUTH_TOKEN="Your_GitHub_Personal_Access_Token"

# Set customizable parameters
DESCRIPTION="Your_webhook_description"                # Description for the webhook
CONSUMER_NAME="Pact_consumer_name"                    # Consumer name in Pact
PROVIDER_NAME="Pact_provider_name"                    # Provider name in Pact
GITHUB_REPO_OWNER="Your_user_name"                    # GitHub username or org
GITHUB_REPO_NAME="Your_repo_name"                     # GitHub repository name

# GitHub dispatch endpoint for the repository and workflow file
REPO_DISPATCHES="https://api.github.com/repos/$GITHUB_REPO_OWNER/$GITHUB_REPO_NAME/dispatches"

# Log important parameters for verification
echo "Pact Broker Base URL: $PACT_BROKER_BASE_URL \"
echo "GitHub Dispatch Endpoint: $REPO_DISPATCHES \"
echo "Consumer: $CONSUMER_NAME \"
echo "Provider: $PROVIDER_NAME \"
echo "Description: $DESCRIPTION"

# Step 1: Verify the Pact Broker URL
echo "Checking Pact Broker accessibility..."
PACT_BROKER_STATUS=$(curl -o /dev/null -s -w "%{http_code}" \
  -H "Authorization: Bearer $PACT_BROKER_TOKEN" \
  "$PACT_BROKER_BASE_URL")

if [ "$PACT_BROKER_STATUS" -ne 200 ]; then
  echo "Error: Pact Broker URL is not accessible. Status code: $PACT_BROKER_STATUS"
  echo "Please check the PACT_BROKER_BASE_URL & PACT_BROKER_TOKEN."
  exit 1
else
  echo "Pact Broker URL is accessible."
fi

# Step 2: Check if the GitHub dispatch endpoint is accessible
echo "Checking GitHub dispatch endpoint..."
RESPONSE_STATUS=$(curl -o /dev/null -s -w "%{http_code}" -X POST "$REPO_DISPATCHES" \
    -H "Authorization: Bearer $GITHUB_AUTH_TOKEN" \
    -H "Accept: application/vnd.github.everest-preview+json" \
    -d '{"event_type": "contract_requiring_verification_published"}')

if [ "$RESPONSE_STATUS" -ne 204 ]; then
  echo "Error: Unable to access GitHub dispatch endpoint. Status code: $RESPONSE_STATUS"
  echo "Please check your GitHub token and webhook related yml. You may have to create a yml with repository_dispatch of type contract_requiring_verification_published"
  exit 1
else
  echo "GitHub dispatch endpoint is accessible."
fi

# Step 3: Run the pact-broker command to create the webhook
echo "Creating Pact webhook..."
pact-broker create-webhook "$REPO_DISPATCHES" \
    --request=POST \
    --header 'Content-Type: application/json' \
    --header 'Accept: application/vnd.github.everest-preview+json' \
    --header "Authorization: Bearer $GITHUB_AUTH_TOKEN" \
    --data '{
        "event_type": "contract_requiring_verification_published",
        "client_payload": {
            "pact_url": "${pactbroker.pactUrl}",
            "sha": "${pactbroker.providerVersionNumber}",
            "branch": "${pactbroker.providerVersionBranch}",
            "message": "Verify changed pact for ${pactbroker.consumerName} version ${pactbroker.consumerVersionNumber} branch ${pactbroker.consumerVersionBranch} by ${pactbroker.providerVersionNumber} (${pactbroker.providerVersionDescriptions})"
        }
    }' \
    --broker-base-url="$PACT_BROKER_BASE_URL" \
    --broker-token="$PACT_BROKER_TOKEN" \
    --consumer="$CONSUMER_NAME" \
    --provider="$PROVIDER_NAME" \
    --description="$DESCRIPTION" \
    --contract-requiring-verification-published

```

#### Provider selective testing

By default, Pact provider tests run against all consumers and their respective contracts, which can make it difficult to debug specific issues. To narrow down the scope and run selective tests, you can filter by specific consumer or use Pact selectors to focus on certain interactions or states.

Refer to the [Pact JS Troubleshooting Guide](https://docs.pact.io/implementation_guides/javascript/docs/troubleshooting) for more details.

You can use the following environment variables to select specific interactions or states:

- `PACT_DESCRIPTION`: Selects all tests containing this string in their description (from the test output or the pact file).
- `PACT_PROVIDER_STATE`: Selects all tests containing this string in one of their provider states.
- `PACT_PROVIDER_NO_STATE`: Set to `TRUE` to select all tests without provider states.

```bash
PACT_DESCRIPTION="a request to get all movies" npm run test:provider

PACT_DESCRIPTION="a request to get all movies" PACT_PROVIDER_STATE="An existing movie exists" npm run test:provider

PACT_PROVIDER_STATE="Has a movie with a specific ID" npm run test:provider

PACT_DESCRIPTION="a request to a specific movie" PACT_PROVIDER_STATE="Has a movie with a specific ID" npm run test:provider

PACT_DESCRIPTION="a request to delete a movie that exists" PACT_PROVIDER_STATE="Has a movie with a specific ID" npm run test:provider

PACT_PROVIDER_NO_STATE=true npm run test:provider
```

To run tests from a certain consumer:

```bash
PACT_CONSUMER="WebConsumer" npm run test:provider
```

#### Handling Breaking Changes

When verifying consumer tests, we use the following default settings:

- `matchingBranch`: Tests against the consumer branch that matches the provider's branch.
- `mainBranch`: Tests against the consumer's main branch.
- `deployedOrReleased`: Tests against the consumer's currently deployed or released versions.

For **breaking changes** introduced on the provider side, you may want to verify only against matching branches, avoiding failures caused by incompatible versions in `mainBranch` or `deployedOrReleased`.

To handle this scenario, use the `PACT_BREAKING_CHANGE` environment variable:

```bash
PACT_BREAKING_CHANGE=true npm run test:provider
```

In CI, you can enable this behavior by including a checkbox in the PR description. If the box is unchecked or not included, the `PACT_BREAKING_CHANGE` variable is set to `false`.

```readme
- [x] Pact breaking change
```

#### Breaking change - consumer flow

```bash
# (2) UPDATE the consumer test
npm run test:consumer # (2) execute it
npm run publish:pact  # (3) publish the pact
npm run can:i:deploy:consumer # (6)
# only on main
npm run record:consumer:deployment --env=dev # (7)
```

#### Breaking change - provider flow

```bash
# (1) create a branch with the breaking (source code) change
PACT_BREAKING_CHANGE=true npm run test:provider-ci # (4) start the provider service and run the tests
# note: can:i:deploy:provider is skipped because we are introducing the breaking change
# (5) merge to main
```

## Consumer Tests

Here is how it works:

1. Write the consumer test.

2. Execute the and generate a contract / pact / json file.

   The contract specifies how the provider should respond upon receiving requests from the consumer.

3. Once the contract is created, from then on the Pact `mockProvider` takes over as if we are locally serving the provider API and executing the tests against that.
   That means, there is no need to serve the client api or the provider api at the moment, the consumer tests and `mockProvider` cover that interaction.

4. The consumer test can only fail at the `executeTest` portion, if / when the assertions do not match the specifications. Any changes to the `provider` section makes updates to the contract.

Here's how a test generally looks:

```js
// consumer test

it('...', () => {
  await pact
    // simulate/specify how the provider should respond
    .addInteraction(...)
    .given(some state name) // optional
    .uponReceiving(<the name of the test>)
    .withRequest(http verb, path)
    .willRespondWith({ this is the meat and bones of the response })

    .executeTest(async(mockProvider) => {
    // call the source code &
    // make assertions against the mockProvider/contract
  })
})
```

Run the consumer tests:

```bash
npm run test:consumer
```

The pact gets recorded, the consumer tests (`executeTest`) are verified against the contract.

Now, for the provider to know about it all, we need to publish the contract

Publish the contract to your Pact Broker:

```bash
npm run publish:pact
```

## Provider Tests

The main goal is to verify that the provider API can fulfill the contract expectations defined by the consumer(s). This ensures that any changes made to the provider won't break existing consumer integrations.

Here is how it works

1. The consumer already generated the contract and published it.
2. The provider has one test per consumer to ensure all is satisfactory. Most of the file is about setting up the options.
3. We ensure that the provider api is running locally.
4. The consumer tests execute against the provider api, as if they are a regular API client running locally.

Here is how the test generally looks:

```js
const options = {..} // most the work is here (ex: provider states)
const verifier = new Verifier(options)

it('should validate the expectations..', () => {
  return verifier.verifyProvider().then((output) => {
    console.log('Pact Verification Complete!')
    console.log('Result:', output)
  })
})
```

#### Execution

Run the Movies API:

```bash
npm run start
```

> The provider API has to be running locally for the provider tests to be executed.

Run the provider test:

```bash
npm run test:provider
```

Two in one:

```bash
npm run test:provider-ci
```

**Provider States**: We can simulate certain states of the api (like an empty or non-empty db) in order to cover different scenarios

- Provider states help maintain the correct data setup before verification.
- State handlers must match the provider states defined in consumer tests.

## Message queue consumer tests in short

1. Write the consumer test.

   Message q consumer test: **simulates receiving a message from the queue**.

   Traditional consumer test: **simulates receiving a response from the provider**.

2. Execute the and generate a contract / pact / json file. (same)

   The message queue contract **specifies the expected structure of the message from the producer.**

   Traditional consumer test contract **specifies the expected structure of the response from the provider**.

3. Once the contract is created, Pact `mockProducer` takes over as if we are locally pushing messages to the queue (`expectsToReceive`) and verifying the message agains our src code event-message-consumer-handler.

   This is similar to traditional consumer test where the `mockProvider` takes over as if we are locally serving the provider API and executing the tests against that.

4. The test can fail at the `verify` portion, if / when the simulated message does not match our src code event-message-consumer.

Here is a contract test vs message queue test side by side:

```typescript
// message queue consumer test

it('...', () => {
  await messagePact
    // simulate/specify the expected message
    .expectsToReceive('some text for event name')
    .withContent({ this is the meat and bones of the event })
    .withMetaData({ contentType: 'application/json' })

    // feed the message into the event consumer
    .verify(asynchronousBodyHandler(yourEventConsumerHandler))
  })
})
```

```typescript
// consumer test

it('...', () => {
  await pact
    // simulate/specify how the provider should respond
    .addInteraction(...)
    .given(some state name) // optional
    .uponReceiving(<the name of the test>)
    .withRequest(http verb, path)
    .willRespondWith({ this is the meat and bones of the response })

    .executeTest(async(mockProvider) => {
    // call the source code &
    // make assertions against the mockProvider/contract
  })
})
```

The flow is the same as a traditional consumer test, in fact if the repo has both, both tests are executed

```bash
npm run test:consumer
npm run publish:pact
```

## Message queue provider tests in short

These tests verify that **the messages the provider produces match the structure the consumer expects**.

In contrast, in traditional CDCT, the tests verify that **the responses of the provider API match the structure the consumer expects**.

1. The message consumer already generated the contract and published it. (Same thing as the traditional CDCT)

2. The provider has one test per consumer to ensure all is satisfactory. Most of the file is about setting up the options. (Again, same)

3. We ensure that the provider api is running locally. (Again, same)

4. **The message queue consumer tests execute against the provider/message-producer**, as if they are a regular message-consumer running locally.

   In contrast, in traditional CDCT, **the consumer tests execute against the provider api**, as if they are a regular API client running locally.

### Execution (Same as traditional CDCT)

Run the server/service.

```bash
npm run start
```

> The provider/producer server/service has to be running locally for the provider message queue tests to be executed.

Run the provider/producer message queue test

```bash
npm run test:provider
```

Two in one:

```bash
npm run test:provider:ci
```

## Can I Deploy?

Before deploying to an environment, we verify if the consumer and provider versions are compatible using the `can-i-deploy` tool. This step ensures that any changes made to the consumer or provider do not break existing integrations across environments.

In the current setup, the provider is tested against the consumer's main branch and currently deployed versions (`dev`).

Verify the provider:

```bash
npm run can:i:deploy:provider
```

Verify the consumer:

```bash
npm run can:i:deploy:consumer
```

## Record Deployments

This is akin to releasing; used to record the deployment in the Pact Broker to show the deployed version in an environment. Usually this is `main` being deployed on `dev` environment.

You can also run them locally but they will only execute on `main` branch. These scripts are designed to only record deployments when on the `main` branch, ensuring that only final production-ready versions are tracked.

Record the provider deployment:

```bash
npm run record:provider:deployment --env=dev # change the env param as needed
```

Record the consumer deployment:

```bash
npm run record:consumer:deployment --env=dev # change the env param as needed
```

## Webhooks

Recall the consumer and provider flow.

The key is that, when there are multiple repos, the provider has to run `test:provider-ci` `(#3)` after the consumer runs `publish:pact` `(#2)` but before the consumer can run `can:i:deploy:consumer` `(#4)` . The trigger to run `test:provider-ci` `(#3)` has to happen automatically, webhooks handle this.

```bash
# Consumer
npm run test:consumer # (1)
npm run publish:pact  # (2)
npm run can:i:deploy:consumer # (4)
# only on main
npm run record:consumer:deployment --env=dev # (5) change the env param as needed

# Provider
npm run test:provider-ci # (3) triggered by webhooks
npm run can:i:deploy:provider # (4)
# only on main
npm run record:provider:deployment --env=dev # (5) change the env param as needed
```

## Nuances of the env vars & scripts

To streamline our scripts, we've centralized the setup of environment variables in a script:

```bash
./scripts/env-setup.sh
```

This script initializes critical environment variables like `GITHUB_SHA` and `GITHUB_BRANCH` and values at the `.env` file `PACT_BROKER_TOKEN` and `PACT_BROKER_BASE_URL`, which are used across multiple scripts to ensure consistency.

Using `GITHUB_SHA` and `GITHUB_BRANCH` in your scripts is essential for ensuring traceability and consistency across different environments and CI/CD workflows. Here's why:

#### Why `GITHUB_SHA` and `GITHUB_BRANCH`?

- **`GITHUB_SHA`**: This variable represents the unique commit ID (SHA) in Git. By using the commit ID as the version identifier when publishing the contract or running tests, you can precisely trace which version of your code generated a specific contract. This traceability is crucial in understanding which code changes correspond to which contract versions, allowing teams to pinpoint when and where an issue was introduced.

- **`GITHUB_BRANCH`**: Including the branch name ensures that contracts and deployments are correctly associated with their respective branches, supporting scenarios where different branches represent different environments or features under development. It helps prevent conflicts or mismatches in contracts when multiple teams or features are being developed simultaneously.

  TL,DR; best practice, do it this way.

#### What is the Pact Matrix?

The Pact Matrix is a feature within Pactflow (or other Pact brokers) that visualizes the relationships between consumer and provider versions and their verification status across different environments. The matrix shows:

- Which versions of consumers are compatible with which versions of providers.
- The verification results of these interactions across various environments (e.g., dev, stage, prod).

By using `GITHUB_SHA` and `GITHUB_BRANCH` in your CI/CD workflows, you ensure that the matrix accurately reflects the state of your contracts and their verifications. This makes it easier to determine if a particular consumer or provider version is safe to deploy in a specific environment, ultimately enabling seamless integration and deployment processes.

Example matrix:

| **Consumer Version (SHA)** | **Provider Version (SHA)** | **Branch**  | **Environment** | **Verification Status** | **Comments**                                                                                             |
| -------------------------- | -------------------------- | ----------- | --------------- | ----------------------- | -------------------------------------------------------------------------------------------------------- |
| `abc123`                   | `xyz789`                   | `main`      | `production`    | Passed                  | The consumer and provider are both verified and deployed in production.                                  |
| `def456`                   | `xyz789`                   | `main`      | `staging`       | Passed                  | The same provider version is compatible with a newer consumer version in staging.                        |
| `ghi789`                   | `xyz789`                   | `feature-x` | `development`   | Failed                  | The consumer from a feature branch failed verification with the provider in the development environment. |
| `jkl012`                   | `uvw345`                   | `main`      | `production`    | Pending                 | A new provider version is pending verification against the consumer in production.                       |

## Bi-directional contract testing

In CDCT, the consumer tests are executed on the provider side, which mandates that the provider server can be served locally. This might be a blocker for CDCT.
It might also happen that we want to contract-test against a provider outside of the org.

BDCT offers an easier alternative to CDCT. All you need is the OpenAPI spec of the provider, and the consumer side stays the same.

Here is how it goes:

1. **Generate the OpeAPI spec at the provider**

   Automate this step using tools like `zod-to-openapi`, `swagger-jsdoc`, [generating OpenAPI documentation directly from TypeScript types, or generating the OpenAPI spec from e2e tests (using Optic)](https://dev.to/muratkeremozcan/automating-api-documentation-a-journey-from-typescript-to-openapi-and-schema-governence-with-optic-ge4). Manual spec writing is the last resort.

2. **Ensure that the spec matches the real API**

   `cypress-ajv-schema-validator`: if you already have cy e2e and you want to easily chain on to the existing api calls.

   Optic: lint the schema and/or run the e2e suite against the OpenAPI spec through the Optic proxy.

   Dredd: executes its own tests (magic!) against your openapi spec (needs your local server, has hooks for things like auth.)

3. **Publish the OpenAPI spec to the pact broker at the provider**.

   ```bash
      npm run publish:pact-openapi
   ```

4. **Record the provider bi-directional deployment at the provider**.

   We still have to record the provider bi-directional, similar to how we do it in CDCT.
   Otherwise the consumers will have nothing to compare against.

   ```bash
   npm run record:provider:bidirectional:deployment --env=dev
   ```

5. **Execute the consumer contract tests at the consumer**

   Execution on the Consumer side works exactly the same as classic CDCT.

   ```bash
    npm run test:consumer
    npm run publish:pact
    npm run can:i:deploy:consumer
    # only on main
    npm run record:consumer:deployment --env=dev
   ```

As you can notice, there is nothing about running the consumer tests on the provider side ( `test:provider`), can-i-deploy checks (`can:i:deploy:provider`),. All you do is get the OpenAPI spec right, publish it to Pact Broker, and record the deployment

We have a sample consumer repo for BDCT [pact-js-example-react-consumer](https://github.com/muratkeremozcan/pact-js-example-react-consumer).

The [api calls](https://github.com/muratkeremozcan/pact-js-example-react-consumer/blob/main/src/consumer.ts) are the same as the plain, non-UI app used int CDCT.

We cannot have CDCT and BDCT in the same contract relationship. Although, we can have the provider have consumer driven contracts with some consumers and provider driven contracts with others

```bash
Consumer        -> CDCT  -> Provider

Consumer-React  <- BDCT  <- Provider
```

#### Consumer flow for Pact Bi-directional contract testing

```bash
npm run test:consumer # (4)
npm run publish:pact # (5)
npm run can:i:deploy:consumer #(6)
# only on main
npm run record:consumer:deployment --env=dev # (7) change the env param as needed
```

#### Provider flow for Pact Bi-directional contract testing

```bash
npm run generate:openapi # (1) generates an OpenAPI doc from Zod schemas
npm run publish:pact-openapi # (2) on main, publish the open api spec to Pact Broker for BDCT
npm run record:provider:bidirectional:deployment --env=dev # (3) on main record the bi-directional provider deployment
```

### How does it work in the CI

The e2e tests already do the schema testing. A section was appended to the end of `e2e-test.yml` to generate a text file about the status of the e2e run. Pact likes to have some file/evidence that the OpenAPI spec was tested, this satisfies that.

```yml
# e2e-test.yml

# ... all the e2e

# We do schema testing within the api e2e
# We publish the OpenAPI spec on main, once after the PR is merged
# Pact likes to have some file/evidence that the OpenAPI spec was tested
# This section handles that need

- name: Generate Verification Result for Success
  if: steps.cypress-tests.conclusion == 'success'
  run: echo "All Cypress tests passed." > cypress/verification-result.txt

- name: Generate Verification Result for Failure
  if: steps.cypress-tests.conclusion != 'success'
  run: echo "Not all Cypress tests passed." > cypress/verification-result.txt

- name: Commit and push verification result
  uses: EndBug/add-and-commit@v9
  with:
    author_name: 'GitHub Actions'
    author_email: 'actions@github.com'
    message: 'Update verification results'
    add: 'cypress/verification-result.txt'
    push: true
```

Using the same commit-and-push GitHub action, we have another `contract-commit-openapi.yml`, which ensures that the latest openapi spec is committed to the PR, if the changed. That way we do not have to locally generate the OpenAPI spec.

When the PR runs, `e2e-test.yml` executes and tests the schema. `contract-commit-openapi.yml` handles the OpenAPI spec.

The merge to main happens on a passing PR.

Finally, on main. we have `contract-publish-openapi.yml` , which publishes the OpenAPI spec to Pact broker with `npm run publish:pact-openapi` and records the bi-directional provider deployment with `npm run record:provider:bidirectional:deployment --env=dev`.

## OpenAPI Documentation and Schema Validation

This project uses Zod and zod-to-openapi to generate OpenAPI documentation. The process involves the following steps:

1. **Schema Definition**:

   - Define schemas using Zod and zod-to-openapi.
   - Link schemas with TypeScript types using `z.infer`.
   - Utilize zod's `safeParse` for runtime type checking.

> `src/@types/schema.ts` contains the schema definitions.

2. **Schema Registration**:

   - Register all schemas with the OpenAPI Registry `OpenAPIRegistry` from `@asteasolutions/zod-to-openapi`.

> `src/api-docs/openapi-generator.ts` contains the schema registration.

3. **OpenAPI Document Generation**:

   - Use `OpenApiGeneratorV31` from `@asteasolutions/zod-to-openapi` to generate the full OpenAPI document.
   - This document can be serialized to JSON or YAML.
   - The script `generate:openapi` creates `openapi.json` and `openapi.yaml` files in the `api-docs` directory.

> `src/api-docs/openapi-writer.ts` contains the OpenAPI document generation.

4. **Schema Governance with Optic**:

   - We use Optic for schema governance.
   - The `optic:diff` command:
     - Lints and verifies the OpenAPI doc for validity.
     - Compares the OpenAPI spec on the main branch with the one in the PR.
     - Detects breaking changes, which we should communicate to API consumers.
     - The only way through a breaking change is incrementing the major version of the OpenAPI spec.

   ```bash
      npm run optic:diff # breaking change detected

     # update the OpenAPI doc version at src/api-docs/openapi-generator.ts

     npm run generate:openapi # rewrite/update the OpenAPI document

     npm run optic:diff # rerun Optic to ensure the breaking change is okay to be merged

     # communicate with the API consumers about the breaking change

     # note: generate:openapi & optic:diff are all done in the CI pipeline
     # .github/workflows/contract-test-commit-openapi.yml
   ```

5. **Runtime Schema Validation**:
   - We use the `cypress-ajv-schema-validator` plugin in our API E2E tests.
   - This ensures that we test our schema during E2E testing.
   - It helps identify potential breaking changes that might pass our tests but could fail for API consumers.
   - The result of these tests are used in Bi-directional contract testing, to ensure that the OpenAPI spec the bi-directional contract consumers test against is always up to spec. If the tests pass, they get merged in main, published to the Pact Broker, and then recorded.

This comprehensive approach ensures that our API documentation is always in sync with our schema definitions, provides flexibility in how we serve and distribute the documentation, and maintains strict governance over schema changes. It also helps us proactively identify and communicate breaking changes to our API consumers.

Mind that, if we are only doing bi-directional contract testing, the only information that should alert us and in turn our consumers about a breaking change is the `optic:diff` and the OpenAPI spec update. Bi-directional contract testing does not block Provider PRs, it only blocks Consumer PRs. As soon as our breaking change from the Provider is merged to main, all consumers are blocked until they accommodate the breaking changes.

## Database Management

This project uses Prisma for database operations. Two main scripts are available:

`npm run db:migrate`

Resets the database using Prisma migrations. Use this to apply all migrations and reset to a clean state.

`npm run db:sync`

Synchronizes the database schema with the current Prisma schema. Use this for quick updates during development.

**Note:** Both scripts will reset your database. Use with caution in production environments.

To start the application with a fresh database, after making changes to `schema.prisma`:

```bash
npm run db:migrate
npm run db:sync
npm run reset:db
```



================================================
FILE: jest-pact.config.ts
================================================
import type { JestConfigWithTsJest } from 'ts-jest'

export const config: JestConfigWithTsJest = {
  clearMocks: true,
  testTimeout: 30000, // Can be longer due to pact tests
  collectCoverage: false, // You can disable coverage for pact tests if needed
  moduleDirectories: ['node_modules', 'src'],
  modulePathIgnorePatterns: ['dist'],
  transform: {
    '^.+\\.(ts|tsx)$': ['ts-jest', { tsconfig: 'tsconfig.jest.json' }]
  },
  testMatch: ['**/*.pacttest.ts'], // Pact test file match
  testEnvironment: 'node',
  globalSetup: './scripts/global-setup.ts', // runs before all tests
  globalTeardown: './scripts/global-teardown.ts', // runs after all tests
  setupFilesAfterEnv: ['./scripts/setup-after-env.ts'] // runs before each test file
}

export default config



================================================
FILE: jest.config.ts
================================================
import type { JestConfigWithTsJest } from 'ts-jest'

export const config: JestConfigWithTsJest = {
  clearMocks: true,
  testTimeout: 10000,
  collectCoverage: true,
  collectCoverageFrom: [
    'src/**/*.ts*', // Include all source TypeScript files
    '!src/server*.ts', // routes are tested via e2e
    '!src/**/*.pacttest.ts', // Exclude pacttest files
    '!**/test-helpers/**', // Exclude test helpers
    '!**/*.json',
    '!?(**)/?(*.|*-)types.ts',
    '!**/models/*',
    '!**/__snapshots__/*',
    '!**/scripts/*',
    '!**/node_modules/**'
  ],
  coverageDirectory: './coverage',
  coverageReporters: [
    'clover',
    'json',
    'lcov',
    ['text', { skipFull: true }],
    'json-summary'
  ],
  coverageThreshold: {
    global: {
      statements: 0,
      branches: 0,
      lines: 0,
      functions: 0
    }
  },
  moduleDirectories: ['node_modules', 'src'],
  modulePathIgnorePatterns: ['dist'],
  transform: {
    '^.+\\.(ts|tsx)$': ['ts-jest', { tsconfig: 'tsconfig.jest.json' }]
  },
  testMatch: ['**/*.test.ts'],
  testEnvironment: 'node'
}

export default config



================================================
FILE: nodemon.json
================================================
{
  "watch": ["src"],
  "ext": "ts,js,json",
  "ignore": ["node_modules", "src/**/*.test.ts", "dist", "coverage"],
  "exec": "tsx src/server.ts"
}



================================================
FILE: optic.yml
================================================
# https://www.useoptic.com/docs/style-guides
ruleset:
  # Prevent breaking changes
  - "breaking-changes"
capture:
  src/api-docs/openapi.yml: # path to openapi.yml file
    x-optic-path-ignore: '/__messages__'
    server:
      # command: pnpm start:local # works better if we start it ourselves
      # specified in package.json with --server-override
      url: http://localhost:3001

      ready_endpoint: /
      # The interval to check 'ready_endpoint', in ms.
      # Optional: default: 1000
      ready_interval: 1000
      # The length of time in ms to wait for a successful ready check to occur.
      # Optional: default: 10_000, 10 seconds
      ready_timeout: 10_000
    # At least one of 'requests.run' or 'requests.send' is required below.
    requests:
      # Run a command to generate traffic. Requests should be sent to the Optic proxy, the address of which is injected
      # into 'run.command's env as OPTIC_PROXY or the value of 'run.proxy_variable', if set.
      run:
        # The command that will generate traffic to the Optic proxy. Globbing with '*' is supported.
        # Required if specifying 'requests.run'.

        # Cypress version:
        # command: export NO_PROXY='<-loopback>' export HTTP_PROXY=http://localhost:8080 export HTTPS_PROXY=http://localhost:8080 && pnpm cy:run-local
        command: npm run cy:run-local-fast
        # The name of the environment variable injected into the env of the command that contains the address of the Optic proxy.
        # Optional: default: OPTIC_PROXY
        proxy_variable: OPTIC_PROXY
    config:
      # The number of parallel requests to make when using 'requests.send'.
      # Optional: default: 4
      request_concurrency: 4


================================================
FILE: package.json
================================================
{
  "name": "pact",
  "version": "1.0.0",
  "description": "",
  "main": "index.js",
  "author": "Murat Ozcan",
  "license": "ISC",
  "scripts": {
    "cy:run-local-base": "cypress run --e2e --browser chrome --config-file cypress/config/local.config.ts",
    "cy:run-local": "npm run cy:run-local-base",
    "cy:run-local-fast": "CYPRESS_NO_COMMAND_LOG=1 npm run cy:run-local-base -- --config video=false screenshot=false",
    "cy:open-local": "cypress open --e2e --browser chrome --config-file cypress/config/local.config.ts",
    "db:migrate": "npx prisma migrate reset --force --skip-seed generate",
    "db:sync": "npx prisma db push --force-reset && npx prisma generate",
    "db:migrate-prod": "npx prisma migrate deploy",
    "reset:db": "tsx ./scripts/global-setup.ts",
    "start": ". ./scripts/env-setup.sh && npm run db:sync && npm run reset:db && npm run kafka:reset-logs && nodemon",
    "kafka:reset-logs": "rm -rf cypress/movie-events.log",
    "kafka:start": "docker compose -f ./src/events/kafka-cluster.yml up -d --no-recreate",
    "kafka:stop": "docker compose -f ./src/events/kafka-cluster.yml down",
    "prettier": "prettier --ignore-path .gitignore \"**/*.+(js|ts|json)\"",
    "fix:format": "prettier --write '**/*.{js,ts,json}' --ignore-path .prettierignore",
    "validate": "npm-run-all --parallel typecheck lint fix:format test",
    "test": "jest --detectOpenHandles --verbose --silent --config jest.config.ts",
    "test:watch": "jest --watch --config jest.config.ts",
    "test:provider": ". ./scripts/env-setup.sh && jest --config jest-pact.config.ts --runInBand",
    "test:provider-ci": ". ./scripts/env-setup.sh && start-server-and-test start http://localhost:${PORT} test:provider",
    "can:i:deploy:provider": ". ./scripts/can-i-deploy-provider.sh",
    "record:provider:deployment": ". ./scripts/record-provider-deployment.sh",
    "record:provider:bidirectional:deployment": ". ./scripts/record-bidirectional-deployment.sh",
    "publish:pact-openapi": ". ././scripts/publish-pact-openapi.sh",
    "typecheck": "tsc --noEmit -p tsconfig.json && tsc --noEmit -p tsconfig.jest.json",
    "lint": "eslint --ext=.js,.ts,.tsx --fix",
    "generate:openapi": "tsx src/api-docs/openapi-writer.ts",
    "optic:lint": "optic lint src/api-docs/openapi.yml",
    "optic:diff": "optic diff src/api-docs/openapi.yml --check --web --base main",
    "optic:verify": "optic capture src/api-docs/openapi.yml",
    "optic:update": "optic capture src/api-docs/openapi.yml --update interactive",
    "optic:verify-ci": ". ./scripts/env-setup.sh && start-server-and-test start http://localhost:${PORT} optic:verify",
    "generate:api-docs": "rm -rf docs && npx redocly build-docs src/api-docs/openapi.yml -o docs/api-docs.html",
    "pw:open-local": "npx playwright test --ui -c pw/config/playwright-local.config.ts",
    "pw:open-local-debug": "PWDEBUG=1 npx playwright test --ui -c pw/config/playwright-local.config.ts",
    "pw:run-local": "npx playwright test -c pw/config/playwright-local.config.ts",
    "pw:run-local-debug": "PW_HTML_REPORT=1 npx playwright test --trace on -c pw/config/playwright-local.config.ts ; npx playwright show-report",
    "pw:trace": "npx playwright show-trace",
    "pw:clear": "rm -rf test-results playwright-report playwright/.cache"
  },
  "dependencies": {
    "@asteasolutions/zod-to-openapi": "7.3.0",
    "@prisma/client": "6.3.1",
    "express": "4.21.2",
    "kafkajs": "2.2.4",
    "prisma": "6.3.1",
    "uuid": "^11.1.0",
    "zod": "3.24.1"
  },
  "devDependencies": {
    "@bahmutov/cy-api": "2.2.8",
    "@bahmutov/cypress-esbuild-preprocessor": "2.2.4",
    "@cypress/skip-test": "2.6.1",
    "@esbuild-plugins/node-globals-polyfill": "0.2.3",
    "@esbuild-plugins/node-modules-polyfill": "0.2.2",
    "@faker-js/faker": "9.4.0",
    "@pact-foundation/pact": "13.2.0",
    "@pact-foundation/pact-cli": "16.0.4",
    "@playwright/test": "^1.49.1",
    "@redocly/cli": "^1.25.15",
    "@types/jest": "29.5.14",
    "@types/lodash": "4.17.15",
    "@types/node": "22.13.1",
    "@types/uuid": "^10.0.0",
    "@typescript-eslint/eslint-plugin": "8.23.0",
    "@typescript-eslint/parser": "8.23.0",
    "@useoptic/optic": "1.0.6",
    "cors": "2.8.5",
    "cross-env": "7.0.3",
    "cy-spok": "1.6.2",
    "cypress": "14.0.2",
    "cypress-ajv-schema-validator": "1.4.0",
    "cypress-data-session": "2.8.6",
    "cypress-map": "1.43.0",
    "cypress-recurse": "1.35.3",
    "cypress-skip-test": "1.0.0",
    "dotenv": "16.4.7",
    "eslint": "8.57.1",
    "eslint-config-prettier": "10.0.1",
    "eslint-import-resolver-typescript": "4.0.0",
    "eslint-plugin-cypress": "3.6.0",
    "eslint-plugin-filenames": "1.3.2",
    "eslint-plugin-implicit-dependencies": "1.1.1",
    "eslint-plugin-import": "2.31.0",
    "eslint-plugin-no-only-tests": "3.3.0",
    "eslint-plugin-prettier": "5.2.3",
    "is-ci": "^4.0.0",
    "jest": "29.7.0",
    "jest-mock-extended": "3.0.7",
    "lodash": "4.17.21",
    "nodemon": "3.1.9",
    "npm-run-all2": "7.0.2",
    "openapi-types": "^12.1.3",
    "prettier": "3.4.2",
    "start-server-and-test": "2.0.10",
    "ts-jest": "29.2.5",
    "ts-node": "10.9.2",
    "tsx": "4.19.2",
    "typescript": "5.7.3"
  }
}



================================================
FILE: renovate.json
================================================
{
  "extends": ["config:base"],
  "automerge": true,
  "rebaseWhen": "conflicted",
  "prHourlyLimit": 2,
  "updateNotScheduled": false,
  "timezone": "America/New_York",
  "schedule": ["after 10pm and before 5am on every weekday", "every weekend"],
  "masterIssue": true,
  "labels": ["type: dependencies", "renovate"],
  "dependencyDashboardApproval": false,
  "packageRules": [
    {
      "groupName": "All Minor and Patch Updates",
      "matchUpdateTypes": ["minor", "patch"]
    }
  ]
}



================================================
FILE: test.http
================================================
@baseUrl = http://localhost:3001

###
# @name generateToken
# Simulate token generation (mocked)
GET {{baseUrl}}/auth/fake-token

###
@token = {{generateToken.response.body.token}}

###
# @name heartbeat
GET {{baseUrl}}

###
# @name addMovie
POST {{baseUrl}}/movies
Content-Type: application/json
Authorization: {{token}}

{
    "name": "Inception",
    "year": 2010,
    "rating": 7.5,
    "director": "Christopher Nolan"
}

###

@movieId = {{addMovie.response.body.data.id}}
@movieName = {{addMovie.response.body.data.name}}

###
# @name getAllMovies
GET {{baseUrl}}/movies
Authorization: {{token}}

###
# @name getMovieById
GET {{baseUrl}}/movies/{{movieId}}
Authorization: {{token}}

###
# @name getMovieByName
GET {{baseUrl}}/movies?name={{movieName}}
Authorization: {{token}}

###
# @name addDuplicateMovie
POST {{baseUrl}}/movies/
Content-Type: application/json
Authorization: {{token}}

{
    "name": "Inception",
    "year": 2010,
    "rating": 7.5
}

###
# @name addMovieInvalidYear
POST {{baseUrl}}/movies
Content-Type: application/json
Authorization: {{token}}

{
    "name": "Invalid Year Movie",
    "year": 1800,
    "rating": 7.5,
    "director": "Christopher Nolan"
}

###
# @name updateMovie
PUT {{baseUrl}}/movies/{{movieId}}
Content-Type: application/json
Authorization: {{token}}

{
    "name": "Inception Updated",
    "year": 2015,
    "rating": 8.0,
    "director": "Steven Spielberg"
}

###
# @name deleteMovie
DELETE {{baseUrl}}/movies/{{movieId}}
Authorization: {{token}}

###
# @name getNonExistentMovie
GET {{baseUrl}}/movies/999
Authorization: {{token}}


###
# @name deleteNonExistentMovie
DELETE {{baseUrl}}/movies/999
Authorization: {{token}}


================================================
FILE: tsconfig.jest.json
================================================
{
  "extends": "./tsconfig.json",
  "exclude": ["**/cypress.d.ts", "**/cypress", "**/*.cy.ts*"],
  "compilerOptions": {
    "types": ["@types/jest"]
  },
  "include": ["**/*.test.ts*", "**/*.pacttest.ts*"]
}



================================================
FILE: tsconfig.json
================================================
{
  "include": [
    "src",
    "./jest.config.ts",
    "./jest-pact.config.ts",
    "./.eslintrc.js",
    "cypress",
    "pw",
    "prisma"
  ],
  "exclude": ["node_modules", "coverage", "dist", "**/*.*test.ts*"],
  "compilerOptions": {
    /* Visit https://aka.ms/tsconfig to read more about this file */
    /* Projects */
    // "incremental": true,                              /* Save .tsbuildinfo files to allow for incremental compilation of projects. */
    // "composite": true,                                /* Enable constraints that allow a TypeScript project to be used with project references. */
    // "tsBuildInfoFile": "./.tsbuildinfo",              /* Specify the path to .tsbuildinfo incremental compilation file. */
    // "disableSourceOfProjectReferenceRedirect": true,  /* Disable preferring source files instead of declaration files when referencing composite projects. */
    // "disableSolutionSearching": true,                 /* Opt a project out of multi-project reference checking when editing. */
    // "disableReferencedProjectLoad": true,             /* Reduce the number of projects loaded automatically by TypeScript. */
    /* Language and Environment */
    "target": "es2022" /* Set the JavaScript language version for emitted JavaScript and include compatible library declarations. */,
    // "lib": [],                                        /* Specify a set of bundled library declaration files that describe the target runtime environment. */
    // "jsx": "preserve",                                /* Specify what JSX code is generated. */
    // "experimentalDecorators": true,                   /* Enable experimental support for TC39 stage 2 draft decorators. */
    // "emitDecoratorMetadata": true,                    /* Emit design-type metadata for decorated declarations in source files. */
    // "jsxFactory": "",                                 /* Specify the JSX factory function used when targeting React JSX emit, e.g. 'React.createElement' or 'h'. */
    // "jsxFragmentFactory": "",                         /* Specify the JSX Fragment reference used for fragments when targeting React JSX emit e.g. 'React.Fragment' or 'Fragment'. */
    // "jsxImportSource": "",                            /* Specify module specifier used to import the JSX factory functions when using 'jsx: react-jsx*'. */
    // "reactNamespace": "",                             /* Specify the object invoked for 'createElement'. This only applies when targeting 'react' JSX emit. */
    // "noLib": true,                                    /* Disable including any library files, including the default lib.d.ts. */
    // "useDefineForClassFields": true,                  /* Emit ECMAScript-standard-compliant class fields. */
    // "moduleDetection": "auto",                        /* Control what method is used to detect module-format JS files. */
    /* Modules */
    "module": "NodeNext" /* Specify what module code is generated. */,
    // "rootDir": "./",                                  /* Specify the root folder within your source files. */
    "moduleResolution": "NodeNext" /* Specify how TypeScript looks up a file from a given module specifier. */,
    // "baseUrl": "./",                                  /* Specify the base directory to resolve non-relative module names. */
    // "paths": {},                                      /* Specify a set of entries that re-map imports to additional lookup locations. */
    // "rootDirs": [],                                   /* Allow multiple folders to be treated as one when resolving modules. */
    // "typeRoots": [],                                  /* Specify multiple folders that act like './node_modules/@types'. */
    // "types": [],                                      /* Specify type package names to be included without being referenced in a source file. */
    // "allowUmdGlobalAccess": true,                     /* Allow accessing UMD globals from modules. */
    // "moduleSuffixes": [],                             /* List of file name suffixes to search when resolving a module. */
    "resolveJsonModule": true /* Enable importing .json files. */,
    // "allowImportingTsExtensions": true                /* Allow importing .ts files even when they cannot be resolved. */
    // "noResolve": true,                                /* Disallow 'import's, 'require's or '<reference>'s from expanding the number of files TypeScript should add to a project. */
    /* JavaScript Support */
    // "allowJs": true /* Allow JavaScript files to be a part of your program. Use the 'checkJS' option to get errors from these files. */,
    // "checkJs": true,                                  /* Enable error reporting in type-checked JavaScript files. */
    // "maxNodeModuleJsDepth": 1,                        /* Specify the maximum folder depth used for checking JavaScript files from 'node_modules'. Only applicable with 'allowJs'. */
    /* Emit */
    // "declaration": true,                              /* Generate .d.ts files from TypeScript and JavaScript files in your project. */
    // "declarationMap": true,                           /* Create sourcemaps for d.ts files. */
    // "emitDeclarationOnly": true,                      /* Only output d.ts files and not JavaScript files. */
    // "sourceMap": true,                                /* Create source map files for emitted JavaScript files. */
    // "outFile": "./",                                  /* Specify a file that bundles all outputs into one JavaScript file. If 'declaration' is true, also designates a file that bundles all .d.ts output. */
    // "outDir": "./",                                   /* Specify an output folder for all emitted files. */
    // "removeComments": true,                           /* Disable emitting comments. */
    "noEmit": true /* Disable emitting files from a compilation. */,
    // "importHelpers": true,                            /* Allow importing helper functions from tslib once per project, instead of including them per-file. */
    // "importsNotUsedAsValues": "remove",               /* Specify emit/checking behavior for imports that are only used for types. */
    // "downlevelIteration": true,                       /* Emit more compliant, but verbose and less performant JavaScript for iteration. */
    // "sourceRoot": "",                                 /* Specify the root path for debuggers to find the reference source code. */
    // "mapRoot": "",                                    /* Specify the location where debugger should locate map files instead of generated locations. */
    // "inlineSourceMap": true,                          /* Include sourcemap files inside the emitted JavaScript. */
    // "inlineSources": true,                            /* Include source code in the sourcemaps inside the emitted JavaScript. */
    // "emitBOM": true,                                  /* Emit a UTF-8 Byte Order Mark (BOM) in the beginning of output files. */
    // "newLine": "crlf",                                /* Set the newline character for emitting files. */
    // "stripInternal": true,                            /* Disable emitting declarations that have '@internal' in their JSDoc comments. */
    // "noEmitHelpers": true,                            /* Disable generating custom helper functions like '__extends' in compiled output. */
    // "noEmitOnError": true,                            /* Disable emitting files if any type checking errors are reported. */
    // "preserveConstEnums": true,                       /* Disable erasing 'const enum' declarations in generated code. */
    // "declarationDir": "./",                           /* Specify the output directory for generated declaration files. */
    // "preserveValueImports": true,                     /* Preserve unused imported values in the JavaScript output that would otherwise be removed. */
    /* Interop Constraints */
    // "isolatedModules": true,                          /* Ensure that each file can be safely transpiled without relying on other imports. */
    "allowSyntheticDefaultImports": true /* Allow 'import x from y' when a module doesn't have a default export. */,
    "esModuleInterop": true /* Emit additional JavaScript to ease support for importing CommonJS modules. This enables 'allowSyntheticDefaultImports' for type compatibility. */,
    // "preserveSymlinks": true,                         /* Disable resolving symlinks to their realpath. This correlates to the same flag in node. */
    "forceConsistentCasingInFileNames": true /* Ensure that casing is correct in imports. */,
    /* Type Checking */
    "strict": true /* Enable all strict type-checking options. */,
    // "noImplicitAny": true,                            /* Enable error reporting for expressions and declarations with an implied 'any' type. */
    "strictNullChecks": true /* When type checking, take into account 'null' and 'undefined'. */,
    "strictFunctionTypes": true /* When assigning functions, check to ensure parameters and the return values are subtype-compatible. */,
    // "strictBindCallApply": true,                      /* Check that the arguments for 'bind', 'call', and 'apply' methods match the original function. */
    // "strictPropertyInitialization": true,             /* Check for class properties that are declared but not set in the constructor. */
    // "noImplicitThis": true,                           /* Enable error reporting when 'this' is given the type 'any'. */
    // "useUnknownInCatchVariables": true,               /* Default catch clause variables as 'unknown' instead of 'any'. */
    // "alwaysStrict": true,                             /* Ensure 'use strict' is always emitted. */
    // "noUnusedLocals": true,                           /* Enable error reporting when local variables aren't read. */
    // "noUnusedParameters": true,                       /* Raise an error when a function parameter isn't read. */
    // "exactOptionalPropertyTypes": true /* Interpret optional property types as written, rather than adding 'undefined'. */,
    // "noImplicitReturns": true,                        /* Enable error reporting for codepaths that do not explicitly return in a function. */
    // "noFallthroughCasesInSwitch": true,               /* Enable error reporting for fallthrough cases in switch statements. */
    "noUncheckedIndexedAccess": true /* Add 'undefined' to a type when accessed using an index. */,
    // "noImplicitOverride": true,                       /* Ensure overriding members in derived classes are marked with an override modifier. */
    // "noPropertyAccessFromIndexSignature": true,       /* Enforces using indexed accessors for keys declared using an indexed type. */
    // "allowUnusedLabels": true,                        /* Disable error reporting for unused labels. */
    // "allowUnreachableCode": true,                     /* Disable error reporting for unreachable code. */
    /* Completeness */
    "skipDefaultLibCheck": true /* Skip type checking .d.ts files that are included with TypeScript. */,
    "skipLibCheck": true /* Skip type checking all .d.ts files. */
  }
}



================================================
FILE: wallaby.js
================================================
require('dotenv').config({ path: '.env' })

module.exports = function () {
  return {
    autoDetect: true,
    files: {
      override: (filePatterns) => [
        ...filePatterns,
        '!src/**/*.pacttest.ts' // Ignore pacttest.ts files
      ]
    },
    tests: {
      override: (testPatterns) => [
        ...testPatterns,
        '!src/**/*.pacttest.ts' // Ignore pacttest.ts files in tests
      ]
    }
  }
}



================================================
FILE: .env.example
================================================
# create a free pact broker at 
# https://pactflow.io/try-for-free/
PACT_BROKER_TOKEN=***********
PACT_BROKER_BASE_URL=https://yourownorg.pactflow.io

# This was inserted by `prisma init`:
# Environment variables declared in this file are automatically made available to Prisma.
# See the documentation for more detail: https://pris.ly/d/prisma-schema#accessing-environment-variables-from-the-schema

# Prisma supports the native connection string format for PostgreSQL, MySQL, SQLite, SQL Server, MongoDB and CockroachDB.
# See the documentation for all the connection string options: https://pris.ly/d/connection-strings

DATABASE_URL="file:./dev.db"
# the local server port to use
PORT=3001

# less Kafka noise
KAFKAJS_NO_PARTITIONER_WARNING=1
KAFKA_UI_URL=http://localhost:8085 # defined at src/events/kafka-cluster.yml L85, purely optional


================================================
FILE: .eslintignore
================================================
.eslintrc.js
wallaby.js



================================================
FILE: .eslintrc.js
================================================
module.exports = {
  env: {
    es2021: true,
    node: true
  },
  extends: [
    'eslint:recommended',
    'plugin:@typescript-eslint/recommended',
    'plugin:import/typescript',
    'plugin:import/recommended',
    'plugin:cypress/recommended',
    'plugin:prettier/recommended'
  ],
  parser: '@typescript-eslint/parser',
  parserOptions: {
    ecmaVersion: 'latest',
    sourceType: 'module',
    project: ['./tsconfig.json', './tsconfig.jest.json']
  },
  plugins: [
    '@typescript-eslint',
    'filenames',
    'implicit-dependencies',
    'no-only-tests'
  ],
  settings: {
    'import/resolver': {
      typescript: {}
    }
  },
  ignorePatterns: ['dist', 'node_modules', 'scripts'],
  root: true,
  rules: {
    '@typescript-eslint/consistent-type-imports': 'error',
    '@typescript-eslint/consistent-type-exports': 'error',
    '@typescript-eslint/no-floating-promises': 'error',
    '@typescript-eslint/await-thenable': 'error',
    'no-only-tests/no-only-tests': 'error',
    '@typescript-eslint/no-unused-vars': ['error', { argsIgnorePattern: '^_' }],
    'filenames/match-regex': ['error', '^[a-z0-9-._\\[\\]]+$', true],
    complexity: ['warn', 15],
    'object-curly-spacing': ['error', 'always'],
    'linebreak-style': ['error', 'unix'],
    quotes: ['error', 'single'],
    semi: ['error', 'never'],
    'import/default': 'off'
  }
}



================================================
FILE: .npmrc
================================================
registry=https://registry.npmjs.org


================================================
FILE: .nvmrc
================================================
22



================================================
FILE: .prettierignore
================================================
src/api-docs/openapi.json


================================================
FILE: .prettierrc
================================================
{
  "printWidth": 80,
  "trailingComma": "none",
  "tabWidth": 2,
  "semi": false,
  "singleQuote": true
}



================================================
FILE: cypress/index.ts
================================================
/* eslint-disable @typescript-eslint/no-namespace */
import type { Movie } from '@prisma/client'
import type {
  UpdateMovieResponse,
  CreateMovieResponse,
  GetMovieResponse,
  DeleteMovieResponse
} from '../src/@types'
import type { OpenAPIV3_1 } from 'openapi-types'

export {}

declare global {
  namespace Cypress {
    interface Chainable<Subject> {
      /** Gets a list of movies
       * ```js
       * cy.getAllMovies(token)
       * ```
       */
      getAllMovies(
        token: string,
        allowedToFail?: boolean
      ): Chainable<Response<GetMovieResponse> & Messages>

      /** Gets a movie by id
       * ```js
       * cy.getMovieById(token, 1)
       * ```
       */
      getMovieById(
        token: string,
        id: number,
        allowedToFail?: boolean
      ): Chainable<Response<GetMovieResponse> & Messages>

      /** Gets a movie by name
       * ```js
       * cy.getMovieByName(token, 'The Great Gatsby')
       * ```
       */
      getMovieByName(
        token: string,
        name: string,
        allowedToFail?: boolean
      ): Chainable<Response<GetMovieResponse> & Messages>

      /** Creates a movie
       * ```js
       * cy.addMovie({name: 'The Great Gatsby', year: 1925  })
       * ```
       */
      addMovie(
        token: string,
        body: Omit<Movie, 'id'>,
        allowedToFail?: boolean
      ): Chainable<Response<CreateMovieResponse> & Messages>

      /** Updates a movie by id
       * ```js
       * cy.updateMovie(1, {name: 'The Great Gatsby Updated'})
       * ```
       */
      updateMovie(
        token: string,
        id: number,
        body: Partial<Movie>
      ): Chainable<Response<UpdateMovieResponse> & Messages>

      /** Deletes a movie
       * ```js
       * cy.deleteMovie(1)
       * ```
       */
      deleteMovie(
        token: string,
        id: number,
        allowedToFail?: boolean
      ): Chainable<Response<DeleteMovieResponse> & Messages>

      /**
       * Validates the response body against the provided schema.
       *
       * @param schema - OpenAPI schema object to validate against.
       * @param options - Endpoint and method information for the schema, with optional path and status.
       *
       * @example
       * ```js
       * cy.validateSchema(schema, {
       *   endpoint: '/movies',
       *   method: 'POST'
       * })
       * ```
       *
       * You can optionally specify `path` and `status`:
       *
       * @example
       * ```js
       * cy.validateSchema(schema, {
       *   endpoint: '/movies',
       *   method: 'POST',
       *   status: 201 // Defaults to 200 if not provided
       * })
       * ``` */
      validateSchema(
        schema: OpenAPIV3_1.Document,
        options: {
          path?: string
          endpoint: string
          method: string
          status?: string | number
        }
      ): Chainable<Subject>

      /** If the token exists, reuse it
       * If no token exists, gets a token. */
      maybeGetToken(sessionName: string): Chainable<string>

      /** https://www.npmjs.com/package/@cypress/skip-test
       * `cy.skipOn('localhost')` */
      skipOn(
        nameOrFlag: string | boolean | (() => boolean),
        cb?: () => void
      ): Chainable<Subject>

      /** https://www.npmjs.com/package/@cypress/skip-test
       * `cy.onlyOn('localhost')` */
      onlyOn(
        nameOrFlag: string | boolean | (() => boolean),
        cb?: () => void
      ): Chainable<Subject>
    }
  }
}



================================================
FILE: cypress/tsconfig.json
================================================
{
  "compilerOptions": {
    "target": "esnext",
    "lib": ["esnext", "dom"],
    "types": ["cypress", "node", "@bahmutov/cy-api", "cypress-data-session"],
    "allowJs": true,
    "resolveJsonModule": true
  },
  "include": ["**/*.ts", "./index.ts", "../src/test-helpers/factories.ts"],
  "extends": "../tsconfig.json"
}



================================================
FILE: cypress/verification-result.txt
================================================
All Cypress tests passed.



================================================
FILE: cypress/config/base.config.ts
================================================
import plugins from '../support/plugins'
import tasks from '../support/tasks'
import esbuildPreprocessor from '../support/esbuild-preprocessor'

export const baseConfig: Cypress.ConfigOptions = {
  projectId: 'tmfkwa',
  viewportHeight: 1280,
  viewportWidth: 1280,

  e2e: {
    setupNodeEvents(on, config) {
      esbuildPreprocessor(on)
      tasks(on)
      return plugins(on, config)
    }
  }
}



================================================
FILE: cypress/config/local.config.ts
================================================
/* eslint-disable @typescript-eslint/no-var-requires */
import { defineConfig } from 'cypress'
import { baseConfig } from './base.config'
import path from 'node:path'
import merge from 'lodash/merge'
import { config as dotenvConfig } from 'dotenv'

dotenvConfig({
  path: path.resolve(__dirname, '../../.env')
})

// for Optic capture: running e2e against openapi spec for api coverage
const BASE_URL =
  process.env.OPTIC_PROXY || `http://localhost:${process.env.PORT}`

const config = {
  e2e: {
    env: {
      ENVIRONMENT: 'local',
      enableMismatchesOnUI: true,
      // disableSchemaValidation: true,
      KAFKA_UI_URL: 'http://localhost:8085' // defined at src/events/kafka-cluster.yml L85, purely optional
    },
    baseUrl: BASE_URL
  }
}
export default defineConfig(merge({}, baseConfig, config))



================================================
FILE: cypress/e2e/crud-movie-event.cy.ts
================================================
import '@cypress/skip-test/support'
import 'cypress-ajv-schema-validator'

import type { Movie } from '@prisma/client'
import spok from 'cy-spok'
import jsonSchema from '../../src/api-docs/openapi.json'
import type { OpenAPIV3_1 } from 'openapi-types'
import { generateMovieWithoutId } from '../../src/test-helpers/factories'
import { parseKafkaEvent } from '../support/parse-kafka-event'
import { retryableBefore } from '../support/retryable-before'
import { recurse } from 'cypress-recurse'

// Cast the imported schema to the correct type
const schema: OpenAPIV3_1.Document = jsonSchema as OpenAPIV3_1.Document

describe('CRUD movie', () => {
  const movie = generateMovieWithoutId()
  const updatedMovie = generateMovieWithoutId()
  const movieProps: Omit<Movie, 'id'> = {
    name: spok.string,
    year: spok.number,
    rating: spok.number,
    director: spok.string
  }

  let token: string

  retryableBefore(() => {
    // if kafka UI is not running, skip the test
    cy.exec(
      `curl -s -o /dev/null -w "%{http_code}" ${Cypress.env('KAFKA_UI_URL')}`,
      {
        failOnNonZeroExit: false
      }
    ).then((res) => {
      cy.log('**npm run kafka:start to enable this test**')
      cy.skipOn(res.stdout !== '200')
    })

    cy.maybeGetToken('token-session').then((t) => {
      token = t
    })
  })

  it('should crud', () => {
    cy.addMovie(token, movie)
      .validateSchema(schema, {
        endpoint: '/movies',
        method: 'POST'
      })
      .its('body')
      .should(
        spok({
          status: 200,
          data: movieProps
        })
      )
      .its('data.id')
      .then((id) => {
        // this can work when setTimeout is 0, or if sync event, if longer than that, it will fail
        // parseKafkaEvent(id, 'movie-created').should(
        //   spok([
        //     {
        //       topic: 'movie-created',
        //       key: String(id),
        //       movie: { ...movieProps, id }
        //     }
        //   ])
        // )
        // in the real world, the events will take place asynchronously
        // unlike our naive file write check
        // therefore we have to assert things via recursive assertions
        recurse(
          () => parseKafkaEvent(id, 'movie-created'),
          spok([
            {
              topic: 'movie-created',
              key: String(id),
              movie: { ...movieProps, id }
            }
          ])
        )

        cy.getAllMovies(token)
          .validateSchema(schema, {
            endpoint: '/movies',
            method: 'GET'
          })
          .its('body')
          .should(
            spok({
              status: 200,
              // test an array of objects with spok
              data: (arr: Movie[]) =>
                arr.map(
                  spok({
                    id: spok.number,
                    ...movieProps
                  })
                )
            })
          )
          .findOne({ name: movie.name })

        cy.getMovieById(token, id)
          .validateSchema(schema, {
            endpoint: '/movies/{id}',
            method: 'GET'
          })
          .its('body')
          .should(
            spok({
              status: 200,
              data: {
                ...movieProps,
                id
              }
            })
          )
          .its('data.name')
          .then((name) => {
            cy.getMovieByName(token, name)
              .validateSchema(schema, {
                endpoint: '/movies',
                method: 'GET'
              })
              .its('body')
              .should(
                spok({
                  status: 200,
                  data: movieProps
                })
              )
          })

        cy.updateMovie(token, id, updatedMovie)
          .validateSchema(schema, {
            endpoint: '/movies/{id}',
            method: 'PUT',
            status: 200
          })
          .its('body')
          .should(
            spok({
              status: 200,
              data: {
                ...movieProps,
                id
              }
            })
          )

        recurse(
          () => parseKafkaEvent(id, 'movie-updated'),
          spok([
            {
              topic: 'movie-updated',
              key: String(id),
              movie: { ...movieProps, id }
            }
          ])
        )

        cy.deleteMovie(token, id)
          .validateSchema(schema, {
            endpoint: '/movies/{id}',
            method: 'DELETE',
            status: 200
          })
          .its('body')
          .should(
            spok({
              status: 200,
              message: `Movie ${id} has been deleted`
            })
          )

        recurse(
          () => parseKafkaEvent(id, 'movie-deleted'),
          spok([
            {
              topic: 'movie-deleted',
              key: String(id),
              movie: { id, ...movieProps }
            }
          ])
        )

        cy.getAllMovies(token).findOne({ name: movie.name }).should('not.exist')

        cy.log('**delete non existing movie**')
        cy.deleteMovie(token, id, true)
          .validateSchema(schema, {
            endpoint: '/movies/{id}',
            method: 'DELETE',
            status: 404
          })
          .its('body')
          .should(
            spok({
              status: 404,
              error: `Movie with ID ${id} not found`
            })
          )
      })
  })
})



================================================
FILE: cypress/e2e/crud-movie.cy.ts
================================================
import 'cypress-ajv-schema-validator'

import type { Movie } from '@prisma/client'
import { generateMovieWithoutId } from '../../src/test-helpers/factories'
import spok from 'cy-spok'
import jsonSchema from '../../src/api-docs/openapi.json'
import { retryableBefore } from '../support/retryable-before'
import type { OpenAPIV3_1 } from 'openapi-types'

// Cast the imported schema to the correct type
const schema: OpenAPIV3_1.Document = jsonSchema as OpenAPIV3_1.Document

describe('CRUD movie', () => {
  const movie = generateMovieWithoutId()
  const updatedMovie = generateMovieWithoutId()
  const movieProps: Omit<Movie, 'id'> = {
    name: spok.string,
    year: spok.number,
    rating: spok.number,
    director: spok.string
  }

  let token: string
  retryableBefore(() => {
    cy.maybeGetToken('token-session').then((t) => {
      token = t
    })
  })

  it('should crud', () => {
    cy.addMovie(token, movie)
      .validateSchema(schema, {
        endpoint: '/movies',
        method: 'POST'
      })
      .its('body')
      .should(
        spok({
          status: 200,
          data: movieProps
        })
      )
      .its('data.id')
      .then((id) => {
        cy.getAllMovies(token)
          .validateSchema(schema, {
            endpoint: '/movies',
            method: 'GET'
          })
          .its('body')
          .should(
            spok({
              status: 200,
              // test an array of objects with spok
              data: (arr: Movie[]) =>
                arr.map(
                  spok({
                    id: spok.number,
                    ...movieProps
                  })
                )
            })
          )
          .findOne({ name: movie.name })

        cy.getMovieById(token, id)
          .validateSchema(schema, {
            endpoint: '/movies/{id}',
            method: 'GET'
          })
          .its('body')
          .should(
            spok({
              status: 200,
              data: {
                ...movieProps,
                id
              }
            })
          )
          .its('data.name')
          .then((name) => {
            cy.getMovieByName(token, name)
              .validateSchema(schema, {
                endpoint: '/movies',
                method: 'GET'
              })
              .its('body')
              .should(
                spok({
                  status: 200,
                  data: movieProps
                })
              )
          })

        cy.updateMovie(token, id, updatedMovie)
          .tap()
          .validateSchema(schema, {
            endpoint: '/movies/{id}',
            method: 'PUT',
            status: 200
          })
          .its('body')
          .should(
            spok({
              status: 200,
              data: {
                ...movieProps,
                id
              }
            })
          )

        cy.deleteMovie(token, id)
          .validateSchema(schema, {
            endpoint: '/movies/{id}',
            method: 'DELETE',
            status: 200
          })
          .its('body')
          .should(
            spok({
              status: 200,
              message: spok.string
            })
          )

        cy.getAllMovies(token).findOne({ name: movie.name }).should('not.exist')

        cy.log('**delete non existing movie**')
        cy.deleteMovie(token, id, true)
          .validateSchema(schema, {
            endpoint: '/movies/{id}',
            method: 'DELETE',
            status: 404
          })
          .its('body')
          .should(
            spok({
              status: 404,
              error: `Movie with ID ${id} not found`
            })
          )
      })
  })
})



================================================
FILE: cypress/fixtures/example.json
================================================
{
  "name": "Using fixtures to represent data",
  "email": "hello@cypress.io",
  "body": "Fixtures are a great way to mock data for responses to routes"
}



================================================
FILE: cypress/support/commands.ts
================================================
[Empty file]


================================================
FILE: cypress/support/e2e.ts
================================================
import './commands'
import './get-token'
import 'cypress-map'
import '@bahmutov/cy-api'
import type { Movie } from '@prisma/client'

const commonHeaders = (token: string) => ({
  Authorization: token
})

Cypress.Commands.add('getAllMovies', (token: string, allowedToFail = false) => {
  cy.log('**getAllMovies**')
  return cy.api({
    method: 'GET',
    url: '/movies',
    headers: commonHeaders(token),
    retryOnStatusCodeFailure: !allowedToFail,
    failOnStatusCode: !allowedToFail
  })
})

Cypress.Commands.add(
  'getMovieById',
  (token: string, id: number, allowedToFail = false) => {
    cy.log(`**getMovieById: ${id}**`)
    return cy.api({
      method: 'GET',
      url: `/movies/${id}`,
      headers: commonHeaders(token),
      retryOnStatusCodeFailure: !allowedToFail,
      failOnStatusCode: !allowedToFail
    })
  }
)

Cypress.Commands.add(
  'getMovieByName',
  (token: string, name: string, allowedToFail = false) => {
    cy.log(`**getMovieByName: ${name}**`)
    return cy.api({
      method: 'GET',
      url: '/movies',
      qs: { name },
      headers: commonHeaders(token),
      retryOnStatusCodeFailure: !allowedToFail,
      failOnStatusCode: !allowedToFail
    })
  }
)

Cypress.Commands.add(
  'addMovie',
  (token: string, body: Omit<Movie, 'id'>, allowedToFail = false) => {
    cy.log('**addMovie**')
    return cy.api({
      method: 'POST',
      url: '/movies',
      body,
      headers: commonHeaders(token),
      retryOnStatusCodeFailure: !allowedToFail,
      failOnStatusCode: !allowedToFail
    })
  }
)

Cypress.Commands.add(
  'updateMovie',
  (token: string, id: number, body: Partial<Movie>, allowedToFail = false) => {
    cy.log(`**updateMovie by id: ${id}**`)
    return cy.api({
      method: 'PUT',
      url: `/movies/${id}`,
      body,
      headers: commonHeaders(token),
      retryOnStatusCodeFailure: !allowedToFail,
      failOnStatusCode: !allowedToFail
    })
  }
)

Cypress.Commands.add(
  'deleteMovie',
  (token: string, id: number, allowedToFail = false) => {
    cy.log('**deleteMovie by id: ${id}**')
    return cy.api({
      method: 'DELETE',
      url: `/movies/${id}`,
      headers: commonHeaders(token),
      retryOnStatusCodeFailure: !allowedToFail,
      failOnStatusCode: !allowedToFail
    })
  }
)



================================================
FILE: cypress/support/esbuild-preprocessor.ts
================================================
import createBundler from '@bahmutov/cypress-esbuild-preprocessor'
import { NodeGlobalsPolyfillPlugin } from '@esbuild-plugins/node-globals-polyfill'
import { NodeModulesPolyfillPlugin } from '@esbuild-plugins/node-modules-polyfill'

export default function tasks(on: Cypress.PluginEvents) {
  on(
    'file:preprocessor',
    createBundler({
      plugins: [
        NodeModulesPolyfillPlugin(),
        NodeGlobalsPolyfillPlugin({
          process: true,
          buffer: true
        })
      ]
    })
  )
}



================================================
FILE: cypress/support/get-token.ts
================================================
import 'cypress-data-session'

const getToken = () =>
  cy
    .api({
      method: 'GET',
      url: '/auth/fake-token'
    })
    .its('body.token')

const maybeGetToken = (sessionName: string) =>
  cy.dataSession({
    name: sessionName,

    validate: () => true,

    setup: getToken,

    shareAcrossSpecs: true
  })
Cypress.Commands.add('maybeGetToken', maybeGetToken)



================================================
FILE: cypress/support/log.ts
================================================
// an example task that logs to the CLI console
// cy.task('log', 'e2e sanity passed')

const log = (x: string) => {
  console.log(x)

  return null
}

export default log



================================================
FILE: cypress/support/parse-kafka-event.ts
================================================
// all Kafka events are logged to a file, so we can somewhat verify them
// in the real world, you might check db, other services, or any other external side effects

import type { MovieEvent, MovieAction } from '../../src/@types'
import { logFilePath } from '../../src/events/log-file-path'

/**
 * Reshapes the Kafka event entry into a simplified format for easier processing.
 *
 * @param {MovieEvent} entry - The Kafka event entry containing topic and message details.
 * @returns {{topic: string, key: string, movie: Movie}} - Returns a simplified object with the topic, key, and movie details.
 */
const reshape = (entry: MovieEvent) => ({
  topic: entry.topic,
  key: entry.messages[0]?.key,
  movie: JSON.parse(entry.messages[0]?.value as unknown as string)
})

/**
 * Curried filter function to filter by topic and movieId
 *
 * @param {number} movieId - The ID of the movie to filter by.
 * @param {string} topic - The Kafka topic to filter by.
 * @returns {(entries: Array<ReturnType<typeof reshape>>) => Array} - A function that filters entries based on the topic and movieId.
 */
const filterByTopicAndId =
  (movieId: number, topic: string) => (entries: ReturnType<typeof reshape>[]) =>
    entries.filter(
      (entry) => entry.topic === topic && entry.movie?.id === movieId
    )

/**
 * Parses the Kafka event log file and filters events based on the topic and movieId.
 *
 * @param {number} movieId - The ID of the movie to filter for.
 * @param {MovieAction} topic - The Kafka topic to filter by.
 * @param {string} [filePath=logFilePath] - Optional file path for the Kafka event log file.
 * @returns {Cypress.Chainable} - A Cypress chainable that resolves to the first matching event.
 */
export const parseKafkaEvent = (
  movieId: number,
  topic: `movie-${MovieAction}`,
  filePath = logFilePath
) =>
  cy
    .print('parsing Kafka events..')
    .readFile(filePath)
    .invoke('trim')
    .invoke('split', '\n')
    .map(JSON.parse)
    .map(reshape)
    .apply(filterByTopicAndId(movieId, topic))



================================================
FILE: cypress/support/plugins.ts
================================================
// eslint-disable-next-line @typescript-eslint/no-require-imports
const cyDataSession = require('cypress-data-session/src/plugin')

/**
 * The collection of plugins to use with Cypress
 * @param on  `on` is used to hook into various events Cypress emits
 * @param config  `config` is the resolved Cypress config
 */
export default function plugins(
  on: Cypress.PluginEvents,
  config: Cypress.PluginConfigOptions
) {
  return {
    // add plugins here
    ...cyDataSession(on, config)
  }
}



================================================
FILE: cypress/support/retryable-before.ts
================================================
/**
 * A `before()` alternative that gets run when a failing test is retried.
 *
 * By default cypress `before()` isn't run when a test below it fails
 * and is retried. Because we use `before()` as a place to setup state
 * before running assertions inside `it()` this means we can't make use
 * of cypress retry functionality to make our suites more reliable.
 *
 * https://github.com/cypress-io/cypress/issues/19458
 * https://stackoverflow.com/questions/71285827/cypress-e2e-before-hook-not-working-on-retries
 */
export const retryableBefore = (fn: () => void) => {
  let shouldRun = true

  // we use beforeEach as cypress will run this on retry attempt
  // we just abort early if we detected that it's already run
  beforeEach(() => {
    if (!shouldRun) return
    shouldRun = false
    fn()
  })

  // When a test fails we flip the `shouldRun` flag back to true
  // so when cypress retries and runs the `beforeEach()` before
  // the test that failed, we'll run the `fn()` logic once more.
  Cypress.on('test:after:run', (result) => {
    if (result.state === 'failed') {
      if (result.currentRetry < result.retries) {
        shouldRun = true
      }
    }
  })
}



================================================
FILE: cypress/support/tasks.ts
================================================
import log from './log'

/**
 * The collection of tasks to use with `cy.task()`
 * @param on `on` is used to hook into various events Cypress emits
 */
export default function tasks(on: Cypress.PluginEvents) {
  on('task', { log })
}



================================================
FILE: prisma/client.ts
================================================
import { PrismaClient } from '@prisma/client'

const globalForPrisma = global as unknown as {
  prisma: PrismaClient | undefined
}

export const prisma =
  globalForPrisma.prisma ??
  new PrismaClient({
    log: ['query']
  })

if (process.env.NODE_ENV !== 'production') globalForPrisma.prisma = prisma

// Prisma notes
/*
To connect our applications to a database, we often use an Object-relational
Mapper (ORM). An ORM is a tool that sits between a database and an application.
It’s responsible for mapping database records to objects in an application.
Prisma is the most widely-used ORM for Next.js (or Node.js) applications.

1. **Define Models**: To use Prisma, first we have to define our data models.
   These are entities that represent our application domain, such as User,
   Order, Customer, etc. Each model has one or more fields (or properties).

 `npx prisma init` , and then at `./prisma/schema.prisma` create your models.

> We want to match these with our Zod types, ex: `./app/api/users/schema.ts`, `./app/api/products/schema.ts`

2. **Create migration file**: Once we create a model, we use Prisma CLI to
   create a migration file. A migration file contains instructions to generate
   or update database tables to match our models. These instructions are in SQL
   language, which is the language database engines understand.

 `npx prisma migrate dev`

3. **Create a Prisma client**: To connect with a database, we create an instance
   of PrismaClient. This client object gets automatically generated whenever we
   create a new migration. It exposes properties that represent our models (eg
   user).

 At `./prisma/client.ts` copy paste this code

```ts
import {PrismaClient} from '@prisma/client'

const globalForPrisma = global as unknown as {
  prisma: PrismaClient | undefined
}

export const prisma =
  globalForPrisma.prisma ??
  new PrismaClient({
    log: ['query'],
  })

if (process.env.NODE_ENV !== 'production') globalForPrisma.prisma = prisma
*/



================================================
FILE: prisma/schema.prisma
================================================
// if this file changes
// npm run db:migrate
// npm run db:sync
// npm run reset:db

generator client {
  provider = "prisma-client-js"
}

datasource db {
  provider = "sqlite"
  url      = env("DATABASE_URL")
}

model Movie {
  id       Int    @id @default(autoincrement())
  name     String
  year     Int
  rating   Float
  director String
}



================================================
FILE: prisma/migrations/migration_lock.toml
================================================
# Please do not edit this file manually
# It should be added in your version-control system (i.e. Git)
provider = "sqlite"


================================================
FILE: prisma/migrations/20240903112501_initial_setup/migration.sql
================================================
-- CreateTable
CREATE TABLE "Movie" (
    "id" INTEGER NOT NULL PRIMARY KEY AUTOINCREMENT,
    "name" TEXT NOT NULL,
    "year" INTEGER NOT NULL
);



================================================
FILE: pw/config/base.config.ts
================================================
import { defineConfig, devices } from '@playwright/test'
import { getStorageStatePath } from '../support/auth'

export const baseConfig = defineConfig({
  testDir: '../e2e',
  testMatch: '**/*.spec.ts',
  fullyParallel: true,
  forbidOnly: !!process.env.CI,
  retries: process.env.CI ? 3 : 2,
  workers: process.env.CI ? 1 : undefined,
  reporter: process.env.CI
    ? 'html'
    : process.env.PW_HTML_REPORT
      ? [['list'], ['html']]
      : 'list',
  globalSetup: '../support/global-setup.ts',
  use: {
    trace: 'retain-on-first-failure',
    // Set the storage state path for all tests
    storageState: getStorageStatePath()
  },
  projects: [
    {
      name: 'chromium',
      use: { ...devices['Desktop Chrome'] }
    }
  ]
})



================================================
FILE: pw/config/playwright-local.config.ts
================================================
import { baseConfig } from './base.config'
import merge from 'lodash/merge'
import { config as dotenvConfig } from 'dotenv'
import path from 'node:path'

dotenvConfig({
  path: path.resolve(__dirname, '../../.env')
})

const BASE_URL = `http://localhost:${process.env.PORT}`

export default merge({}, baseConfig, {
  // Required: enable global setup to initialize auth configuration
  globalSetup: '../support/global-setup.ts',

  use: {
    baseURL: BASE_URL
  },
  webServer: {
    command: 'npm run start',
    url: BASE_URL,
    reuseExistingServer: !process.env.CI,
    stdout: 'pipe'
  }
})



================================================
FILE: pw/e2e/auth-session-example.spec.ts
================================================
import { clearAuthToken } from '../support/auth'
import { test, expect } from '../support/fixtures'

/**
 * This test demonstrates how auth sessions work:
 * - The first test gets a token using the authToken fixture
 * - The second test reuses the same token without making another request
 * - The session is preserved across test runs as well
 */
test.describe('Auth Session Example', () => {
  // This test just demonstrates that we get a token
  test('should have auth token available', async ({ authToken }) => {
    // Token is already obtained via the fixture
    expect(authToken).toBeDefined()
    expect(typeof authToken).toBe('string')
    expect(authToken.length).toBeGreaterThan(0)

    console.log('Token is available in first test without explicit fetching')
  })

  // This test will reuse the same token without making another request
  test('should reuse the same auth token', async ({
    authToken,
    apiRequest
  }) => {
    // The token is already available without making a new request
    expect(authToken).toBeDefined()
    expect(typeof authToken).toBe('string')

    // We can use the token for API requests
    const { status } = await apiRequest({
      method: 'GET',
      url: '/movies',
      headers: {
        Authorization: authToken // Use the token directly as the CRUD helpers do
      }
    })

    expect(status).toBe(200)
    console.log('Second test reuses the same token without fetching it again')
  })

  // This test demonstrates how to manually clear the token
  test('can manually clear the token if needed', async () => {
    // Clear the token - this will cause the next test to fetch a new one
    clearAuthToken()
    console.log('Token cleared - next test will fetch a new one')
  })
})



================================================
FILE: pw/e2e/crud-movie-event.spec.ts
================================================
import { test, expect } from '../support/fixtures'
import { runCommand } from '../support/utils/run-command'
import { generateMovieWithoutId } from '../../src/test-helpers/factories'
import { parseKafkaEvent } from '../support/parse-kafka-event'
import { recurseWithExpect } from '../support/utils/recurse-with-expect'
import type { Movie } from '@prisma/client'

test.describe('CRUD movie', () => {
  const movie = generateMovieWithoutId()
  const updatedMovie = generateMovieWithoutId()

  const movieProps: Omit<Movie, 'id'> = {
    name: movie.name,
    year: movie.year,
    rating: movie.rating,
    director: movie.director
  }

  const movieEventProps = {
    name: expect.any(String),
    year: expect.any(Number),
    rating: expect.any(Number),
    director: expect.any(String)
  }

  test.beforeAll(() => {
    const responseCode = runCommand(
      `curl -s -o /dev/null -w "%{http_code}" ${process.env.KAFKA_UI_URL}`
    )
    if (responseCode !== '200') {
      test.skip()
    }
  })

  test('should crud', async ({
    addMovie,
    getAllMovies,
    getMovieById,
    getMovieByName,
    updateMovie,
    deleteMovie,
    authToken
  }) => {
    // Add a movie
    const { body: createResponse, status: createStatus } = await addMovie(
      authToken,
      movie
    )
    const movieId = createResponse.data.id

    expect(createStatus).toBe(200)
    expect(createResponse).toMatchObject({
      status: 200,
      data: { ...movieProps, id: movieId }
    })

    // Wait for 'movie-created' Kafka event using recurseWithExpect
    await recurseWithExpect(
      async () => {
        const topic = 'movie-created'
        const event = await parseKafkaEvent(movieId, topic)

        // Perform assertions on the event content
        expect(event).toEqual([
          {
            topic,
            key: String(movieId),
            movie: {
              id: movieId,
              ...movieEventProps
            }
          }
        ])
      },
      { timeout: 10000, interval: 500 }
    )

    // Get all movies and verify that the movie exists
    const { body: getAllResponse, status: getAllStatus } =
      await getAllMovies(authToken)
    expect(getAllStatus).toBe(200)
    expect(getAllResponse).toMatchObject({
      status: 200,
      data: expect.arrayContaining([
        expect.objectContaining({ id: movieId, name: movie.name })
      ])
    })

    // Get the movie by ID
    const { body: getByIdResponse, status: getByIdStatus } = await getMovieById(
      authToken,
      movieId
    )
    expect(getByIdStatus).toBe(200)
    expect(getByIdResponse).toMatchObject({
      status: 200,
      data: { ...movieProps, id: movieId }
    })

    // Get the movie by name
    const { body: getByNameResponse, status: getByNameStatus } =
      await getMovieByName(authToken, movie.name)
    expect(getByNameStatus).toBe(200)
    expect(getByNameResponse).toMatchObject({
      status: 200,
      data: { ...movieProps, id: movieId }
    })

    // Update the movie
    const { body: updateResponse, status: updateStatus } = await updateMovie(
      authToken,
      movieId,
      updatedMovie
    )
    expect(updateStatus).toBe(200)
    expect(updateResponse).toMatchObject({
      status: 200,
      data: {
        id: movieId,
        name: updatedMovie.name,
        year: updatedMovie.year,
        rating: updatedMovie.rating,
        director: updatedMovie.director
      }
    })

    await recurseWithExpect(
      async () => {
        const topic = 'movie-updated'
        const event = await parseKafkaEvent(movieId, topic)

        // Perform assertions on the event content
        expect(event).toEqual([
          {
            topic,
            key: String(movieId),
            movie: {
              id: movieId,
              ...movieEventProps
            }
          }
        ])
      },
      { timeout: 10000, interval: 500 }
    )

    // Delete the movie
    const {
      status: deleteStatus,
      body: { message }
    } = await deleteMovie(authToken, movieId)
    expect(deleteStatus).toBe(200)
    expect(message).toBe(`Movie ${movieId} has been deleted`)

    await recurseWithExpect(
      async () => {
        const topic = 'movie-deleted'
        const event = await parseKafkaEvent(movieId, topic)

        // Perform assertions on the event content
        expect(event).toEqual([
          {
            topic,
            key: String(movieId),
            movie: {
              id: movieId,
              ...movieEventProps
            }
          }
        ])
      },
      { timeout: 10000, interval: 500 }
    )

    // Verify the movie no longer exists
    const { body: allMoviesAfterDelete } = await getAllMovies(authToken)
    expect(allMoviesAfterDelete).toMatchObject({
      status: 200,
      data: expect.not.arrayContaining([
        expect.objectContaining({ id: movieId })
      ])
    })

    // Attempt to delete the non-existing movie
    const { status: deleteNonExistentStatus, body: deleteNonExistentBody } =
      await deleteMovie(authToken, movieId)
    expect(deleteNonExistentStatus).toBe(404)
    expect(deleteNonExistentBody).toMatchObject({
      error: `Movie with ID ${movieId} not found`
    })
  })
})



================================================
FILE: pw/e2e/crud-movie.spec.ts
================================================
import { test, expect } from '../support/fixtures'
import { generateMovieWithoutId } from '../../src/test-helpers/factories'
import type { Movie } from '@prisma/client'

test.describe('CRUD movie', () => {
  const movie = generateMovieWithoutId()
  const updatedMovie = generateMovieWithoutId()

  const movieProps: Omit<Movie, 'id'> = {
    name: movie.name,
    year: movie.year,
    rating: movie.rating,
    director: movie.director
  }

  test('should crud', async ({
    addMovie,
    getAllMovies,
    getMovieById,
    getMovieByName,
    updateMovie,
    deleteMovie,
    authToken
  }) => {
    // Add a movie
    const { body: createResponse, status: createStatus } = await addMovie(
      authToken,
      movie
    )
    const movieId = createResponse.data.id

    expect(createStatus).toBe(200)
    expect(createResponse).toMatchObject({
      status: 200,
      data: { ...movieProps, id: movieId }
    })

    // Get all movies and verify that the movie exists
    const { body: getAllResponse, status: getAllStatus } =
      await getAllMovies(authToken)
    expect(getAllStatus).toBe(200)
    expect(getAllResponse).toMatchObject({
      status: 200,
      data: expect.arrayContaining([
        expect.objectContaining({ id: movieId, name: movie.name })
      ])
    })

    // Get the movie by ID
    const { body: getByIdResponse, status: getByIdStatus } = await getMovieById(
      authToken,
      movieId
    )

    expect(getByIdStatus).toBe(200)
    expect(getByIdResponse).toMatchObject({
      status: 200,
      data: { ...movieProps, id: movieId }
    })

    // Get the movie by name
    const { body: getByNameResponse, status: getByNameStatus } =
      await getMovieByName(authToken, movie.name)

    expect(getByNameStatus).toBe(200)
    expect(getByNameResponse).toMatchObject({
      status: 200,
      data: { ...movieProps, id: movieId }
    })

    // Update the movie
    const { body: updateResponse, status: updateStatus } = await updateMovie(
      authToken,
      movieId,
      updatedMovie
    )
    expect(updateStatus).toBe(200)
    expect(updateResponse).toMatchObject({
      status: 200,
      data: {
        name: updatedMovie.name,
        year: updatedMovie.year,
        rating: updatedMovie.rating,
        director: updatedMovie.director,
        id: movieId
      }
    })

    // Delete the movie
    const {
      status: deleteStatus,
      body: { message }
    } = await deleteMovie(authToken, movieId)
    expect(deleteStatus).toBe(200)
    expect(message).toBe(`Movie ${movieId} has been deleted`)

    // Verify the movie no longer exists
    const { body: allMoviesAfterDelete } = await getAllMovies(authToken)
    expect(allMoviesAfterDelete).toMatchObject({
      status: 200,
      data: expect.not.arrayContaining([
        expect.objectContaining({ id: movieId })
      ])
    })

    // Attempt to delete the non-existing movie
    const { status: deleteNonExistentStatus, body: deleteNonExistentBody } =
      await deleteMovie(authToken, movieId)
    expect(deleteNonExistentStatus).toBe(404)
    expect(deleteNonExistentBody).toMatchObject({
      error: `Movie with ID ${movieId} not found`
    })
  })
})



================================================
FILE: pw/e2e/get-token.spec.ts
================================================
import { test, expect } from '../support/fixtures'

test.describe('token acquisition', () => {
  test('should get a token', async ({ request }) => {
    const tokenRes = await request.get('/auth/fake-token')
    const tokenResBody = await tokenRes.json()
    const tokenResStatus = tokenRes.status()
    const token = tokenResBody.token

    expect(tokenResStatus).toBe(200)
    expect(token).toEqual(expect.any(String))
  })

  test('should get a token with helper', async ({ apiRequest }) => {
    const {
      body: { token },
      status
    } = await apiRequest<{ token: string }>({
      method: 'GET',
      url: '/auth/fake-token'
    })

    expect(status).toBe(200)
    expect(token).toEqual(expect.any(String))
  })
})



================================================
FILE: pw/support/custom-auth-provider.ts
================================================
/**
 * Example of a custom auth provider implementation
 *
 * This demonstrates how to create a fully custom authentication provider
 * that can handle specialized auth flows beyond the default implementation.
 *
 * The provider is now the source of truth for environment and role information.
 */
import { type AuthProvider } from './auth'
import * as fs from 'fs'
import {
  getTokenFilePath,
  authStorageInit
} from './auth/internal/auth-storage-utils'
import { loadTokenFromStorage, saveTokenToStorage } from './auth/core'
import { getAuthBaseUrl } from './auth/internal/url-utils'

/**
 * Utility function to get credentials for a specific user role using a functional approach
 * This is placed outside the auth provider object to maintain proper encapsulation
 * and follow functional programming principles
 */
// eslint-disable-next-line complexity
const getCredentialsForRole = (
  role: string
): { username: string; password: string } => {
  // Using a map pattern for role-based credentials instead of imperative conditionals
  const credentialMap: Record<string, { username: string; password: string }> =
    {
      admin: {
        username: process.env.ADMIN_USERNAME || 'admin@example.com',
        password: process.env.ADMIN_PASSWORD || 'admin123'
      },
      regular: {
        username: process.env.USER_USERNAME || 'user@example.com',
        password: process.env.USER_PASSWORD || 'user123'
      },
      guest: {
        username: process.env.GUEST_USERNAME || 'guest@example.com',
        password: process.env.GUEST_PASSWORD || 'guest123'
      },
      tester: {
        username: process.env.TESTER_USERNAME || 'tester@example.com',
        password: process.env.TESTER_PASSWORD || 'tester123'
      },
      readonly: {
        username: process.env.READONLY_USERNAME || 'readonly@example.com',
        password: process.env.READONLY_PASSWORD || 'readonly123'
      },
      default: {
        username: process.env.DEFAULT_USERNAME || 'default@example.com',
        password: process.env.DEFAULT_PASSWORD || 'default123'
      }
    }
  // Ensure we always return a valid credential object with functional fallback pattern
  return (
    credentialMap[role] ||
    credentialMap.default || {
      username: process.env.DEFAULT_USERNAME || 'default@example.com',
      password: process.env.DEFAULT_PASSWORD || 'default123'
    }
  )
}

// Create a fully custom provider implementation
const myCustomProvider: AuthProvider = {
  /**
   * Get the current environment to use
   */
  getEnvironment(options = {}) {
    // Environment priority:
    // 1. Options passed directly to this method
    // 2. Environment variables
    // 3. Default environment
    return options.environment || process.env.TEST_ENV || 'local'
  },
  /**
   * Get the current user role to use, with associated credentials
   */
  getUserRole(options = {}) {
    // Role priority:
    // 1. Options passed directly to this method
    // 2. Default role based on environment
    const environment = this.getEnvironment(options)
    // You could implement environment-specific default roles
    let defaultRole = 'regular' // Default role is 'regular' user
    if (environment === 'staging') defaultRole = 'tester'
    if (environment === 'production') defaultRole = 'readonly'
    return options.userRole || process.env.TEST_USER_ROLE || defaultRole
  },
  /**
   * Get authentication token using custom logic with multi-role support
   */
  // eslint-disable-next-line complexity
  async getToken(request, options = {}) {
    // Use our own methods to ensure consistency
    const environment = this.getEnvironment(options)
    const userRole = this.getUserRole(options)
    // Use the utility functions to get standardized paths
    const tokenPath = getTokenFilePath({
      environment,
      userRole,
      tokenFileName: 'custom-auth-token.json'
    })
    // Check if we already have a valid token using the core utility
    // Add custom logging for this provider implementation
    console.log(`[Custom Auth] Checking for existing token at ${tokenPath}`)
    const existingToken = loadTokenFromStorage(tokenPath, true)
    if (existingToken) {
      console.log(`[Custom Auth] Using existing token from ${tokenPath}`)
      return existingToken
    }
    // Initialize storage directories (in case you're not using authGlobalInit() in global-setup)
    authStorageInit({ environment, userRole })
    // Get a new token using our custom auth flow
    console.log(
      `[Custom Auth] Fetching new token for ${environment}/${userRole}`
    )
    // Use the authBaseUrl utility to get the environment-appropriate auth URL
    const authBaseUrl = getAuthBaseUrl({
      environment,
      authBaseUrl: options.authBaseUrl
    })
    // Get the endpoint (could also be environment-specific if needed)
    const endpoint = process.env.AUTH_TOKEN_ENDPOINT || '/token'
    const authUrl = `${authBaseUrl}${endpoint}`
    console.log(`[Custom Auth] Requesting token from ${authUrl}`)
    // Get immutable credentials object for the current role using our functional helper
    const credentials = getCredentialsForRole(userRole)
    // Make the authentication request with the appropriate credentials
    const response = await request.post(authUrl, {
      data: credentials,
      headers: {
        'Content-Type': 'application/json'
      }
    })
    // Extract token from response - customize based on your API response format
    const data = await response.json()
    const token = data.access_token || data.token || data.accessToken
    // Use the core utility to save the token with metadata
    // We turn on debug mode to get logging
    console.log(`[Custom Auth] Saving token to ${tokenPath}`)
    saveTokenToStorage(
      tokenPath,
      token,
      {
        environment,
        userRole,
        source: 'custom-provider'
      },
      true
    )
    return token
  },
  /**
   * Apply the token to a browser context for UI testing
   */
  async applyToBrowserContext(context, token, options = {}) {
    // Get environment for domain configuration
    const environment = this.getEnvironment(options)
    // Set domain based on environment
    const domain =
      environment === 'local' ? 'localhost' : `${environment}.example.com`
    // Log what we're doing
    console.log(
      `[Custom Auth] Applying token to browser context for ${environment}`
    )
    // Example: Set authentication cookie
    await context.addCookies([
      {
        name: 'auth_token',
        value: token,
        domain,
        path: '/',
        httpOnly: true,
        secure: environment !== 'local',
        sameSite: 'Lax'
      }
    ])
    // Example: Set localStorage (alternative auth method)
    await context.addInitScript(`
      localStorage.setItem('token', '${token}');
      console.log('[Custom Auth] Set token in localStorage');
    `)
    // You could also:
    // - Set headers for all requests
    // - Modify the page before it loads
    // - Inject scripts
  },
  /**
   * Clear token when needed
   */
  clearToken(options = {}) {
    // Use our own methods to ensure consistency
    const environment = this.getEnvironment(options)
    const userRole = this.getUserRole(options)
    // Use the utility function to get the token path - same as in getToken
    const tokenPath = getTokenFilePath({
      environment,
      userRole,
      tokenFileName: 'custom-auth-token.json'
    })
    // Delete the token file if it exists
    if (fs.existsSync(tokenPath)) {
      console.log(`[Custom Auth] Clearing token at ${tokenPath}`)
      fs.unlinkSync(tokenPath)
    }
  }
}
// Export for using in global setup
export default myCustomProvider



================================================
FILE: pw/support/fixtures.ts
================================================
import { test as base, mergeTests } from '@playwright/test'
import { test as apiRequestFixture } from './fixtures/api-request-fixture'
import { test as crudHelperFixtures } from './fixtures/crud-helper-fixture'
import { test as authFixture } from './fixtures/auth-fixture'

// Merge the fixtures
const test = mergeTests(apiRequestFixture, crudHelperFixtures, authFixture)

const expect = base.expect
export { test, expect }



================================================
FILE: pw/support/global-setup.ts
================================================
/**
 * Global setup script for Playwright testing
 *
 * This script handles initial setup tasks before tests run:
 * 1. Ensures storage directories exist for auth sessions
 * 2. Explicitly configures authentication using one of two approaches:
 *    - Default approach: configureAuthSession with token fetch options
 *    - Custom approach: Register a custom auth provider implementation
 *
 * To use this, add to your playwright config:
 * ```
 * globalSetup: '../support/global-setup.ts'
 * ```
 */

import {
  authStorageInit,
  setAuthProvider,
  configureAuthSession
  // authGlobalInit
} from './auth'

// Uncomment to use the custom auth provider
import myCustomProvider from './custom-auth-provider'

/**
 * Global setup function that runs before tests
 */
async function globalSetup() {
  console.log('Running global setup')

  // Ensure storage directories exist (required for both auth approaches)
  authStorageInit()

  // ========================================================================
  // STEP 1: Configure minimal auth storage settings
  // ========================================================================
  // This just sets up where tokens will be stored and debug options
  configureAuthSession({
    debug: true
  })

  // ========================================================================
  // STEP 2: Set up custom auth provider
  // ========================================================================
  // This defines HOW authentication tokens are acquired and used

  setAuthProvider(myCustomProvider)

  // Optional: pre-fetch all tokens in the beginning
  // await authGlobalInit()
}

export default globalSetup



================================================
FILE: pw/support/parse-kafka-event.ts
================================================
import { promises as fs } from 'fs'
import { logFilePath } from '../../src/events/log-file-path'
import type { MovieEvent, MovieAction } from '../../src/@types'

/**
 * Reshapes the Kafka event entry into a simplified format for easier processing.
 *
 * @param {MovieEvent} entry - The Kafka event entry containing topic and message details.
 * @returns {{ topic: string; key: string; movie: Movie }} - Returns a simplified object with the topic, key, and movie details.
 */
const reshape = (entry: MovieEvent) => ({
  topic: entry.topic,
  key: entry.messages[0]?.key,
  movie: JSON.parse(entry.messages[0]?.value as unknown as string)
})

/**
 * Filters Kafka event entries by topic and movieId.
 *
 * @param {number} movieId - The ID of the movie to filter by.
 * @param {string} topic - The Kafka topic to filter by.
 * @param {Array<ReturnType<typeof reshape>>} entries - The list of reshaped Kafka event entries.
 * @returns {Array} - Filtered entries based on the topic and movieId.
 */
const filterByTopicAndId = (
  movieId: number,
  topic: string,
  entries: ReturnType<typeof reshape>[]
) =>
  entries.filter(
    (entry) => entry.topic === topic && entry.movie?.id === movieId
  )

/**
 * Parses the Kafka event log file and filters events based on the topic and movieId.
 *
 * @param {number} movieId - The ID of the movie to filter for.
 * @param {`movie-${MovieAction}`} topic - The Kafka topic to filter by.
 * @param {string} [filePath=logFilePath] - Optional file path for the Kafka event log file.
 * @returns {Promise<Array>} - A promise that resolves to the matching events.
 */
export const parseKafkaEvent = async (
  movieId: number,
  topic: `movie-${MovieAction}`,
  filePath = logFilePath
) => {
  try {
    // Read and process the Kafka log file
    const fileContent = await fs.readFile(filePath, 'utf-8')
    const entries = fileContent
      .trim()
      .split('\n')
      .map((line) => JSON.parse(line))
      .map(reshape)

    // Filter the entries by topic and movie ID
    return filterByTopicAndId(movieId, topic, entries)
  } catch (error) {
    if (error instanceof Error) {
      console.error(`Error parsing Kafka event log: ${error.message}`)
    } else {
      console.error('An unknown error occurred')
    }
    throw error
  }
}



================================================
FILE: pw/support/auth/core.ts
================================================
/**
 * Core authentication functionality for the auth session library
 * This file consolidates and re-exports the public API from implementation files
 */
import type { APIRequestContext, BrowserContext } from '@playwright/test'
import type { AuthSessionOptions, AuthTokenData } from './internal/auth-types'
import { AuthSessionManager } from './internal/auth-session'
import {
  configureAuthSession as configureAuth,
  getGlobalAuthOptions
} from './internal/auth-configure'
import { getStorageStatePath } from './internal/auth-storage-utils'
import * as fs from 'fs'
import * as path from 'path'

// Re-export the default token formatter
export { defaultTokenFormatter } from './internal/auth-session'

/**
 * Load a token from storage if one exists
 * Handles token expiration checking
 *
 * @param tokenPath Path to the token file
 * @param debug Whether to log debug information
 * @returns The token if valid, or null if not found or expired
 */
export function loadTokenFromStorage(
  tokenPath: string,
  debug = false
): string | null {
  if (fs.existsSync(tokenPath)) {
    try {
      const data = fs.readFileSync(tokenPath, 'utf8')
      const tokenData = JSON.parse(data) as AuthTokenData

      // Check if token is expired
      if (tokenData.expiresAt && new Date(tokenData.expiresAt) < new Date()) {
        if (debug) {
          console.log(
            `Token expired at ${tokenData.expiresAt}, will fetch new one`
          )
        }
        return null
      }

      if (debug) {
        console.log(`Loaded token from ${tokenPath}`)
      }

      return tokenData.token
    } catch (error) {
      console.error(`Error loading token from ${tokenPath}:`, error)
      return null
    }
  }
  return null
}

/**
 * Save a token to storage with optional metadata
 * Ensures the storage directory exists
 *
 * @param tokenPath Path to save the token file
 * @param token The token string to save
 * @param metadata Additional metadata to store with the token
 * @param debug Whether to log debug information
 */
export function saveTokenToStorage(
  tokenPath: string,
  token: string,
  metadata: Record<string, unknown> = {},
  debug = false
): void {
  try {
    const storageDir = path.dirname(tokenPath)

    // Ensure the storage directory exists
    if (!fs.existsSync(storageDir)) {
      fs.mkdirSync(storageDir, { recursive: true })
      if (debug) {
        console.log(`Created directory ${storageDir} for token storage`)
      }
    }

    // Save token with metadata
    fs.writeFileSync(
      tokenPath,
      JSON.stringify(
        {
          token,
          createdAt: new Date().toISOString(),
          ...metadata
        },
        null,
        2
      )
    )

    if (debug) {
      console.log(`Saved token to ${tokenPath}`)
    }
  } catch (error) {
    console.error(`Error saving token to ${tokenPath}:`, error)
  }
}

/**
 * Configure the authentication session with the provided options
 * This is the main entry point for setting up the auth system
 */
export function configureAuthSession(options: AuthSessionOptions): void {
  configureAuth(options)
}

/**
 * Get an authentication token, fetching a new one if needed
 * @param request The Playwright APIRequestContext
 * @param options Optional environment and user role overrides
 * @returns A promise that resolves to the authentication token
 */
export async function getAuthToken(
  request: APIRequestContext,
  options?: { environment?: string; userRole?: string }
): Promise<string> {
  // Get global auth options
  const globalOptions = getGlobalAuthOptions()
  if (!globalOptions) {
    throw new Error(
      'Auth session not configured. Call configureAuthSession first.'
    )
  }

  // Create a full options object by combining global options with the provided options
  const fullOptions: AuthSessionOptions = {
    ...globalOptions,
    ...options
  }

  // Get the auth manager with combined options and fetch token
  const authManager = AuthSessionManager.getInstance(fullOptions)
  return authManager.getToken(request)
}

/**
 * Clear the authentication token from storage
 * @param options Optional environment and user role overrides
 */
export function clearAuthToken(options?: {
  environment?: string
  userRole?: string
}): void {
  // Get global auth options
  const globalOptions = getGlobalAuthOptions()
  if (!globalOptions) {
    throw new Error(
      'Auth session not configured. Call configureAuthSession first.'
    )
  }

  // Create full options with correct environment/role
  const fullOptions: AuthSessionOptions = {
    ...globalOptions,
    ...options
  }

  // Get the auth manager with the right options
  const authManager = AuthSessionManager.getInstance(fullOptions)
  authManager.clearToken()
}

/**
 * Apply the authentication token to a browser context for UI testing
 * @param context The Playwright BrowserContext
 * @param token The authentication token to apply
 * @param options Optional environment and user role overrides
 * @returns A promise that resolves when the token has been applied
 */
export function applyAuthToBrowserContext(
  context: BrowserContext,
  token: string,
  options?: { environment?: string; userRole?: string }
): Promise<void> {
  // Get global auth options
  const globalOptions = getGlobalAuthOptions()
  if (!globalOptions) {
    throw new Error(
      'Auth session not configured. Call configureAuthSession first.'
    )
  }

  // Get storage state path based on environment and role from options
  // Extract just the environment and userRole properties that getStorageStatePath expects
  const storageOptions = options || {}
  const statePath = getStorageStatePath(storageOptions)

  // Save the current state
  return context.storageState({ path: statePath }).then(() => {
    // Add the auth token to localStorage
    return context.addInitScript((token) => {
      // Store token in localStorage
      window.localStorage.setItem('authToken', token)
    }, token)
  })
}



================================================
FILE: pw/support/auth/global-setup-helper.ts
================================================
/**
 * Global setup helper for Playwright Auth Session
 * Provides utilities for initializing authentication in global setup
 */
import type { APIRequestContext } from '@playwright/test'
import { getAuthToken } from './core'

/**
 * Initialize authentication token during Playwright's global setup.
 * This helper simplifies the integration into the globalSetup function.
 *
 * @param request - Playwright APIRequestContext for making API calls
 * @param options - Optional environment and user role settings
 * @returns Promise that resolves when auth initialization is complete
 */
export async function initializeAuthForGlobalSetup(
  request: APIRequestContext,
  options?: { environment?: string; userRole?: string }
): Promise<void> {
  console.log('Initializing auth token')

  try {
    // Fetch and store the token
    await getAuthToken(request, options)
    console.log('Auth token initialized successfully')
    // Function returns void, no need to return the token
  } catch (error) {
    console.error('Failed to initialize auth token:', error)
    throw error
  }
}



================================================
FILE: pw/support/auth/index.ts
================================================
/**
 * Playwright Auth Session Library
 * A reusable authentication session management system for Playwright
 */

// Public Types
export type {
  AuthTokenData,
  TokenDataFormatter,
  AuthSessionOptions,
  TokenFetchOptions,
  AuthOptions,
  AuthFixtures
} from './internal/auth-types'

// Core API functions
export {
  configureAuthSession,
  getAuthToken,
  clearAuthToken,
  applyAuthToBrowserContext,
  defaultTokenFormatter,
  // Token utility functions
  loadTokenFromStorage,
  saveTokenToStorage
} from './core'

// Global setup helper (optional)
export { initializeAuthForGlobalSetup } from './global-setup-helper'

// Storage utilities
export { getStorageStatePath } from './internal/auth-storage-utils'

// URL utilities
export { getBaseUrl, getAuthBaseUrl } from './internal/url-utils'

// Global initialization utilities
export { authStorageInit, authGlobalInit } from './internal/auth-global-setup'

// Auth Provider API
export {
  type AuthProvider,
  setAuthProvider,
  getAuthProvider
} from './internal/auth-provider'

// Test fixtures
export { createAuthFixtures, createRoleSpecificTest } from './test-fixtures'



================================================
FILE: pw/support/auth/test-fixtures.ts
================================================
/* eslint-disable @typescript-eslint/no-explicit-any */
/**
 * Playwright Auth Session Test Fixtures
 * Provides factory functions to create test fixtures for authentication
 */

import {
  type BrowserContext,
  type Page,
  type APIRequestContext
} from '@playwright/test'
import { getAuthProvider } from './internal/auth-provider'
import { getStorageStatePath } from './internal/auth-storage-utils'
import { getBaseUrl } from './internal/url-utils'
import { type AuthOptions } from './internal/auth-types'

/**
 * Creates auth fixtures that can be used to extend Playwright's test object
 * @returns An object with fixtures that can be used with test.extend()
 */
export function createAuthFixtures() {
  /**
   * Default auth options using the current environment
   */
  const defaultAuthOptions: AuthOptions = {
    environment: process.env.TEST_ENV || 'local',
    userRole: 'default'
  }

  // Get the configured auth provider
  const authProvider = getAuthProvider()

  return {
    /**
     * Auth options to configure environment and user role
     * @default { environment: process.env.TEST_ENV || 'local', userRole: 'default' }
     */
    authOptions: [defaultAuthOptions, { option: true }],

    /**
     * Authentication token fixture that reuses tokens across tests
     * @example
     * ```ts
     * test('use auth token', async ({ authToken }) => {
     *   // Use the token in API calls
     *   const response = await fetch('/api/data', {
     *     headers: { Authorization: authToken }
     *   })
     * })
     * ```
     */
    authToken: async (
      {
        request,
        authOptions
      }: { request: APIRequestContext; authOptions: AuthOptions },
      use: (token: string) => Promise<void>
    ) => {
      // Get token using the auth provider
      const token = await authProvider.getToken(request, authOptions)
      await use(token)
    },

    /**
     * Browser context with authentication applied
     * @example
     * ```ts
     * test('use authenticated context', async ({ context }) => {
     *   const page = await context.newPage()
     *   await page.goto('/protected-page')
     *   // Auth is already set up!
     * })
     * ```
     */
    context: async (
      {
        browser,
        request,
        authOptions
      }: { browser: any; request: APIRequestContext; authOptions: AuthOptions },
      use: (context: BrowserContext) => Promise<void>
    ) => {
      // Get token using the auth provider
      const token = await authProvider.getToken(request, authOptions)

      // Create and configure browser context with environment-aware base URL
      const context = await browser.newContext({
        baseURL: getBaseUrl({
          environment: authOptions.environment || 'local',
          baseUrl: authOptions.baseUrl
        }),
        storageState: getStorageStatePath(authOptions)
      })

      // Apply auth token to browser context
      await authProvider.applyToBrowserContext(context, token, authOptions)

      // Use and clean up
      await use(context)
      await context.close()
    },

    /**
     * Page with authentication applied
     * @example
     * ```ts
     * test('use authenticated page', async ({ page }) => {
     *   await page.goto('/protected-page')
     *   // Auth is already set up!
     * })
     * ```
     */
    page: async (
      { context }: { context: BrowserContext },
      use: (page: Page) => Promise<void>
    ) => {
      const page = await context.newPage()
      await use(page)
    }
  }
}

/**
 * Creates role-specific test fixtures
 * @param testBase The base test object to extend
 * @param role The user role to authenticate as
 * @returns A test object configured for the specified role
 */
export function createRoleSpecificTest(testBase: any, role: string) {
  return testBase.extend({
    authOptions: { userRole: role }
  })
}



================================================
FILE: pw/support/auth/internal/auth-configure.ts
================================================
/**
 * Auth session setup for the current project
 * Manages global authentication configuration
 */
import { config as dotenvConfig } from 'dotenv'
import path from 'node:path'
import { storageDir } from './auth-storage-utils'
import type { AuthSessionOptions } from './auth-types'
import fs from 'node:fs'
// eslint-disable-next-line import/named
import { v4 as uuidv4 } from 'uuid'

// Load environment variables
dotenvConfig({
  path: path.resolve(__dirname, '../../.env')
})

// File path for storing configuration
const CONFIG_FILE_PATH = path.join(storageDir, 'auth-config.json')

// Create the storage directory if it doesn't exist
if (!fs.existsSync(storageDir)) {
  fs.mkdirSync(storageDir, { recursive: true })
}

/**
 * Configure minimal auth storage settings required by custom auth providers
 *
 * This function only sets up storage paths and debugging options.
 * It does NOT handle token acquisition or environment/role management (that should be done by the auth provider).
 */
export function configureAuthSession(
  options: Partial<AuthSessionOptions> = {}
): void {
  // Extract only the core options needed for storage and debugging
  const coreConfig = {
    // Storage directory configuration
    storageDir: options.storageDir || storageDir,

    // Debug mode (used by all providers)
    debug: options.debug || false,

    // Add tracking metadata
    configId: uuidv4(),
    timestamp: new Date().toISOString()
  }

  // Write minimal configuration to file storage
  fs.writeFileSync(CONFIG_FILE_PATH, JSON.stringify(coreConfig, null, 2))
  console.log(`Auth storage configuration saved to ${CONFIG_FILE_PATH}`)
}

/**
 * Get the current global auth session options
 * @returns The global auth options or null if not configured
 */
export function getGlobalAuthOptions(): AuthSessionOptions | null {
  try {
    if (fs.existsSync(CONFIG_FILE_PATH)) {
      const configData = fs.readFileSync(CONFIG_FILE_PATH, 'utf8')
      return JSON.parse(configData)
    }
  } catch (error) {
    console.error('Error reading auth configuration:', error)
  }
  return null
}

/**
 * Initialize auth configuration with project defaults
 * * Makes auth configuration available
 * * Tests will fetch their own tokens as needed
 * * First auth call in tests will be slower (needs to fetch a token)
 * @returns The configuration options that were applied
 */
export function initializeDefaultConfiguration(): AuthSessionOptions {
  // Default configuration options
  const defaultOptions: AuthSessionOptions = {
    // Storage configuration
    storageDir,

    // Token fetch configuration - uses fallbacks in configureAuthSession
    tokenFetch: {
      url: process.env.AUTH_TOKEN_ENDPOINT || '/auth/token', // Required by TokenFetchOptions
      method: 'GET',
      body: null
    },

    // Enable debug logging for troubleshooting
    debug: true
  }

  // Apply the configuration
  configureAuthSession(defaultOptions)

  // Return the applied options (immutable copy)
  return { ...defaultOptions }
}

// NO LONGER auto-initializes when imported
// Instead, core.ts will handle initialization on demand



================================================
FILE: pw/support/auth/internal/auth-global-setup.ts
================================================
/**
 * Global initialization utilities for Playwright Auth Session
 * Consolidates functions related to storage and auth token initialization
 */
import { request } from '@playwright/test'
import { getAuthToken } from '../core'
import {
  authStorageInit as initStorage,
  getStorageStatePath
} from './auth-storage-utils'

/**
 * Initialize auth session storage directories and files
 *
 * Creates necessary directories and empty storage state files for Playwright.
 * Call this in your global setup to ensure proper directory structure.
 *
 * @param options Optional environment and user role overrides
 * @returns Object containing created storage paths
 */
export function authStorageInit(options?: {
  environment?: string
  userRole?: string
}): { storageDir: string; storageStatePath: string } {
  return initStorage(options)
}

/**
 * Pre-fetch authentication token during global setup
 *
 * This function creates a Playwright request context and fetches a token
 * for the default environment and user role, storing it for future test runs.
 *
 * Use this in your global setup to improve test performance by
 * avoiding repeated token fetches.
 *
 * @returns Promise that resolves when auth initialization is complete
 */
export async function authGlobalInit(): Promise<boolean> {
  console.log('Initializing auth token')

  // Create a request context with storageState option for auth persistence
  const requestContext = await request.newContext({
    baseURL: process.env.BASE_URL || `http://localhost:${process.env.PORT}`,
    storageState: getStorageStatePath()
  })

  try {
    // Get the auth token (this will save it for future use)
    await getAuthToken(requestContext)
    console.log('Auth token initialized successfully')
    return true
  } catch (error) {
    console.error('Failed to initialize auth token:', error)
    throw error
  } finally {
    await requestContext.dispose()
  }
}



================================================
FILE: pw/support/auth/internal/auth-provider.ts
================================================
/* eslint-disable @typescript-eslint/no-require-imports */
/**
 * Auth Provider Interface
 * Defines the contract for authentication providers
 */
import type { APIRequestContext, BrowserContext } from '@playwright/test'
import type { AuthOptions } from './auth-types'

/**
 * AuthProvider interface defines the contract for custom authentication providers
 * Applications can implement this interface to provide their own authentication logic
 */
export interface AuthProvider {
  /**
   * Get the current environment (e.g., 'local', 'staging', 'production')
   * @param options Optional options that might override the default environment
   * @returns The current environment to use
   */
  getEnvironment(options?: Partial<AuthOptions>): string

  /**
   * Get the current user role (e.g., 'admin', 'user', 'guest')
   * @param options Optional options that might override the default role
   * @returns The current user role to use
   */
  getUserRole(options?: Partial<AuthOptions>): string

  /**
   * Get authentication token for API requests
   * @param request Playwright APIRequestContext for making HTTP requests
   * @param options Optional auth options that might override defaults
   * @returns Promise resolving to the authentication token
   */
  getToken(
    request: APIRequestContext,
    options?: Partial<AuthOptions>
  ): Promise<string>

  /**
   * Apply authentication to a browser context for UI testing
   * @param context Playwright BrowserContext to apply authentication to
   * @param token Authentication token
   * @param options Optional auth options that might override defaults
   */
  applyToBrowserContext(
    context: BrowserContext,
    token: string,
    options?: Partial<AuthOptions>
  ): Promise<void>

  /**
   * Clear authentication token
   * @param options Optional auth options that might override defaults
   */
  clearToken(options?: Partial<AuthOptions>): void
}

/**
 * Default auth provider factory.
 * Creates a default implementation of AuthProvider that uses the built-in session manager.
 */
function createDefaultAuthProvider(
  customConfig: {
    tokenUrl?: string
    // eslint-disable-next-line @typescript-eslint/no-explicit-any
    tokenExtractor?: (data: any) => string
    storageBaseDir?: string
    defaultEnvironment?: string
    defaultUserRole?: string
  } = {}
): AuthProvider {
  // Import implementation details here, not in consumer code
  // Use dynamic import to avoid circular dependencies
  const authSession = require('./auth-session')
  const { clearAuthToken, applyAuthToBrowserContext } = authSession

  return {
    // New methods to make provider the source of truth
    getEnvironment: (options = {}) => {
      // Env provided in options takes precedence over default
      return (
        options.environment ||
        customConfig.defaultEnvironment ||
        process.env.TEST_ENV ||
        'local'
      )
    },

    getUserRole: (options = {}) => {
      // Role provided in options takes precedence over default
      return options.userRole || customConfig.defaultUserRole || 'default'
    },

    getToken: async (request, options = {}) => {
      // Get environment and role from provider methods
      const environment =
        options.environment ||
        customConfig.defaultEnvironment ||
        process.env.TEST_ENV ||
        'local'
      const userRole =
        options.userRole || customConfig.defaultUserRole || 'default'

      // Create a direct instance of the auth manager instead of using getAuthToken
      // to avoid circular dependency
      const storageBase = customConfig.storageBaseDir || undefined
      const storagePath = storageBase
        ? `${storageBase}/${environment}/${userRole}`
        : undefined

      // Configure the options with AuthSessionManager.getInstance()
      const authOptions = {
        storageDir: storagePath,
        tokenFetch: customConfig.tokenUrl
          ? { url: customConfig.tokenUrl }
          : undefined,
        tokenExtractor: customConfig.tokenExtractor,
        debug: false // Set debug off by default
      }

      // Get token directly from the manager using the authSession module
      const token =
        await authSession.AuthSessionManager.getInstance(authOptions).getToken(
          request
        )

      // Ensure we're returning a string
      return typeof token === 'string'
        ? token
        : token.token || JSON.stringify(token)
    },

    applyToBrowserContext: async (context, token, options = {}) => {
      // Use provider methods to get environment and role
      const finalOptions = {
        environment:
          options.environment ||
          customConfig.defaultEnvironment ||
          process.env.TEST_ENV ||
          'local',
        userRole: options.userRole || customConfig.defaultUserRole || 'default',
        ...options
      }
      return applyAuthToBrowserContext(context, token, finalOptions)
    },

    clearToken: (options = {}) => {
      // Use provider methods to get environment and role
      const finalOptions = {
        environment:
          options.environment ||
          customConfig.defaultEnvironment ||
          process.env.TEST_ENV ||
          'local',
        userRole: options.userRole || customConfig.defaultUserRole || 'default',
        ...options
      }
      clearAuthToken(finalOptions)
    }
  }
}

// Global provider instance that can be configured
let globalAuthProvider: AuthProvider | null = null

/**
 * Set the global auth provider
 * @param provider Custom auth provider implementation
 */
export function setAuthProvider(provider: AuthProvider): void {
  globalAuthProvider = provider
}

/**
 * Get the configured auth provider or create a default one
 * Requires that configuration has been set up before use
 */
export function getAuthProvider(): AuthProvider {
  // Create default provider if none exists
  if (!globalAuthProvider) {
    globalAuthProvider = createDefaultAuthProvider()
  }
  return globalAuthProvider
}



================================================
FILE: pw/support/auth/internal/auth-session.ts
================================================
/**
 * Authentication session manager for use with playwright
 * Similar pattern to the cypress-data-session package
 *
 * @internal This file contains implementation details that should not be directly imported
 * Use the public API exported from index.ts instead
 */
import type { APIRequestContext, BrowserContext } from '@playwright/test'
import {
  getStorageDir,
  getStorageStatePath,
  getTokenFilePath
} from './auth-storage-utils'
import * as fs from 'fs'
import * as path from 'path'
import type {
  AuthSessionOptions,
  AuthTokenData,
  TokenDataFormatter
} from './auth-types'
import { getGlobalAuthOptions } from './auth-configure'
import { getAuthProvider } from './auth-provider'

/**
 * Default token data formatter that creates the basic token structure
 * Can be overridden by providing a custom formatter in AuthSessionOptions
 */
const defaultTokenFormatter: TokenDataFormatter = (
  token: string
): AuthTokenData => ({
  token,
  createdAt: new Date().toISOString(),
  expiresAt: null // Set this if you know when the token expires
})

/**
 * Re-export configureAuthSession from auth-configure
 */
export { configureAuthSession } from './auth-configure'

/**
 * Export the default token formatter for consumers to extend
 */
export { defaultTokenFormatter }

/**
 * Authentication session manager that saves and reuses auth tokens
 * to avoid making unnecessary token requests.
 *
 * Follows Playwright's authentication state reuse pattern:
 * @see https://playwright.dev/docs/api-testing#reusing-authentication-state
 */
/**
 * Internal authentication manager that handles token storage and retrieval
 * @internal
 */
export class AuthSessionManager {
  private static instance: AuthSessionManager
  private readonly storageDir: string
  private readonly storageFile: string
  private readonly options: AuthSessionOptions
  private hasToken: boolean = false
  private token: string | null = null

  private constructor(options: AuthSessionOptions) {
    // Get global options as fallback
    const mergedOptions = { ...getGlobalAuthOptions(), ...options }

    // First gather defaults and merge with options
    const defaultTokenFetch: AuthSessionOptions['tokenFetch'] =
      mergedOptions.tokenFetch
        ? {
            method: mergedOptions.tokenFetch.method || 'GET',
            body: mergedOptions.tokenFetch.body || null,
            url: mergedOptions.tokenFetch.url,
            baseUrl: mergedOptions.tokenFetch.baseUrl,
            headers: mergedOptions.tokenFetch.headers
          }
        : {
            method: 'GET',
            body: null,
            url: '/auth/fake-token',
            baseUrl: `http://localhost:${process.env.PORT || 3000}`
          }

    // Create the final options by removing tokenFetch to avoid duplicates
    // eslint-disable-next-line @typescript-eslint/no-unused-vars
    const { tokenFetch: _, ...restOptions } = mergedOptions

    // Merge everything together with proper typing
    this.options = {
      debug: false,
      tokenFileName: 'auth-token.json',
      // eslint-disable-next-line @typescript-eslint/no-explicit-any
      tokenExtractor: (data: any) => data.token,
      tokenFetch: defaultTokenFetch,
      ...restOptions
    }

    // Get the auth provider for environment and role information
    // eslint-disable-next-line @typescript-eslint/no-require-imports
    const { getAuthProvider } = require('./auth-provider')
    const provider = getAuthProvider()

    // Get environment and user role from the provider
    const environment = provider.getEnvironment()
    const userRole = provider.getUserRole()

    // Get storage paths based on environment and user role from the provider
    this.storageDir =
      this.options.storageDir ||
      getStorageDir({
        environment,
        userRole
      })

    this.storageFile = this.options.storageDir
      ? path.join(this.storageDir, this.options.tokenFileName!)
      : getTokenFilePath({
          environment,
          userRole,
          tokenFileName: this.options.tokenFileName
        })

    // Create the storage directory if it doesn't exist
    if (!fs.existsSync(this.storageDir)) {
      fs.mkdirSync(this.storageDir, { recursive: true })
    }

    // Try to load existing token
    this.loadTokenFromStorage()

    if (this.options.debug) {
      console.log(
        `Auth session manager initialized with storage at: ${this.storageFile}`
      )
    }
  }

  /**
   * Get singleton instance with options
   */
  public static getInstance(options?: AuthSessionOptions): AuthSessionManager {
    // Use provided options, fallback to global options, or throw if neither exists
    const resolvedOptions = options || getGlobalAuthOptions()
    if (!resolvedOptions) {
      throw new Error(
        'Auth session options must be provided either directly or via configureAuthSession'
      )
    }

    if (!AuthSessionManager.instance) {
      AuthSessionManager.instance = new AuthSessionManager(resolvedOptions)
    } else if (options) {
      // If new options are provided, warn that they won't be used as instance already exists
      console.warn(
        'Auth session manager already initialized - new options ignored'
      )
    }

    return AuthSessionManager.instance
  }

  /**
   * Load token from storage if it exists
   */
  private loadTokenFromStorage(): void {
    try {
      if (fs.existsSync(this.storageFile)) {
        const data = fs.readFileSync(this.storageFile, 'utf8')
        const parsed = JSON.parse(data) as AuthTokenData

        // Check if token is expired
        if (
          parsed.expiresAt &&
          new Date(parsed.expiresAt).getTime() < Date.now()
        ) {
          if (this.options.debug) {
            console.log('Token expired, will fetch a new one')
          }
          return
        }

        this.token = parsed.token
        this.hasToken = true

        if (this.options.debug) {
          console.log('Token loaded from storage')
        }
      }
    } catch (error) {
      console.error('Error loading token from storage:', error)
    }
  }

  /**
   * Save token to storage
   */
  private saveTokenToStorage(token: string): void {
    try {
      // Use custom formatter if provided or default formatter
      const tokenFormatter =
        this.options.tokenDataFormatter || defaultTokenFormatter
      const data = tokenFormatter(token)

      fs.writeFileSync(this.storageFile, JSON.stringify(data, null, 2))

      if (this.options.debug) {
        console.log('Token saved to storage')
      }
    } catch (error) {
      console.error('Error saving token to storage:', error)
    }
  }

  /**
   * Clear the token from storage
   */
  public clearToken(): void {
    try {
      if (fs.existsSync(this.storageFile)) {
        fs.unlinkSync(this.storageFile)
      }
      this.token = null
      this.hasToken = false

      if (this.options.debug) {
        console.log('Token cleared from storage')
      }
    } catch (error) {
      console.error('Error clearing token from storage:', error)
    }
  }

  /**
   * Fetch a new token
   */
  private async fetchToken(request: APIRequestContext): Promise<string> {
    // Check if tokenFetch is available
    if (!this.options.tokenFetch) {
      throw new Error(
        'Token fetch configuration is not available. Use setAuthProvider with a custom provider instead.'
      )
    }

    // Now we know tokenFetch exists, we can safely destructure it
    const {
      url,
      baseUrl,
      method = 'GET',
      body,
      headers
    } = this.options.tokenFetch

    if (this.options.debug) {
      console.log(
        `Fetching token from ${baseUrl || 'baseURL'}${url} with method ${method}`
      )
    }

    // Construct the full URL if baseUrl is provided
    const fullUrl = baseUrl ? `${baseUrl}${url}` : url

    const requestMethod = method.toLowerCase() as 'get' | 'post'

    // Handle GET vs POST differently - GET requests shouldn't have a body
    let response
    if (requestMethod === 'get') {
      response = await request.get(fullUrl, {
        headers: headers || {}
      })
    } else {
      response = await request[requestMethod](fullUrl, {
        data: body,
        headers: headers || { 'Content-Type': 'application/json' }
      })
    }

    if (!response.ok()) {
      throw new Error(
        `Failed to fetch token: ${response.status()} ${await response.text()}`
      )
    }

    let responseData
    const contentType = response.headers()['content-type'] || ''

    if (contentType.includes('application/json')) {
      responseData = await response.json()
    } else {
      responseData = await response.text()
    }

    // Extract token using the token extractor or default to the response itself
    const token =
      typeof responseData === 'string'
        ? responseData
        : this.options.tokenExtractor?.(responseData) || responseData

    if (!token || token === '') {
      throw new Error(
        'Failed to extract token from response - token is empty or undefined'
      )
    }

    return token
  }

  /**
   * Get a token, fetching a new one if needed
   */
  public async getToken(request: APIRequestContext): Promise<string> {
    if (this.hasToken && this.token) {
      if (this.options.debug) {
        console.log('Using cached token')
      }
      return this.token
    }

    const token = await this.fetchToken(request)
    this.token = token
    this.hasToken = true
    this.saveTokenToStorage(token)

    return token
  }
}

/**
 * Get a token for authentication
 *
 * This function requires both:
 * 1. configureAuthSession() - For basic storage paths and configuration
 * 2. setAuthProvider() - For actual token implementation
 */
export async function getAuthToken(
  request: APIRequestContext,
  options?: { environment?: string; userRole?: string }
): Promise<string> {
  // Step 1: Check if basic configuration exists (from configureAuthSession)
  const globalOptions = getGlobalAuthOptions()
  if (!globalOptions) {
    throw new Error(
      'Basic auth configuration missing. You must call configureAuthSession() first to set up storage paths.'
    )
  }

  // Step 2: Check if a custom provider is configured (from setAuthProvider)
  const provider = getAuthProvider()
  if (!provider) {
    throw new Error(
      'No auth provider configured. You must call setAuthProvider() with your custom provider.'
    )
  }

  // Step 3: Use the custom provider with configuration from both sources
  return provider.getToken(request, {
    environment: options?.environment,
    userRole: options?.userRole
  })
}

/**
 * Clear the token from storage
 */
export function clearAuthToken(options?: {
  environment?: string
  userRole?: string
}): void {
  // Get global auth options
  const globalOptions = getGlobalAuthOptions()
  if (!globalOptions) {
    throw new Error(
      'Auth session not configured. Call configureAuthSession first.'
    )
  }

  // Create full options
  const fullOptions: AuthSessionOptions = {
    ...globalOptions,
    ...options
  }

  const authManager = AuthSessionManager.getInstance(fullOptions)
  authManager.clearToken()
}

/**
 * Apply auth token to a browser context for UI testing
 */
export async function applyAuthToBrowserContext(
  context: BrowserContext,
  token: string,
  options?: { environment?: string; userRole?: string }
): Promise<void> {
  // Get the storage state path
  const statePath = getStorageStatePath(options)

  // Save the current state
  await context.storageState({ path: statePath })

  // Add the auth token to localStorage
  await context.addInitScript((token) => {
    // Store token in localStorage
    window.localStorage.setItem('authToken', token)
  }, token)

  // Navigate to the app to ensure the init script runs
  const page = await context.newPage()
  await page.goto('/')
  await page.close()

  // Save the state with the token
  await context.storageState({ path: statePath })
}



================================================
FILE: pw/support/auth/internal/auth-storage-utils.ts
================================================
/**
 * Storage utilities for Playwright testing
 * Simple, explicit functions for managing test storage files
 *
 * Uses Playwright's storage state for auth sessions:
 * @see https://playwright.dev/docs/api-testing#reusing-authentication-state
 * @see https://playwright.dev/docs/api/class-apirequestcontext#api-request-context-storage-state
 * @see https://playwright.dev/docs/api/class-browsercontext#browser-context-storage-state
 */

/* eslint-disable @typescript-eslint/no-unused-vars */
/* eslint-disable @typescript-eslint/no-require-imports */
import fs from 'node:fs'
import path from 'node:path'

/**
 * Default environment when none is specified
 */
const DEFAULT_ENVIRONMENT = 'local'

/**
 * Default user role when none is specified
 */
const DEFAULT_USER_ROLE = 'default'

/**
 * Get environment from the auth provider or fallback to environment variables
 * @param options Optional overrides
 */
export function getCurrentEnvironment(options?: {
  environment?: string
}): string {
  try {
    // Try to get from provider first
    const { getAuthProvider } = require('./auth-provider')
    const provider = getAuthProvider()
    return provider.getEnvironment(options)
  } catch (error) {
    // Fallback to environment variables
    return options?.environment || process.env.TEST_ENV || DEFAULT_ENVIRONMENT
  }
}

/**
 * Get current user role from the auth provider or fallback to default
 * @param options Optional overrides
 */
export function getCurrentUserRole(options?: { userRole?: string }): string {
  try {
    // Try to get from provider first
    const { getAuthProvider } = require('./auth-provider')
    const provider = getAuthProvider()
    return provider.getUserRole(options)
  } catch (error) {
    // Fallback to default or provided value
    return options?.userRole || DEFAULT_USER_ROLE
  }
}

/**
 * Get the storage directory path based on environment and user role
 *
 * @param options Configuration options
 * @param options.environment Test environment (e.g., 'local', 'dev', 'staging')
 * @param options.userRole User role for storage separation
 * @returns Path to the auth storage directory
 */
export function getStorageDir(options?: {
  environment?: string
  userRole?: string
}): string {
  const environment = getCurrentEnvironment(options)
  const userRole = getCurrentUserRole(options)

  return path.join(process.cwd(), 'pw', '.auth-sessions', environment, userRole)
}

/**
 * Get the storage state path for a specific environment and user role
 *
 * @param options Configuration options
 * @param options.environment Test environment (e.g., 'local', 'dev', 'staging')
 * @param options.userRole User role for storage separation
 * @returns Path to the storage state file
 */
export function getStorageStatePath(options?: {
  environment?: string
  userRole?: string
}): string {
  return path.join(getStorageDir(options), 'storage-state.json')
}

/**
 * Get the token file path for a specific environment and user role
 *
 * @param options Configuration options
 * @param options.environment Test environment (e.g., 'local', 'dev', 'staging')
 * @param options.userRole User role for storage separation
 * @param options.tokenFileName Custom token filename
 * @returns Path to the token file
 */
export function getTokenFilePath(options?: {
  environment?: string
  userRole?: string
  tokenFileName?: string
}): string {
  const tokenFileName = options?.tokenFileName || 'auth-token.json'
  return path.join(getStorageDir(options), tokenFileName)
}

// Default paths using the current environment
export const storageDir = getStorageDir()

/**
 * Initialize storage for auth sessions
 * This ensures the directory structure is ready for auth session storage
 *
 * Creates an empty storage state compatible with Playwright's storageState option:
 * @see https://playwright.dev/docs/api/class-browsercontext#browser-context-storage-state
 *
 * @param options Configuration options
 * @param options.environment Test environment (e.g., 'local', 'dev', 'staging')
 * @param options.userRole User role for storage separation
 * @returns Object containing the created storage paths
 */
export function authStorageInit(options?: {
  environment?: string
  userRole?: string
}): { storageDir: string; storageStatePath: string } {
  const dir = getStorageDir(options)
  const statePath = getStorageStatePath(options)

  if (!fs.existsSync(dir)) {
    fs.mkdirSync(dir, { recursive: true })
    console.log(`Created auth session directory at ${dir}`)
  }

  if (!fs.existsSync(statePath)) {
    fs.writeFileSync(
      statePath,
      // Create empty storage state in Playwright's expected format
      // See: https://playwright.dev/docs/api/class-browsercontext#browser-context-storage-state
      JSON.stringify({ cookies: [], origins: [] })
    )
    console.log(`Created empty storage state at ${statePath}`)
  }

  return { storageDir: dir, storageStatePath: statePath }
}



================================================
FILE: pw/support/auth/internal/auth-types.ts
================================================
/**
 * Type definitions for the authentication session manager
 */

/* eslint-disable @typescript-eslint/no-explicit-any */
/**
 * Options for token fetching
 */
export interface TokenFetchOptions {
  /**
   * URL path to fetch the token from (relative to baseUrl)
   */
  url: string

  /**
   * Base URL for the request (default: baseUrl from playwright config)
   */
  baseUrl?: string

  /**
   * HTTP method for the token fetch (default: POST)
   */
  method?: 'GET' | 'POST' | 'PUT' | 'DELETE'

  /**
   * Request body for the token fetch (default: null)
   */
  body?: any

  /**
   * Headers for the token fetch (default: content-type: application/json)
   */
  headers?: Record<string, string>

  /**
   * How to extract the token from the response (default: direct string or json.token)
   */
  tokenExtractor?: (response: any) => string
}

/**
 * Options for the auth session
 */
export interface AuthSessionOptions {
  /**
   * Root directory for auth session storage (default: pw/.auth-sessions)
   * Note: The environment and user role will be appended to this path by the provider
   */
  storageDir?: string

  /**
   * Token filename (default: auth-token.json)
   */
  tokenFileName?: string

  /**
   * Storage state filename (default: storage-state.json)
   */
  storageStateFileName?: string

  /**
   * Function to extract the token from a response
   * @default (data) => data.token
   */
  tokenExtractor?: (data: any) => string

  /**
   * Custom token data formatter to control how tokens are saved
   * This function generates the structure of saved token data
   * @default defaultTokenFormatter
   */
  tokenDataFormatter?: TokenDataFormatter

  /**
   * Token fetch configuration
   */
  tokenFetch?: TokenFetchOptions

  /**
   * Debug mode (default: false)
   */
  debug?: boolean
}

/**
 * Auth token storage format
 *
 * Extensible to support different authentication systems and token formats.
 * Only 'token' and 'createdAt' are required, all other fields are optional.
 */
export interface AuthTokenData {
  /**
   * The token value (required)
   */
  token: string

  /**
   * When the token was created (ISO date string, required)
   */
  createdAt: string

  /**
   * When the token expires (ISO date string or null if not set)
   */
  expiresAt?: string | null

  /**
   * Optional refresh token for OAuth2 or similar flows
   */
  refreshToken?: string

  /**
   * Optional token type (e.g., "Bearer", "JWT")
   */
  tokenType?: string

  /**
   * Allow any additional properties needed by specific authentication systems
   */
  [key: string]: unknown
}

/**
 * Function type for customizing how token data is formatted before storage
 * This allows for complete customization of the token storage format
 */
export type TokenDataFormatter = (token: string) => AuthTokenData

/**
 * Options for authentication fixtures
 */
export interface AuthOptions {
  /**
   * Environment to use for authentication
   * @default process.env.TEST_ENV || 'local'
   */
  environment?: string

  /**
   * User role to authenticate as
   * @default 'default'
   */
  userRole?: string

  /**
   * Base URL to use for the browser context (the application URL)
   * If not provided, will be determined based on environment
   * @default process.env.BASE_URL || environment-specific URL
   */
  baseUrl?: string

  /**
   * Base URL to use for authentication requests (the auth service URL)
   * This is often different from the application baseUrl
   * @default process.env.AUTH_BASE_URL || environment-specific auth URL
   */
  authBaseUrl?: string
}

/**
 * For usage in test fixtures
 */
export type AuthFixtures = {
  authOptions: AuthOptions
  authToken: string
  // context and page are already part of the base Playwright test
}



================================================
FILE: pw/support/auth/internal/url-utils.ts
================================================
/**
 * Utilities for URL handling in test environments
 */

/**
 * Get the application base URL for a specific environment
 *
 * @param options Options containing environment and optional explicit baseUrl
 * @returns The application base URL appropriate for the current environment
 */
export function getBaseUrl(options: {
  environment: string
  baseUrl?: string
}): string {
  // Priority order:
  // 1. Explicitly provided baseUrl in options
  // 2. Environment variable BASE_URL
  // 3. Environment-specific URL mapping

  // First priority: explicit baseUrl from options
  if (options.baseUrl) {
    return options.baseUrl
  }

  // Second priority: environment variable
  if (process.env.BASE_URL) {
    return process.env.BASE_URL
  }

  // Third priority: environment-specific mapping
  const { environment } = options

  // Map environments to base URLs
  // This could be extended with more environments or moved to configuration
  switch (environment) {
    case 'local':
      return `http://localhost:${process.env.PORT || '8080'}`
    case 'dev':
      return 'https://dev.example.com'
    case 'staging':
      return 'https://staging.example.com'
    case 'production':
      return 'https://example.com'
    default:
      // If unknown environment, use local as fallback with warning
      console.warn(
        `[Auth] Unknown environment '${environment}', falling back to localhost`
      )
      return `http://localhost:${process.env.PORT || '8080'}`
  }
}

/**
 * Get the authentication service base URL for a specific environment
 *
 * Often the auth service is hosted at a different domain than the app itself
 *
 * @param options Options containing environment and optional explicit authBaseUrl
 * @returns The auth service base URL appropriate for the current environment
 */
export function getAuthBaseUrl(options: {
  environment: string
  authBaseUrl?: string
}): string {
  // Priority order:
  // 1. Explicitly provided authBaseUrl in options
  // 2. Environment variable AUTH_BASE_URL
  // 3. Environment-specific auth URL mapping

  // First priority: explicit authBaseUrl from options
  if (options.authBaseUrl) {
    return options.authBaseUrl
  }

  // Second priority: environment variable
  if (process.env.AUTH_BASE_URL) {
    return process.env.AUTH_BASE_URL
  }

  // Third priority: environment-specific mapping
  const { environment } = options

  // Map environments to auth base URLs
  // This could be extended with more environments or moved to configuration
  switch (environment) {
    case 'local':
      return `http://localhost:${process.env.AUTH_PORT || '8081'}/auth`
    case 'dev':
      return 'https://auth.dev.example.com'
    case 'staging':
      return 'https://auth.staging.example.com'
    case 'production':
      return 'https://auth.example.com'
    default:
      // If unknown environment, use local as fallback with warning
      console.warn(
        `[Auth] Unknown environment '${environment}' for auth URL, falling back to localhost`
      )
      return `http://localhost:${process.env.AUTH_PORT || '8081'}/auth`
  }
}



================================================
FILE: pw/support/fixture-helpers/plain-functions.ts
================================================
import type { APIRequestContext, APIResponse } from '@playwright/test'

/**
 * Simplified helper for making API requests and returning the status and JSON body.
 * This helper automatically performs the request based on the provided method, URL, body, and headers.
 *
 * @param {Object} params - The parameters for the request.
 * @param {APIRequestContext} params.request - The Playwright request object, used to make the HTTP request.
 * @param {string} params.method - The HTTP method to use (POST, GET, PUT, DELETE).
 * @param {string} params.url - The URL to send the request to.
 * @param {string} [params.baseUrl] - The base URL to prepend to the request URL.
 * @param {Record<string, unknown> | null} [params.body=null] - The body to send with the request (for POST and PUT requests).
 * @param {Record<string, string> | undefined} [params.headers=undefined] - The headers to include with the request.
 * @returns {Promise<{ status: number; body: unknown }>} - An object containing the status code and the parsed response body.
 *    - `status`: The HTTP status code returned by the server.
 *    - `body`: The parsed JSON response body from the server.
 */
export async function apiRequest({
  request,
  method,
  url,
  baseUrl,
  body = null,
  headers
}: {
  request: APIRequestContext
  method: 'POST' | 'GET' | 'PUT' | 'DELETE'
  url: string
  baseUrl?: string
  body?: Record<string, unknown> | null
  headers?: Record<string, string>
}): Promise<{ status: number; body: unknown }> {
  let response: APIResponse

  // Common request options
  const options: {
    data?: Record<string, unknown> | null
    headers?: Record<string, string>
  } = {}
  if (body) options.data = body
  if (headers) options.headers = headers

  // Construct full URL
  const fullUrl = baseUrl ? `${baseUrl}${url}` : url

  // Make the request based on the method
  switch (method.toUpperCase()) {
    case 'POST':
      response = await request.post(fullUrl, options)
      break
    case 'GET':
      response = await request.get(fullUrl, { headers })
      break
    case 'PUT':
      response = await request.put(fullUrl, options)
      break
    case 'DELETE':
      response = await request.delete(fullUrl, { headers })
      break
    default:
      throw new Error(`Unsupported HTTP method: ${method}`)
  }

  const status = response.status()

  // Determine how to parse the response body
  let bodyData: unknown = null
  const contentType = response.headers()['content-type'] || ''

  try {
    if (contentType.includes('application/json')) {
      bodyData = await response.json()
    } else if (contentType.includes('text/')) {
      bodyData = await response.text()
    }
  } catch (err) {
    console.warn(`Failed to parse response body for status ${status}: ${err}`)
  }

  return { status, body: bodyData }
}



================================================
FILE: pw/support/fixtures/api-request-fixture.ts
================================================
import { test as base } from '@playwright/test'
import { apiRequest as apiRequestFunction } from '../fixture-helpers/plain-functions'

type ApiRequestParams = {
  method: 'POST' | 'GET' | 'PUT' | 'DELETE'
  url: string
  baseUrl?: string
  body?: Record<string, unknown> | null
  headers?: Record<string, string>
}

export type ApiRequestResponse<T = unknown> = {
  status: number
  body: T
}

export const test = base.extend<{
  apiRequest: <T = unknown>(
    params: ApiRequestParams
  ) => Promise<ApiRequestResponse<T>>
}>({
  apiRequest: async ({ request }, use) => {
    const apiRequest = async <T = unknown>({
      method,
      url,
      baseUrl,
      body = null,
      headers
    }: ApiRequestParams): Promise<ApiRequestResponse<T>> => {
      const response = await apiRequestFunction({
        request,
        method,
        url,
        baseUrl,
        body,
        headers
      })

      return {
        status: response.status,
        body: response.body as T
      }
    }

    await use(apiRequest)
  }
})



================================================
FILE: pw/support/fixtures/auth-fixture.ts
================================================
/**
 * Extended test fixture that adds authentication support for both API and UI testing
 *
 * @see https://playwright.dev/docs/test-fixtures
 * @see https://playwright.dev/docs/api-testing#authentication
 * @see https://playwright.dev/docs/auth
 */

import { test as base } from '@playwright/test'
import {
  createAuthFixtures,
  type AuthOptions,
  type AuthFixtures
} from '../auth'

// Default auth options using the current environment
const defaultAuthOptions: AuthOptions = {
  environment: process.env.TEST_ENV || 'local',
  userRole: 'default'
}

// Get the fixtures from the factory function
const fixtures = createAuthFixtures()

// Export the test object with auth fixtures
export const test = base.extend<AuthFixtures>({
  // For authOptions, we need to define it directly using the Playwright array format
  authOptions: [defaultAuthOptions, { option: true }],

  // Use the other fixtures directly
  authToken: fixtures.authToken,
  context: fixtures.context,
  page: fixtures.page
})



================================================
FILE: pw/support/fixtures/crud-helper-fixture.ts
================================================
import type { Movie } from '@prisma/client'
import { test as baseApiRequestFixture } from './api-request-fixture'
import type { ApiRequestResponse } from './api-request-fixture'
import type {
  DeleteMovieResponse,
  CreateMovieResponse,
  GetMovieResponse,
  UpdateMovieResponse
} from '../../../src/@types'

// Common headers function
const commonHeaders = (token: string) => ({
  Authorization: token
})

export const test = baseApiRequestFixture.extend<{
  addMovie: (
    token: string,
    body: Omit<Movie, 'id'>,
    baseUrl?: string
  ) => Promise<ApiRequestResponse<CreateMovieResponse>>
  getAllMovies: (
    token: string,
    baseUrl?: string
  ) => Promise<ApiRequestResponse<GetMovieResponse>>
  getMovieById: (
    token: string,
    id: number,
    baseUrl?: string
  ) => Promise<ApiRequestResponse<GetMovieResponse>>
  getMovieByName: (
    token: string,
    name: string,
    baseUrl?: string
  ) => Promise<ApiRequestResponse<GetMovieResponse>>
  updateMovie: (
    token: string,
    id: number,
    body: Partial<Movie>,
    baseUrl?: string
  ) => Promise<ApiRequestResponse<UpdateMovieResponse>>
  deleteMovie: (
    token: string,
    id: number,
    baseUrl?: string
  ) => Promise<ApiRequestResponse<DeleteMovieResponse>>
}>({
  addMovie: async ({ apiRequest }, use) => {
    const addMovie = async (
      token: string,
      body: Omit<Movie, 'id'>,
      baseUrl?: string
    ) => {
      return apiRequest<CreateMovieResponse>({
        method: 'POST',
        url: '/movies',
        baseUrl,
        body,
        headers: commonHeaders(token)
      })
    }

    await use(addMovie)
  },

  getAllMovies: async ({ apiRequest }, use) => {
    const getAllMovies = async (token: string, baseUrl?: string) => {
      return apiRequest<GetMovieResponse>({
        method: 'GET',
        url: '/movies',
        baseUrl,
        headers: commonHeaders(token)
      })
    }

    await use(getAllMovies)
  },

  getMovieById: async ({ apiRequest }, use) => {
    const getMovieById = async (
      token: string,
      id: number,
      baseUrl?: string
    ) => {
      return apiRequest<GetMovieResponse>({
        method: 'GET',
        url: `/movies/${id}`,
        baseUrl,
        headers: commonHeaders(token)
      })
    }

    await use(getMovieById)
  },

  getMovieByName: async ({ apiRequest }, use) => {
    const getMovieByName = async (
      token: string,
      name: string,
      baseUrl?: string
    ) => {
      // Construct the query parameters manually
      const queryParams = new URLSearchParams({ name }).toString()
      const url = `/movies?${queryParams}` // Append the query string to the endpoint

      return apiRequest<GetMovieResponse>({
        method: 'GET',
        url, // Pass the constructed URL
        baseUrl,
        headers: commonHeaders(token)
      })
    }

    await use(getMovieByName)
  },

  updateMovie: async ({ apiRequest }, use) => {
    const updateMovie = async (
      token: string,
      id: number,
      body: Partial<Movie>,
      baseUrl?: string
    ) => {
      return apiRequest<UpdateMovieResponse>({
        method: 'PUT',
        url: `/movies/${id}`,
        baseUrl,
        body,
        headers: commonHeaders(token)
      })
    }

    await use(updateMovie)
  },

  deleteMovie: async ({ apiRequest }, use) => {
    const deleteMovie = async (token: string, id: number, baseUrl?: string) => {
      return apiRequest<DeleteMovieResponse>({
        method: 'DELETE',
        url: `/movies/${id}`,
        baseUrl,
        headers: commonHeaders(token)
      })
    }

    await use(deleteMovie)
  }
})



================================================
FILE: pw/support/utils/recurse-with-expect.ts
================================================
/**
 * Retries an asynchronous function with specified options until it succeeds or the retries/timeout are exhausted.
 *
 * This function attempts to execute the provided asynchronous function `fn`. If `fn` throws an error, it will retry
 * executing `fn` after waiting for a specified interval. The function continues to retry until either:
 * - The function succeeds (`fn` resolves), or
 * - The number of retries is exhausted, or
 * - The total timeout duration is exceeded.
 *
 * After exhausting all retries and before the timeout is reached, a final attempt is made to execute `fn`.
 *
 * @async
 * @function recurseWithExpect
 *
 * @param {() => Promise<void>} fn - The asynchronous function to be executed and potentially retried.
 *
 * @param {Object} [options] - Configuration options for retry behavior.
 * @param {number} [options.retries=10] - The maximum number of retry attempts. Defaults to 10.
 * @param {number} [options.interval=500] - The delay between retries in milliseconds. Defaults to 500ms.
 * @param {number} [options.timeout=10000] - The maximum total time to keep retrying in milliseconds. Defaults to 10,000ms (10 seconds).
 *
 * @returns {Promise<void>} - Resolves when `fn` executes successfully. Rejects if all attempts fail.
 *
 * @throws {Error} - Throws the last encountered error if all retry attempts fail.
 *
 * @example
 * ```typescript
 * async function fetchData() {
 *   // Some asynchronous operation, e.g., fetching data from an API
 * }
 *
 * try {
 *   await recurseWithExpect(fetchData, { retries: 5, interval: 1000, timeout: 5000 });
 *   console.log("Operation succeeded.");
 * } catch (error) {
 *   console.error("All retry attempts failed:", error);
 * }
 * ```
 */
export async function recurseWithExpect(
  fn: () => Promise<void>,
  options?: {
    retries?: number
    interval?: number
    timeout?: number
  }
): Promise<void> {
  const retries = options?.retries ?? 10
  const interval = options?.interval ?? 500 // milliseconds
  const timeout = options?.timeout ?? 10000 // milliseconds

  const endTime = Date.now() + timeout
  let attempt = 0

  while (attempt < retries && Date.now() < endTime) {
    try {
      await fn()
      return // All assertions passed
    } catch (error: unknown) {
      if (error instanceof Error) {
        console.warn(
          `Attempt ${attempt + 1} failed: ${error.message}. Retrying in ${interval}ms...`
        )
      } else {
        console.error(
          `Attempt ${attempt + 1} failed: An unknown error occurred. Retrying in ${interval}ms...`,
          error
        )
        throw error
      }
    }

    attempt++
    await new Promise((res) => setTimeout(res, interval))
  }

  // Final attempt
  await fn()
}



================================================
FILE: pw/support/utils/run-command.ts
================================================
import { execSync } from 'node:child_process'

/**
 * Runs a shell command and returns the output.
 * Handles errors gracefully and returns null if the command fails.
 * @param {string} command - The command to run.
 * @returns {string | null} - The output of the command or null if it fails.
 */
export function runCommand(command: string): string | null {
  try {
    return execSync(command, { encoding: 'utf-8' }).trim()
  } catch (error) {
    const typedError = error as Error
    console.error(typedError.message)
    return null // Return null to signify failure
  }
}



================================================
FILE: scripts/can-i-deploy-provider.sh
================================================
#!/bin/bash

# Exit immediately if a command exits with a non-zero status
set -e

# Load environment variables
. ./scripts/env-setup.sh

# Check if MoviesAPI can be deployed
pact-broker can-i-deploy \
    --pacticipant MoviesAPI \
    --version=$GITHUB_SHA \
    --to-environment dev \
    --broker-base-url=$PACT_BROKER_BASE_URL \
    --verbose

# Check if MoviesAPI-event-producer can be deployed
pact-broker can-i-deploy \
    --pacticipant MoviesAPI-event-producer \
    --version=$GITHUB_SHA \
    --to-environment dev \
    --broker-base-url=$PACT_BROKER_BASE_URL \
    --verbose



================================================
FILE: scripts/env-setup.sh
================================================
#!/bin/bash

# load environment vartiables from .env file if it exists
if [ -f .env ]; then
  set -a # all the vars that are defined subsequently, are exported to the env of subsequent commands
	source .env
	set +a # turn off allexport
fi

# git related things
export GITHUB_SHA=$(git rev-parse --short HEAD)
export GITHUB_BRANCH=$(git rev-parse --abbrev-ref HEAD)


================================================
FILE: scripts/global-setup.ts
================================================
import { truncateTables } from './truncate-tables'

export default async function globalSetup() {
  console.log('Running global setup once before everything...')
  await truncateTables()
}



================================================
FILE: scripts/global-teardown.ts
================================================
import { truncateTables } from './truncate-tables'

export default async function globalTeardown(): Promise<void> {
  console.log('Running global teardown once after everything...')
  await truncateTables()
}



================================================
FILE: scripts/publish-pact-openapi.sh
================================================
#!/bin/bash

# Load environment variables
. ./scripts/env-setup.sh

# Publish the provider OpenAPI contract to Pactflow
pactflow publish-provider-contract \
    src/api-docs/openapi.json \
    --provider MoviesAPI-bi-directional \
    --provider-app-version=$GITHUB_SHA \
    --branch=$GITHUB_BRANCH \
    --content-type application/json \
    --verification-exit-code=0 \
    --verification-results ./cypress/verification-result.txt \
    --verification-results-content-type text/plain \
    --verifier cypress



================================================
FILE: scripts/record-bidirectional-deployment.sh
================================================
#!/bin/bash

# Load environment variables
. ./scripts/env-setup.sh

# Record deployment for MoviesAPI-bi-directional if the branch is main
if [ "$GITHUB_BRANCH" = "main" ]; then
    pact-broker record-deployment \
        --pacticipant MoviesAPI-bi-directional \
        --version $GITHUB_SHA \
        --environment $npm_config_env
fi



================================================
FILE: scripts/record-provider-deployment.sh
================================================
#!/bin/bash

# Exit immediately if a command exits with a non-zero status
set -e

# Load environment variables
. ./scripts/env-setup.sh

# Record provider deployment for the main branch
if [ "$GITHUB_BRANCH" = "main" ]; then
  # Record deployment for MoviesAPI
  pact-broker record-deployment \
    --pacticipant MoviesAPI \
    --version $GITHUB_SHA \
    --environment $npm_config_env
  
  # Record deployment for MoviesAPI-event-producer
  pact-broker record-deployment \
    --pacticipant MoviesAPI-event-producer \
    --version $GITHUB_SHA \
    --environment $npm_config_env
fi



================================================
FILE: scripts/setup-after-env.ts
================================================
import { truncateTables } from './truncate-tables'

// if this was a before, it would run once in each test file
// since this is beforeEach, if there are multiple it blocks, it will run before each it block in each test file
// as it is, it behaves the same as a before because there is 1 it block in the pact test
beforeEach(async () => {
  console.log('Running before each test file, on the provider...')
  await truncateTables()
})



================================================
FILE: scripts/truncate-tables.ts
================================================
import { PrismaClient } from '@prisma/client'

const prisma = new PrismaClient()

// In SQLite, TRUNCATE is not supported, so we use DELETE to remove all rows from the table.
// Unlike TRUNCATE, DELETE logs each row deletion, but it's the proper way to clear tables in SQLite.
// This script ensures that all rows are deleted, resetting the table's state for clean tests.

// Additionally, SQLite maintains an auto-increment sequence for primary keys in the `sqlite_sequence` table.
// We reset this sequence to ensure that the IDs start from 1 again after the deletion, simulating a "fresh" table.

export async function truncateTables(): Promise<void> {
  await prisma.$executeRaw`DELETE FROM "Movie"` // Clears the table by deleting all rows
  await prisma.$executeRaw`DELETE FROM sqlite_sequence WHERE name='Movie'` // Reset auto-increment if needed
  console.log('Tables truncated')
  await prisma.$disconnect()
}



================================================
FILE: scripts/one-time-scripts/create-github-issue-test.sh
================================================
#!/bin/bash

# this file is a test for your GitHub Personal Access token
# if you can create an issue, then Pact webhook will work

# Set your GitHub credentials and repository details
GITHUB_REPO_OWNER="Your_GITHUB_REPO_OWNER"                      # GitHub username or org
GITHUB_REPO_NAME="Your_repo_name"                               # GitHub repository name
GITHUB_AUTH_TOKEN="Your_GitHub_Personal_Access_Token"           # GitHub Personal Access Token with repo permissions

# Issue details
ISSUE_TITLE="Test issue"                                    # Title of the issue to be created
ISSUE_BODY="This is a test issue created via API."          # Body of the issue

# Step 1: Verify the GitHub Token
echo "Verifying GitHub token..."
TOKEN_VERIFICATION_RESPONSE=$(curl -s -o /dev/null -w "%{http_code}" -H "Authorization: Bearer $GITHUB_AUTH_TOKEN" https://api.github.com/users/$GITHUB_REPO_OWNER)

if [ "$TOKEN_VERIFICATION_RESPONSE" -ne 200 ]; then
  echo "Error: Bad credentials. Please check your GitHub token and ensure it has the required permissions."
  exit 1
else
  echo "GitHub token verified successfully."
fi

# GitHub API endpoint for creating an issue
ISSUE_URL="https://api.github.com/repos/$GITHUB_REPO_OWNER/$GITHUB_REPO_NAME/issues"

# Step 2: Run the curl command to create the issue
echo "Creating a new GitHub issue..."
curl -X POST "$ISSUE_URL" \
    -H "Accept: application/vnd.github.v3+json" \
    -H "Authorization: Bearer $GITHUB_AUTH_TOKEN" \
    -d "{\"title\": \"$ISSUE_TITLE\", \"body\": \"$ISSUE_BODY\"}"


================================================
FILE: scripts/one-time-scripts/create-pact-webhook.sh
================================================
#!/bin/bash

# Pre-setup:
# Ensure that you have pact-broker working; pact-broker version
# Get it at https://github.com/pact-foundation/pact-ruby-standalone/releases, per your OS
# You may have to set the path with
# export PATH=$PATH:$(pwd)/pact/bin
# or 
# set -x PATH $PATH (pwd)/pact/bin
# 
# Ensure that your target provider GitHub repository has a .yml workflow file in .github/workflows/ 
# configured to respond to repository_dispatch events with an event type like "contract_requiring_verification_published".
# Example: https://github.com/muratkeremozcan/pact-js-example-provider/blob/main/.github/workflows/webhook.yml

# Set the Pact Broker and GitHub tokens and URLs as environment variables
PACT_BROKER_BASE_URL="Your_PactFlow_Org_URL"
PACT_BROKER_TOKEN="Your_Pact_Token"
GITHUB_AUTH_TOKEN="Your_GitHub_Personal_Access_Token"

# Set customizable parameters
DESCRIPTION="Your_webhook_description"                # Description for the webhook
CONSUMER_NAME="Pact_consumer_name"                    # Consumer name in Pact
PROVIDER_NAME="Pact_provider_name"                    # Provider name in Pact
GITHUB_REPO_OWNER="Your_user_name"                    # GitHub username or org
GITHUB_REPO_NAME="Your_repo_name"                     # GitHub repository name

# GitHub dispatch endpoint for the repository and workflow file
REPO_DISPATCHES="https://api.github.com/repos/$GITHUB_REPO_OWNER/$GITHUB_REPO_NAME/dispatches"

# Log important parameters for verification
echo "Pact Broker Base URL: $PACT_BROKER_BASE_URL \"
echo "GitHub Dispatch Endpoint: $REPO_DISPATCHES \"
echo "Consumer: $CONSUMER_NAME \"
echo "Provider: $PROVIDER_NAME \"
echo "Description: $DESCRIPTION"

# Step 1: Verify the Pact Broker URL
echo "Checking Pact Broker accessibility..."
PACT_BROKER_STATUS=$(curl -o /dev/null -s -w "%{http_code}" \
  -H "Authorization: Bearer $PACT_BROKER_TOKEN" \
  "$PACT_BROKER_BASE_URL")

if [ "$PACT_BROKER_STATUS" -ne 200 ]; then
  echo "Error: Pact Broker URL is not accessible. Status code: $PACT_BROKER_STATUS"
  echo "Please check the PACT_BROKER_BASE_URL & PACT_BROKER_TOKEN."
  exit 1
else
  echo "Pact Broker URL is accessible."
fi

# Step 2: Check if the GitHub dispatch endpoint is accessible
echo "Checking GitHub dispatch endpoint..."
RESPONSE_STATUS=$(curl -o /dev/null -s -w "%{http_code}" -X POST "$REPO_DISPATCHES" \
    -H "Authorization: Bearer $GITHUB_AUTH_TOKEN" \
    -H "Accept: application/vnd.github.everest-preview+json" \
    -d '{"event_type": "contract_requiring_verification_published"}')

if [ "$RESPONSE_STATUS" -ne 204 ]; then
  echo "Error: Unable to access GitHub dispatch endpoint. Status code: $RESPONSE_STATUS"
  echo "Please check your GitHub token and webhook related yml. You may have to create a yml with repository_dispatch of type contract_requiring_verification_published"
  exit 1
else
  echo "GitHub dispatch endpoint is accessible."
fi

# Step 3: Run the pact-broker command to create the webhook
echo "Creating Pact webhook..."
pact-broker create-webhook "$REPO_DISPATCHES" \
    --request=POST \
    --header 'Content-Type: application/json' \
    --header 'Accept: application/vnd.github.everest-preview+json' \
    --header "Authorization: Bearer $GITHUB_AUTH_TOKEN" \
    --data '{
        "event_type": "contract_requiring_verification_published",
        "client_payload": {
            "pact_url": "${pactbroker.pactUrl}",
            "sha": "${pactbroker.providerVersionNumber}",
            "branch": "${pactbroker.providerVersionBranch}",
            "message": "Verify changed pact for ${pactbroker.consumerName} version ${pactbroker.consumerVersionNumber} branch ${pactbroker.consumerVersionBranch} by ${pactbroker.providerVersionNumber} (${pactbroker.providerVersionDescriptions})"
        }
    }' \
    --broker-base-url="$PACT_BROKER_BASE_URL" \
    --broker-token="$PACT_BROKER_TOKEN" \
    --consumer="$CONSUMER_NAME" \
    --provider="$PROVIDER_NAME" \
    --description="$DESCRIPTION" \
    --contract-requiring-verification-published



================================================
FILE: src/movie-adapter.test.ts
================================================
import type { Movie } from '@prisma/client'
import { Prisma, PrismaClient } from '@prisma/client'
import type { DeepMockProxy } from 'jest-mock-extended'
import { mockDeep } from 'jest-mock-extended'
import { MovieAdapter } from './movie-adapter'
import {
  generateMovieWithId,
  generateMovieWithoutId
} from './test-helpers/factories'

// In this test suite, we are testing the Adapter,
// which is responsible for interacting with the data source (Prisma).

// Since this is an adapter in the hexagonal architecture (ports & adapters),
// its primary role is to handle data persistence and retrieval,
// and the tests here ensure that it behaves correctly in terms of data handling and error management.
//
// By mocking PrismaClient, we isolate the tests to focus solely on the adapter's logic and its interaction with Prisma's API.
// This allows us to test how the adapter handles different scenarios,
// like successfully retrieving or creating data, and how it manages errors (e.g., database connection issues).
//
// These tests do not touch the real database, making them unit tests that ensure correctness
// of the adapter's interaction with the mocked data layer.

jest.mock('@prisma/client', () => {
  const actualPrisma = jest.requireActual('@prisma/client')
  return {
    ...actualPrisma,
    PrismaClient: jest.fn(() => mockDeep<PrismaClient>())
  }
})

describe('MovieAdapter', () => {
  let prismaMock: DeepMockProxy<PrismaClient>
  let movieAdapter: MovieAdapter

  const mockMovie: Movie = generateMovieWithId()

  beforeEach(() => {
    prismaMock = new PrismaClient() as DeepMockProxy<PrismaClient>
    movieAdapter = new MovieAdapter(prismaMock)
  })

  describe('getMovies', () => {
    it('should get all movies', async () => {
      prismaMock.movie.findMany.mockResolvedValue([mockMovie])

      const { data } = await movieAdapter.getMovies()

      expect(data).toEqual([mockMovie])
      expect(prismaMock.movie.findMany).toHaveBeenCalledTimes(1)
    })

    it('should handle errors in getMovies', async () => {
      prismaMock.movie.findMany.mockRejectedValue(
        new Error('Error fetching all movies')
      )

      const result = await movieAdapter.getMovies()
      expect(result.data).toBe(null) // empty array on error
      expect(prismaMock.movie.findMany).toHaveBeenCalledTimes(1)
    })
  })

  describe('getMovieById', () => {
    it('should get a movie by id', async () => {
      prismaMock.movie.findUnique.mockResolvedValue(mockMovie)

      // @ts-expect-error TypeScript should chill for tests here
      const { data } = await movieAdapter.getMovieById(mockMovie.id)

      expect(data).toEqual(mockMovie)
      expect(prismaMock.movie.findUnique).toHaveBeenCalledWith({
        where: { id: mockMovie.id }
      })
    })

    it('should return null if movie by id not found', async () => {
      prismaMock.movie.findUnique.mockResolvedValue(null)
      const id = 999

      // @ts-expect-error TypeScript should chill for tests here
      const { data } = await movieAdapter.getMovieById(id)

      expect(data).toBeNull()
      expect(prismaMock.movie.findUnique).toHaveBeenCalledWith({
        where: { id }
      })
    })

    it('should handle errors in getMovieById', async () => {
      prismaMock.movie.findUnique.mockRejectedValue(
        new Error('Error fetching movie by id')
      )

      // @ts-expect-error TypeScript should chill for tests here
      const { data } = await movieAdapter.getMovieById(1)

      expect(data).toBeNull()
      expect(prismaMock.movie.findUnique).toHaveBeenCalledTimes(1)
    })
  })

  describe('getMovieByName', () => {
    it('should get a movie by name', async () => {
      prismaMock.movie.findFirst.mockResolvedValue(mockMovie)

      const { data } = await movieAdapter.getMovieByName(mockMovie.name)

      expect(data).toEqual(mockMovie)
      expect(prismaMock.movie.findFirst).toHaveBeenCalledWith({
        where: { name: mockMovie.name }
      })
    })

    it('should return null if movie by name not found', async () => {
      prismaMock.movie.findFirst.mockResolvedValue(null)
      const name = 'Non-existent Movie'

      const { data } = await movieAdapter.getMovieByName(name)

      expect(data).toBeNull()
      expect(prismaMock.movie.findFirst).toHaveBeenCalledWith({
        where: { name }
      })
    })

    it('should handle errors in getMovieByName', async () => {
      prismaMock.movie.findFirst.mockRejectedValue(
        new Error('Error fetching movie by name')
      )

      const { data } = await movieAdapter.getMovieByName('Inception')

      expect(data).toBeNull() // Expect null on error
      expect(prismaMock.movie.findFirst).toHaveBeenCalledTimes(1)
    })
  })

  describe('deleteMovieById', () => {
    it('should delete a movie by id', async () => {
      prismaMock.movie.delete.mockResolvedValue(mockMovie)

      const result = await movieAdapter.deleteMovieById(mockMovie.id)

      const expectedResult = {
        status: 200,
        message: `Movie ${mockMovie.id} has been deleted`
      }
      expect(result).toStrictEqual(expectedResult)
      expect(prismaMock.movie.delete).toHaveBeenCalledWith({
        where: { id: mockMovie.id }
      })
    })

    it('should delete a movie and return false if the movie is not found', async () => {
      prismaMock.movie.delete.mockRejectedValue(
        new Prisma.PrismaClientKnownRequestError('Movie not found', {
          code: 'P2025',
          clientVersion: '1'
        })
      )
      const id = 999

      const result = await movieAdapter.deleteMovieById(id)

      const expectedResult = {
        status: 404,
        error: `Movie with ID ${id} not found`
      }
      expect(result).toStrictEqual(expectedResult)
      expect(prismaMock.movie.delete).toHaveBeenCalledWith({ where: { id } })
    })

    it('should call handleError and rethrow unexpected errors in deleteMovieById', async () => {
      // Mock an unexpected error (not a P2025 error)
      const unexpectedError = new Error('Unexpected error')
      prismaMock.movie.delete.mockRejectedValue(unexpectedError)
      const id = 999

      // Spy on the handleError method to ensure it's called
      // eslint-disable-next-line @typescript-eslint/no-explicit-any
      const handleErrorSpy = jest.spyOn(movieAdapter as any, 'handleError')

      // Expect the method to throw the error
      await expect(movieAdapter.deleteMovieById(id)).rejects.toThrow(
        'Unexpected error'
      )
      expect(handleErrorSpy).toHaveBeenCalledWith(unexpectedError)
      expect(prismaMock.movie.delete).toHaveBeenCalledTimes(1)
    })
  })

  describe('addMovie', () => {
    const movieData = { ...generateMovieWithoutId(), name: 'Inception' }
    const id = 1
    const movie = { id, ...movieData }

    it('should successfully add a movie without specifying an id', async () => {
      prismaMock.movie.findFirst.mockResolvedValue(null) // no existing movie
      prismaMock.movie.create.mockResolvedValue(movie)

      const result = await movieAdapter.addMovie(movieData)
      expect(result).toEqual({
        status: 200,
        data: movie
      })
      expect(prismaMock.movie.create).toHaveBeenCalledWith({ data: movieData })
    })

    it('should successfully add a movie specifying id', async () => {
      prismaMock.movie.findFirst.mockResolvedValue(null) // no existing movie
      prismaMock.movie.create.mockResolvedValue(movie)

      const result = await movieAdapter.addMovie(movieData, id)

      expect(result).toEqual(
        expect.objectContaining({
          status: 200,
          data: movie
        })
      )
      expect(prismaMock.movie.create).toHaveBeenCalledWith({
        data: movie
      })
    })

    it('should return 409 if the movie already exists', async () => {
      prismaMock.movie.findFirst.mockResolvedValue(movie) // existing movie

      const result = await movieAdapter.addMovie(movieData)

      expect(result).toEqual(
        expect.objectContaining({
          status: 409,
          error: `Movie ${movie.name} already exists`
        })
      )
    })

    it('should return 500 if an unexpected error occurs', async () => {
      prismaMock.movie.findFirst.mockResolvedValue(null) // No existing movie
      const error = 'Unexpected error'
      prismaMock.movie.create.mockRejectedValue(new Error(error))

      // Spy on the handleError method to ensure it's called
      // eslint-disable-next-line @typescript-eslint/no-explicit-any
      const handleErrorSpy = jest.spyOn(movieAdapter as any, 'handleError')

      const result = await movieAdapter.addMovie(movieData)
      expect(result).toEqual(
        expect.objectContaining({ status: 500, error: 'Internal server error' })
      )
      expect(handleErrorSpy).toHaveBeenCalledWith(new Error(error))
    })
  })

  describe('updateMovie', () => {
    const id = 1
    const existingMovie = {
      name: 'Inception',
      year: 2020,
      id,
      rating: 7.5,
      director: 'Christopher Nolan'
    }
    const updateMovieData = {
      name: 'The Dark Knight',
      year: 2008,
      rating: 8.5,
      director: 'Steven Spielberg'
    }
    const updatedMovie = { id, ...updateMovieData }

    it('should successfully update a movie', async () => {
      prismaMock.movie.findUnique.mockResolvedValue(existingMovie)
      prismaMock.movie.update.mockResolvedValue(updatedMovie)

      const result = await movieAdapter.updateMovie(updateMovieData, id)
      expect(result).toEqual({
        status: 200,
        data: updatedMovie
      })

      expect(prismaMock.movie.findUnique).toHaveBeenCalledWith({
        where: { id }
      })
      expect(prismaMock.movie.update).toHaveBeenCalledWith({
        where: { id },
        data: updateMovieData
      })
    })

    it('should return 404 if the movie is not found', async () => {
      prismaMock.movie.findUnique.mockResolvedValue(null)

      const result = await movieAdapter.updateMovie(updateMovieData, id)

      expect(result).toEqual({
        status: 404,
        error: `Movie with ID ${id} not found`
      })

      expect(prismaMock.movie.findUnique).toHaveBeenCalledWith({
        where: { id }
      })
      expect(prismaMock.movie.update).not.toHaveBeenCalled()
    })

    it('should return 500 if an unexpected error occurs', async () => {
      // Mock the movie to be found in the database
      prismaMock.movie.findUnique.mockResolvedValue(existingMovie)
      // Mock an unexpected error during the update
      const error = new Error('Unexpected error')
      prismaMock.movie.update.mockRejectedValue(error)

      // Spy on the handleError method to ensure it's called
      // eslint-disable-next-line @typescript-eslint/no-explicit-any
      const handleErrorSpy = jest.spyOn(movieAdapter as any, 'handleError')

      const result = await movieAdapter.updateMovie(updateMovieData, id)

      // Assertions
      expect(result).toEqual({
        status: 500,
        error: 'Internal server error'
      })
      expect(handleErrorSpy).toHaveBeenCalledWith(error)
    })
  })
})



================================================
FILE: src/movie-adapter.ts
================================================
import { Prisma, type PrismaClient } from '@prisma/client'
import type {
  GetMovieResponse,
  CreateMovieRequest,
  CreateMovieResponse,
  MovieNotFoundResponse,
  ConflictMovieResponse,
  DeleteMovieResponse,
  UpdateMovieRequest,
  UpdateMovieResponse
} from './@types'
import type { MovieRepository } from './movie-repository'

// MovieAdapter: This is the implementation of the MovieRepository interface,
// responsible for interacting with a specific data source (like Prisma).
// It's an adapter in hexagonal architecture.

// The key benefits are improved flexibility and testability:
// 1) Flexibility: the business logic (MovieService) is decoupled from the data access layer (MovieAdapter),
// making it easier to swap or replace adapters (e.g., switch from Prisma to an API or mock implementation)
// without changing the business logic.

// 2) Testability: this separation allows for isolated unit tests of each component,
// meaning you can test the business logic independently from the data layer,
// and mock the repository for more controlled and efficient tests.

export class MovieAdapter implements MovieRepository {
  private readonly prisma: PrismaClient

  constructor(prisma: PrismaClient) {
    this.prisma = prisma
  }

  /*
  General Error Handling with unknown in TypeScript:

    try {
      // Code that might throw an error
    } catch (error: unknown) {
      if (error instanceof Error) {
        // Handle the error as an instance of the Error class
        console.error(error.message);
      } else {
        // Handle the case where the error is not an instance of Error
        console.error("An unknown error occurred:", error);
      }
    }
  */
  // Centralized error handling method
  private handleError(error: unknown): void {
    if (error instanceof Prisma.PrismaClientKnownRequestError) {
      console.error('Prisma error code:', error.code, 'Message:', error.message)
    } else if (error instanceof Error) {
      console.error('Error:', error.message)
    } else {
      console.error('An unknown error occurred:', error)
    }
  }

  // Get all movies
  async getMovies(): Promise<GetMovieResponse> {
    try {
      const movies = await this.prisma.movie.findMany()

      if (movies.length > 0) {
        return {
          status: 200,
          data: movies,
          error: null
        }
      } else {
        return {
          status: 200,
          data: [],
          error: null
        }
      }
    } catch (error) {
      this.handleError(error)

      return {
        status: 500,
        data: null,
        error: 'Failed to retrieve movies'
      }
    }
  }

  // Get a movie by its ID
  async getMovieById(
    id: number
  ): Promise<GetMovieResponse | MovieNotFoundResponse> {
    try {
      const movie = await this.prisma.movie.findUnique({ where: { id } })
      if (movie) {
        return {
          status: 200,
          data: movie, // return the movie object
          error: null // no error if successful
        }
      }
      return {
        status: 404,
        data: null, // return null if not found
        error: `Movie with ID ${id} not found`
      }
    } catch (error) {
      this.handleError(error)
      return {
        status: 500,
        data: null, // return null in case of failure
        error: 'Internal server error'
      }
    }
  }

  // Get a movie by its name
  async getMovieByName(name: string): Promise<GetMovieResponse> {
    try {
      const movie = await this.prisma.movie.findFirst({ where: { name } })

      if (movie) {
        return {
          status: 200,
          data: movie,
          error: null
        }
      } else {
        // Return a structured response if no movie is found
        return {
          status: 404,
          data: null,
          error: `Movie with name "${name}" not found`
        }
      }
    } catch (error) {
      this.handleError(error)
      return {
        status: 500,
        data: null,
        error: 'Internal server error'
      }
    }
  }

  // Delete a movie by its ID
  async deleteMovieById(
    id: number
  ): Promise<DeleteMovieResponse | MovieNotFoundResponse> {
    try {
      await this.prisma.movie.delete({
        where: { id }
      })
      return {
        status: 200,
        message: `Movie ${id} has been deleted`
      }
    } catch (error) {
      // Handle specific error codes (e.g., movie not found)
      if (
        error instanceof Prisma.PrismaClientKnownRequestError &&
        error.code === 'P2025'
      ) {
        return {
          status: 404,
          error: `Movie with ID ${id} not found`
        }
      }
      this.handleError(error)
      throw error // Re-throw other errors
    }
  }

  // Add a new movie with validation
  async addMovie(
    data: CreateMovieRequest,
    id?: number
  ): Promise<CreateMovieResponse | ConflictMovieResponse> {
    try {
      // Check if the movie already exists
      const existingMovie = await this.prisma.movie.findFirst({
        where: { name: data.name }
      })

      if (existingMovie) {
        return { status: 409, error: `Movie ${data.name} already exists` }
      }

      // Create the new movie
      const movie = await this.prisma.movie.create({
        data: id ? { ...data, id } : data
      })

      return {
        status: 200,
        data: movie
      }
    } catch (error) {
      this.handleError(error)
      return { status: 500, error: 'Internal server error' }
    }
  }

  async updateMovie(
    data: Partial<UpdateMovieRequest>,
    id: number
  ): Promise<
    UpdateMovieResponse | MovieNotFoundResponse | ConflictMovieResponse
  > {
    try {
      const existingMovie = await this.prisma.movie.findUnique({
        where: { id }
      })
      if (!existingMovie)
        return { status: 404, error: `Movie with ID ${id} not found` }

      const updatedMovie = await this.prisma.movie.update({
        where: { id },
        data
      })

      return {
        status: 200,
        data: updatedMovie
      }
    } catch (error) {
      this.handleError(error)
      return { status: 500, error: 'Internal server error' }
    }
  }
}



================================================
FILE: src/movie-repository.ts
================================================
import type {
  GetMovieResponse,
  CreateMovieRequest,
  CreateMovieResponse,
  MovieNotFoundResponse,
  ConflictMovieResponse,
  DeleteMovieResponse,
  UpdateMovieRequest,
  UpdateMovieResponse
} from './@types'

// MovieRepository: this is the interface/contract that defines the methods
// for interacting with the data layer.
// It's a port in hexagonal architecture.

/*
  API (Driving Adapter - entry point)
                  |
                  v
    +----------------------------+
    |        MovieService        |
    | (Application Core/Hexagon) |
    +----------------------------+
                  |
                  v
      MovieRepository (Port)
                  |
                  v
MovieAdapter (Driven Adapter - 2ndary, interacts with outside)
                  |
                  v
              Database
*/

export interface MovieRepository {
  getMovies(): Promise<GetMovieResponse>
  getMovieById(id: number): Promise<GetMovieResponse | MovieNotFoundResponse>
  getMovieByName(
    name: string
  ): Promise<GetMovieResponse | MovieNotFoundResponse>
  deleteMovieById(
    id: number
  ): Promise<DeleteMovieResponse | MovieNotFoundResponse>
  addMovie(
    data: CreateMovieRequest,
    id?: number
  ): Promise<CreateMovieResponse | ConflictMovieResponse>
  updateMovie(
    data: UpdateMovieRequest,
    id: number
  ): Promise<
    UpdateMovieResponse | MovieNotFoundResponse | ConflictMovieResponse
  >
}



================================================
FILE: src/movie-service.test.ts
================================================
import { MovieService } from './movie-service'
import type { MovieRepository } from './movie-repository'
import type { Movie } from '@prisma/client'
import { generateMovieWithoutId } from './test-helpers/factories'

// because we use ports & adapters / hex pattern,
// the data layer (MovieRepository) is a dependency we can mock
// this ensures we're testing only the business logic and not the database.

// In this test suite, we are focusing on the Service, which encapsulates the business logic.
// Since we are following the ports & adapters (hexagonal) architecture,
// the service depends on a port/interface/contract, defined by the Repository.

// We mock the data layer (Repository) to isolate and test only the business logic in the service.
// By mocking the data layer (Repository), we ensure that the tests focus purely on how the service behaves:
// handling input, interacting with the repository, and returning the appropriate output or errors.
// This approach allows us to write unit tests that are fast, isolated, and independent of any external systems like databases.

describe('MovieService', () => {
  let movieService: MovieService
  let mockMovieRepository: jest.Mocked<MovieRepository>
  const id = 1
  const mockMovie: Movie = { id, ...generateMovieWithoutId() }
  const mockMovieResponse = { status: 200, data: mockMovie, error: null }
  const mockMoviesResponse = {
    status: 200,
    data: [mockMovie],
    error: null
  }
  const notFoundResponse = { status: 404, data: null, error: null }

  beforeEach(() => {
    mockMovieRepository = {
      getMovies: jest.fn(),
      getMovieById: jest.fn(),
      getMovieByName: jest.fn(),
      deleteMovieById: jest.fn(),
      addMovie: jest.fn(),
      updateMovie: jest.fn()
    } as jest.Mocked<MovieRepository>

    movieService = new MovieService(mockMovieRepository)
  })

  it('should get all movies', async () => {
    mockMovieRepository.getMovies.mockResolvedValue(mockMoviesResponse)

    const { data } = await movieService.getMovies()

    expect(data).toEqual([mockMovie])
    expect(mockMovieRepository.getMovies).toHaveBeenCalledTimes(1)
  })

  it('should get a movie by id', async () => {
    mockMovieRepository.getMovieById.mockResolvedValue(mockMovieResponse)

    // @ts-expect-error TypeScript should chill for tests here
    const { data } = await movieService.getMovieById(mockMovie.id)

    expect(data).toEqual(mockMovie)
    expect(mockMovieRepository.getMovieById).toHaveBeenCalledWith(mockMovie.id)
  })

  it('should return null if movie by id not found', async () => {
    mockMovieRepository.getMovieById.mockResolvedValue(notFoundResponse)
    const id = 999

    // @ts-expect-error TypeScript should chill for tests here
    const { data } = await movieService.getMovieById(id)

    expect(data).toBeNull()
    expect(mockMovieRepository.getMovieById).toHaveBeenCalledWith(id)
  })

  it('should get a movie by name', async () => {
    mockMovieRepository.getMovieByName.mockResolvedValue(mockMovieResponse)

    // @ts-expect-error TypeScript should chill for tests here
    const { data } = await movieService.getMovieByName(mockMovie.name)

    expect(data).toEqual(mockMovie)
    expect(mockMovieRepository.getMovieByName).toHaveBeenCalledWith(
      mockMovie.name
    )
  })

  it('should return null if movie by name not found', async () => {
    mockMovieRepository.getMovieByName.mockResolvedValue(notFoundResponse)
    const name = 'Non-existent Movie'

    // @ts-expect-error TypeScript should chill for tests here
    const { data } = await movieService.getMovieByName(name)

    expect(data).toBeNull()
    expect(mockMovieRepository.getMovieByName).toHaveBeenCalledWith(name)
  })

  it('should add a new movie', async () => {
    const expectedResult = {
      status: 200,
      data: mockMovie,
      error: undefined
    }
    mockMovieRepository.addMovie.mockResolvedValue(expectedResult)

    const result = await movieService.addMovie(mockMovie)

    expect(result).toEqual(expectedResult)
    expect(mockMovieRepository.addMovie).toHaveBeenCalledWith(
      mockMovie,
      undefined
    )
  })

  it('should update a movie', async () => {
    const expectedResult = {
      status: 200,
      data: mockMovie,
      error: undefined
    }
    mockMovieRepository.updateMovie.mockResolvedValue(expectedResult)

    const result = await movieService.updateMovie(
      { name: mockMovie.name, year: mockMovie.year },
      id
    )

    expect(result).toEqual(expectedResult)
    expect(mockMovieRepository.updateMovie).toHaveBeenCalledWith(
      { name: mockMovie.name, year: mockMovie.year },
      id
    )
  })

  it('should delete a movie by id', async () => {
    const expectedResult = {
      status: 200,
      message: 'Movie deleted'
    }
    mockMovieRepository.deleteMovieById.mockResolvedValue(expectedResult)

    const result = await movieService.deleteMovieById(1)

    expect(result).toBe(expectedResult)
    expect(mockMovieRepository.deleteMovieById).toHaveBeenCalledWith(1)
  })

  it('should return 400 if addMovie validation fails', async () => {
    const invalidMovieData = {
      name: '',
      year: 1899,
      rating: 7.5,
      director: 'Christopher Nolan'
    } // Invalid year, empty name

    const result = await movieService.addMovie(invalidMovieData)
    expect(result).toEqual(
      expect.objectContaining({
        status: 400,
        error:
          'name - String must contain at least 1 character(s), year - Number must be greater than or equal to 1900'
      })
    )
  })

  it('should return 400 if updateMovie validation fails', async () => {
    const invalidMovieData = { name: '', year: 1899 } // Invalid year, empty name

    const result = await movieService.updateMovie(invalidMovieData, id)
    expect(result).toEqual(
      expect.objectContaining({
        status: 400,
        error:
          'name - String must contain at least 1 character(s), year - Number must be greater than or equal to 1900'
      })
    )
  })

  it('should try to delete and not find a movie', async () => {
    const expectedResult = {
      status: 404,
      message: 'Movie not found'
    }
    mockMovieRepository.deleteMovieById.mockResolvedValue(expectedResult)
    const id = 999

    const result = await movieService.deleteMovieById(id)

    expect(result).toEqual(expectedResult)
    expect(mockMovieRepository.deleteMovieById).toHaveBeenCalledWith(id)
  })
})



================================================
FILE: src/movie-service.ts
================================================
import type { MovieRepository } from './movie-repository'
import type {
  GetMovieResponse,
  CreateMovieRequest,
  CreateMovieResponse,
  MovieNotFoundResponse,
  ConflictMovieResponse,
  DeleteMovieResponse,
  UpdateMovieRequest,
  UpdateMovieResponse
} from './@types'
import type { ZodSchema } from 'zod'
import { CreateMovieSchema, UpdateMovieSchema } from './@types/schema'

// In the context of the MovieService, what you care about is the contract/interface
// (i.e., the methods defined by the MovieRepository interface).
// The service doesn't care if it's using Prisma, a REST API, or an in-memory database
// it only cares that the object implements MovieRepository.

/*
  API (Driving Adapter - entry point)
                  |
                  v
    +----------------------------+
    |        MovieService        |
    | (Application Core/Hexagon) |
    +----------------------------+
                  |
                  v
      MovieRepository (Port)
                  |
                  v
MovieAdapter (Driven Adapter - 2ndary, interacts with outside)
                  |
                  v
              Database
*/

export class MovieService {
  constructor(private readonly movieRepository: MovieRepository) {
    this.movieRepository = movieRepository
  }

  async getMovies(): Promise<GetMovieResponse> {
    return this.movieRepository.getMovies()
  }

  async getMovieById(
    id: number
  ): Promise<GetMovieResponse | MovieNotFoundResponse> {
    return this.movieRepository.getMovieById(id)
  }

  async getMovieByName(
    name: string
  ): Promise<GetMovieResponse | MovieNotFoundResponse> {
    return this.movieRepository.getMovieByName(name)
  }

  async deleteMovieById(
    id: number
  ): Promise<DeleteMovieResponse | MovieNotFoundResponse> {
    return this.movieRepository.deleteMovieById(id)
  }

  async addMovie(
    data: CreateMovieRequest,
    id?: number
  ): Promise<CreateMovieResponse | ConflictMovieResponse> {
    // Zod Key feature 3: safeParse
    // Zod note: if you have a frontend, you can use the schema + safeParse there
    // in order to perform form validation before sending the data to the server
    const validationResult = validateSchema(CreateMovieSchema, data)
    if (!validationResult.success)
      return { status: 400, error: validationResult.error }

    return this.movieRepository.addMovie(data, id)
  }

  async updateMovie(
    data: UpdateMovieRequest,
    id: number
  ): Promise<
    UpdateMovieResponse | MovieNotFoundResponse | ConflictMovieResponse
  > {
    // Zod Key feature 3: safeParse
    // Zod note: if you have a frontend, you can use the schema + safeParse there
    // in order to perform form validation before sending the data to the server
    const validationResult = validateSchema(UpdateMovieSchema, data)
    if (!validationResult.success)
      return { status: 400, error: validationResult.error }

    return this.movieRepository.updateMovie(data, id)
  }
}

// helper function for schema validation
function validateSchema<T>(
  schema: ZodSchema<T>,
  data: unknown
): { success: true; data: T } | { success: false; error: string } {
  const result = schema.safeParse(data)
  if (result.success) {
    return { success: true, data: result.data }
  } else {
    const errorMessages = result.error.errors
      .map((err) => `${err.path.join('.')} - ${err.message}`)
      .join(', ')
    return { success: false, error: errorMessages }
  }
}

/*
How would this look in a lambda?

Lambda Function (Driving Adapter)
          |
          v
      MovieService
          |
          v
   MovieRepository (Port)
          |
          v
   MovieAdapter (Driven Adapter)
          |
          v
      Database

// example lambda
// lambda functions replace the Express routes as driving adapters

import { MovieService } from './movie-service'
import { MovieAdapter } from './movie-adapter'
import { PrismaClient } from '@prisma/client'

const prisma = new PrismaClient()
const movieRepository = new MovieAdapter(prisma)
const movieService = new MovieService(movieRepository)

export const getMovie = async (event) => {
  const id = parseInt(event.pathParameters.id, 10)
  return movieService.getMovieById(id)
}


*/



================================================
FILE: src/provider-contract.pacttest.ts
================================================
import { Verifier } from '@pact-foundation/pact'
import { stateHandlers } from './test-helpers/state-handlers'
import { buildVerifierOptions } from './test-helpers/pact-utils/build-verifier-options'
import { truncateTables } from '../scripts/truncate-tables'
import { requestFilter } from './test-helpers/pact-utils/pact-request-filter'

// 1) Run the provider service
// 2) Setup the provider verifier options
// 3) Write & execute the provider contract test

const PACT_BREAKING_CHANGE = process.env.PACT_BREAKING_CHANGE || 'false'
const PACT_ENABLE_PENDING = process.env.PACT_ENABLE_PENDING || 'false'
const GITHUB_BRANCH = process.env.GITHUB_BRANCH || 'local'

describe('Pact Verification Pact Classic', () => {
  // 2) Setup the provider verifier options
  const port = process.env.PORT || '3001'
  const options = buildVerifierOptions({
    provider: 'MoviesAPI',
    consumer: 'WebConsumer', // with multiple pact test files, best to specify the consumer
    includeMainAndDeployed: PACT_BREAKING_CHANGE !== 'true', // if it is a breaking change, set the env var
    enablePending: PACT_ENABLE_PENDING === 'true',
    // logLevel: 'debug',
    port,
    stateHandlers,
    requestFilter,
    beforeEach: async () => {
      // console.log('I run before each test coming from the consumer...')
      await truncateTables()
      return Promise.resolve()
    }
    // afterEach: () => {
    //   console.log('I run after each test coming from the consumer...')
    //   return Promise.resolve()
    // }
  })
  const verifier = new Verifier(options)

  // our produceMovieEvent has some console.logs which we don't need during tests
  // but you can comment these out if you want to see them.
  beforeAll(() => {
    jest.spyOn(console, 'log').mockImplementation(() => {})
    jest.spyOn(console, 'error').mockImplementation(() => {})
  })
  afterAll(() => {
    jest.restoreAllMocks()
  })

  it('should validate the expectations of WebConsumer', async () => {
    // 3) Write & execute the provider contract test
    try {
      const output = await verifier.verifyProvider()
      console.log('Pact Verification Complete!')
      console.log('Result:', output)
    } catch (error) {
      console.error('Pact Verification Failed:', error)

      if (PACT_BREAKING_CHANGE === 'true' && GITHUB_BRANCH === 'main') {
        console.log(
          'Ignoring Pact verification failures due to breaking change on main branch.'
        )
      } else {
        throw error // Re-throw the error to fail the test
      }
    }
  })
})

// Selective testing note: If you prefix your test command (e.g. npm t) with the following environment variables,
//  you can selectively run a specific interaction during provider verification.
// You can also filter tests to a certain consumer.
// https://docs.pact.io/implementation_guides/javascript/docs/troubleshooting
// PACT_DESCRIPTION:   	   select all tests that contain this string in its description(from the test output, or the pact file)
// PACT_PROVIDER_STATE:	   select all tests that contain this string in one of its providerState
// PACT_PROVIDER_NO_STATE: set to TRUE to select all tests what don't have any providerState
/*

examples:

PACT_DESCRIPTION="a request to get all movies" npm run test:provider
PACT_DESCRIPTION="a request to get all movies" PACT_PROVIDER_STATE="An existing movie exists" npm run test:provider

PACT_PROVIDER_STATE="Has a movie with a specific ID" npm run test:provider
PACT_DESCRIPTION="a request to a specific movie" PACT_PROVIDER_STATE="Has a movie with a specific ID" npm run test:provider

PACT_DESCRIPTION="a request to delete a movie that exists" PACT_PROVIDER_STATE="Has a movie with a specific ID" npm run test:provider

PACT_PROVIDER_NO_STATE=true npm run test:provider

# to relax the can:i:deploy and only check against matching branches
PACT_BREAKING_CHANGE=true npm run test:provider
*/



================================================
FILE: src/provider-kafka.pacttest.ts
================================================
import { MessageProviderPact } from '@pact-foundation/pact'
import { messageProviders } from './test-helpers/message-providers'
import { stateHandlers } from './test-helpers/state-handlers'
import { buildMessageVerifierOptions } from './test-helpers/pact-utils/build-verifier-options'

// 1) Run the provider service, optionally start the kafka cluster (if you want to see the console logs)
// 2) Setup the provider message verifier options
// 3) Write & execute the provider message queue test

const PACT_BREAKING_CHANGE = process.env.PACT_BREAKING_CHANGE || 'false'
const PACT_ENABLE_PENDING = process.env.PACT_ENABLE_PENDING || 'false'
const GITHUB_BRANCH = process.env.GITHUB_BRANCH || 'local'

describe('Pact Verification for Message queue', () => {
  const options = buildMessageVerifierOptions({
    provider: 'MoviesAPI-event-producer', // ensure unique provider name for message pacts
    consumer: 'WebConsumer-event-consumer', // with multiple pact test files, best to specify the consumer
    includeMainAndDeployed: PACT_BREAKING_CHANGE !== 'true', // if it is a breaking change, set the env var
    enablePending: PACT_ENABLE_PENDING === 'true',
    // logLevel: 'debug',
    messageProviders, // the bread and butter of the test is here
    stateHandlers
  })
  const verifier = new MessageProviderPact(options)

  // our produceMovieEvent has some console.logs which we don't need during tests
  // but you can comment these out if you want to see them.
  beforeAll(() => {
    jest.spyOn(console, 'log').mockImplementation(() => {})
    jest.spyOn(console, 'error').mockImplementation(() => {})
  })
  afterAll(() => {
    jest.restoreAllMocks()
  })

  it('should validate the expectations of WebConsumer-event-consumer', async () => {
    try {
      const output = await verifier.verify()
      console.log('Pact Message Verification Complete!')
      console.log('Result:', output)
    } catch (error) {
      console.error('Pact Message Verification Failed:', error)

      if (PACT_BREAKING_CHANGE === 'true' && GITHUB_BRANCH === 'main') {
        console.log(
          'Ignoring Pact Message verification failures due to breaking change on main branch.'
        )
      } else {
        throw error // Re-throw the error to fail the test
      }
    }
  })
})

// Selective testing note: If you prefix your test command (e.g. npm t) with the following environment variables,
//  you can selectively run a specific interaction during provider verification.
// You can also filter tests to a certain consumer.
// https://docs.pact.io/implementation_guides/javascript/docs/troubleshooting
// PACT_DESCRIPTION:   	   select all tests that contain this string in its description(from the test output, or the pact file)
// PACT_PROVIDER_STATE:	   select all tests that contain this string in one of its providerState
// PACT_PROVIDER_NO_STATE: set to TRUE to select all tests what don't have any providerState
/*

examples:

PACT_DESCRIPTION="a request to get all movies" npm run test:provider
PACT_DESCRIPTION="a request to get all movies" PACT_PROVIDER_STATE="An existing movie exists" npm run test:provider

PACT_PROVIDER_STATE="Has a movie with a specific ID" npm run test:provider
PACT_DESCRIPTION="a request to a specific movie" PACT_PROVIDER_STATE="Has a movie with a specific ID" npm run test:provider

PACT_DESCRIPTION="a request to delete a movie that exists" PACT_PROVIDER_STATE="Has a movie with a specific ID" npm run test:provider

PACT_PROVIDER_NO_STATE=true npm run test:provider

# to relax the can:i:deploy and only check against matching branches
PACT_BREAKING_CHANGE=true npm run test:provider
*/



================================================
FILE: src/routes.ts
================================================
import type { Movie } from '@prisma/client'
import { PrismaClient } from '@prisma/client'
import { Router } from 'express'
import { authMiddleware } from './middleware/auth-middleware'
import { validateId } from './middleware/validate-movie-id'
import { MovieAdapter } from './movie-adapter'
import { MovieService } from './movie-service'
import { formatResponse } from './utils/format-response'
import { produceMovieEvent } from './events/movie-events'

export const moviesRoute = Router()

// apply auth middleware to all routes under this prefix
moviesRoute.use(authMiddleware)

// Initialize PrismaClient
const prisma = new PrismaClient()
// Create the MovieAdapter and inject it into MovieService
const movieAdapter = new MovieAdapter(prisma)
const movieService = new MovieService(movieAdapter)

// Routes are focused on handling HTTP requests and responses,
// delegating business logic to the MoviesService (Separation of Concerns)

moviesRoute.get('/', async (req, res) => {
  const name = req.query.name

  if (typeof name === 'string') {
    const movie = await movieService.getMovieByName(name)
    return formatResponse(res, movie)
  } else if (name) {
    return res.status(400).json({ error: 'Invalid movie name provided' })
  } else {
    const allMovies = await movieService.getMovies()
    return formatResponse(res, allMovies)
  }
})

moviesRoute.post('/', async (req, res) => {
  const result = await movieService.addMovie(req.body)

  if ('data' in result) {
    const movie = result.data
    await produceMovieEvent(movie, 'created')
  }

  return formatResponse(res, result)
})

moviesRoute.get('/:id', validateId, async (req, res) => {
  const result = await movieService.getMovieById(Number(req.params.id))
  return formatResponse(res, result)
})

moviesRoute.put('/:id', validateId, async (req, res) => {
  const result = await movieService.updateMovie(req.body, Number(req.params.id))

  if ('data' in result) {
    const movie = result.data
    await produceMovieEvent(movie, 'updated')
  }

  return formatResponse(res, result)
})

moviesRoute.delete('/:id', validateId, async (req, res) => {
  const movieId = Number(req.params.id)
  // check if the movie exists before attempting to delete it
  const movieResponse = await movieService.getMovieById(movieId)

  // proceed only if the movie exists
  if ('data' in movieResponse && movieResponse.data) {
    const movie = movieResponse.data as Movie
    const result = await movieService.deleteMovieById(movieId)

    if ('message' in result) {
      await produceMovieEvent(movie, 'deleted')
    }

    return formatResponse(res, result)
  } else {
    // If the movie was not found, return a 404 or an appropriate error response
    return formatResponse(res, {
      status: 404,
      error: `Movie with ID ${movieId} not found`
    })
  }
})



================================================
FILE: src/server-config.ts
================================================
import cors from 'cors'
import express, { json } from 'express'
import { moviesRoute } from './routes'

const server = express()
server.use(
  cors({
    origin: 'http://localhost:3000' // allow only your React app, add other urls if you have deployments
  })
)

server.use(json())

server.get('/', (_, res) => {
  res.status(200).json({ message: 'Server is running' })
})

server.use('/movies', moviesRoute)

server.use('/auth/fake-token', (_, res) => {
  const token = `Bearer ${new Date().toISOString()}`
  return res.status(200).json({ token, status: 200 })
})

export { server }



================================================
FILE: src/server.ts
================================================
import { server } from './server-config'

const port = process.env.PORT || 3001

server.listen(port, () => console.log(`Listening on port ${port}...`))



================================================
FILE: src/@types/index.ts
================================================
export type * from './movie-types'
export type * from './movie-event-types'



================================================
FILE: src/@types/movie-event-types.ts
================================================
export type MovieAction = 'created' | 'updated' | 'deleted'

type Event<T extends string> = {
  topic: `movie-${T}`
  messages: Array<{
    key: string // id as a string
    value: string // serialized movie object
  }>
}

export type MovieEvent = Event<MovieAction>



================================================
FILE: src/@types/movie-types.ts
================================================
import type { z } from 'zod'

import type {
  CreateMovieResponseSchema,
  CreateMovieSchema,
  GetMovieResponseUnionSchema,
  MovieNotFoundResponseSchema,
  DeleteMovieResponseSchema,
  ConflictMovieResponseSchema,
  UpdateMovieSchema,
  UpdateMovieResponseSchema
} from './schema'

// Zod key feature 2: link the schemas to the types

export type CreateMovieRequest = z.infer<typeof CreateMovieSchema>

export type CreateMovieResponse = z.infer<typeof CreateMovieResponseSchema>

export type ConflictMovieResponse = z.infer<typeof ConflictMovieResponseSchema>

export type GetMovieResponse = z.infer<typeof GetMovieResponseUnionSchema>

export type MovieNotFoundResponse = z.infer<typeof MovieNotFoundResponseSchema>

export type DeleteMovieResponse = z.infer<typeof DeleteMovieResponseSchema>

export type UpdateMovieRequest = z.infer<typeof UpdateMovieSchema>

export type UpdateMovieResponse = z.infer<typeof UpdateMovieResponseSchema>



================================================
FILE: src/@types/schema.ts
================================================
import { z } from 'zod'
import { extendZodWithOpenApi } from '@asteasolutions/zod-to-openapi'

// Zod Key feature 1: define the schema with Zod (and expand it with zod-to-openapi)

// Generate OpenAPI Docs with Zod step 1) Define Schemas (with zod)
// Each field is annotated with OpenAPI-specific metadata such as example and description.

// extends Zod with OpenAPI support
extendZodWithOpenApi(z)

export const CreateMovieSchema = z
  .object({
    id: z
      .number()
      .int()
      .optional()
      .openapi({ example: 1, description: 'Movie ID ' }),
    name: z
      .string()
      .min(1)
      .openapi({ example: 'Inception', description: 'Movie name' }),
    year: z
      .number()
      .int()
      .min(1900)
      .max(2024)
      .openapi({ example: 2010, description: 'Release year' }),
    rating: z.number().openapi({ example: 7.5, description: 'Rating' }),
    director: z.string().min(1).openapi({
      example: 'Christopher Nolan',
      description: 'Director'
    })
  })
  .openapi('CreateMovieRequest')

export const CreateMovieResponseSchema = z
  .object({
    status: z
      .number()
      .int()
      .openapi({ example: 200, description: 'Response status code' }),
    data: z.object({
      id: z.number().int().openapi({ example: 1, description: 'Movie ID' }),
      name: z
        .string()
        .openapi({ example: 'Inception', description: 'Movie name' }),
      year: z
        .number()
        .int()
        .openapi({ example: 2010, description: 'Release year' }),
      rating: z.number().openapi({ example: 7.5, description: 'Rating' }),
      director: z.string().openapi({
        example: 'Christopher Nolan',
        description: 'Director'
      })
    }),
    error: z
      .string()
      .optional()
      .openapi({ description: 'Error message, if any' })
  })
  .openapi('CreateMovieResponse')

export const ConflictMovieResponseSchema = z.object({
  status: z
    .number()
    .int()
    .openapi({ example: 409, description: 'Conflict status code' }),
  error: z
    .string()
    .openapi({ example: 'Movie already exists', description: 'Error message' })
})

const movieObj = {
  id: z.number().openapi({ example: 1, description: 'Movie ID' }),
  name: z.string().openapi({ example: 'Inception', description: 'Movie name' }),
  year: z.number().openapi({ example: 2010, description: 'Release year' }),
  rating: z.number().openapi({ example: 7.5, description: 'Rating' }),
  director: z.string().openapi({
    example: 'Christopher Nolan',
    description: 'Director'
  })
}

export const GetMovieResponseUnionSchema = z
  .object({
    status: z
      .number()
      .int()
      .openapi({ example: 200, description: 'Response status code' }),
    data: z.union([
      z
        .object(movieObj)
        .nullable()
        .openapi({
          description: 'Movie details or null if not found',
          example: {
            id: 1,
            name: 'Inception',
            year: 2010,
            rating: 7.5,
            director: 'Christopher Nolan'
          }
        }),
      z.array(z.object(movieObj)).openapi({
        description: 'List of movies or an empty array if no movies exist',
        example: []
      })
    ]),
    error: z.string().nullable().optional().openapi({
      description: 'Error message if an error occurred, otherwise null',
      example: null
    })
  })
  .openapi('GetMovieResponse')

export const MovieNotFoundResponseSchema = z.object({
  status: z
    .number()
    .int()
    .openapi({ example: 404, description: 'Response status code' }),
  error: z
    .string()
    .openapi({ example: 'Movie not found', description: 'Error message' })
})

export const DeleteMovieResponseSchema = z.object({
  status: z
    .number()
    .int()
    .openapi({ example: 200, description: 'Response status code' }),
  message: z.string().openapi({
    example: 'Movie {id} has been deleted',
    description: 'Success message for the deleted movie'
  })
})

export const UpdateMovieSchema = z
  .object({
    id: z.number().optional().openapi({ example: 1, description: 'Movie ID' }),
    name: z
      .string()
      .min(1)
      .optional()
      .openapi({ example: 'Inception', description: 'Movie name' }),
    year: z
      .number()
      .int()
      .min(1900)
      .max(2024)
      .optional()
      .openapi({ example: 2010, description: 'Release year' }),
    rating: z
      .number()
      .optional()
      .openapi({ example: 7.5, description: 'Rating' }),
    director: z.string().min(1).optional().openapi({
      example: 'Christopher Nolan',
      description: 'Director'
    })
  })
  .openapi('UpdateMovieRequest')

export const UpdateMovieResponseSchema = z
  .object({
    status: z
      .number()
      .int()
      .openapi({ example: 200, description: 'Response status code' }),
    data: z
      .object({
        id: z.number().openapi({ example: 1, description: 'Movie ID' }),
        name: z
          .string()
          .openapi({ example: 'Inception', description: 'Movie name' }),
        year: z
          .number()
          .openapi({ example: 2010, description: 'Release year' }),
        rating: z.number().openapi({ example: 7.5, description: 'Rating' }),
        director: z.string().openapi({
          example: 'Christopher Nolan',
          description: 'Director'
        })
      })
      .openapi({ description: 'Updated movie data' }),
    error: z
      .string()
      .optional()
      .openapi({ description: 'Error message, if any' })
  })
  .openapi('UpdatedMovieResponse')



================================================
FILE: src/api-docs/openapi-generator.ts
================================================
import {
  OpenAPIRegistry,
  OpenApiGeneratorV31
} from '@asteasolutions/zod-to-openapi'
import {
  ConflictMovieResponseSchema,
  CreateMovieResponseSchema,
  CreateMovieSchema,
  DeleteMovieResponseSchema,
  MovieNotFoundResponseSchema,
  GetMovieResponseUnionSchema,
  UpdateMovieSchema,
  UpdateMovieResponseSchema
} from '../@types/schema'
import type { ParameterObject } from 'openapi3-ts/oas31'

// this file registers the schemas and generates the OpenAPI document.
// it’s the logic responsible for creating the OpenAPI structure
// based on the Zod schemas.

// 2) Register Schemas with the OpenAPI Registry
const registry = new OpenAPIRegistry()
registry.register('CreateMovieRequest', CreateMovieSchema)
registry.register('CreateMovieResponse', CreateMovieResponseSchema)
registry.register('GetMovieResponse', GetMovieResponseUnionSchema)
registry.register('MovieNotFound', MovieNotFoundResponseSchema)
registry.register('DeleteMovieMessage', DeleteMovieResponseSchema)
registry.register('ConflictMovieResponse', ConflictMovieResponseSchema)
registry.register('UpdateMovieRequest', UpdateMovieSchema)
registry.register('UpdateMovieResponse', UpdateMovieResponseSchema)

// Constants to avoid repetition
const MOVIE_ID_PARAM: ParameterObject = {
  name: 'id',
  in: 'path',
  required: true,
  schema: { type: 'string' },
  description: 'Movie ID'
}
const MOVIE_NAME_PARAM: ParameterObject = {
  name: 'name',
  in: 'query',
  required: false,
  schema: { type: 'string' },
  description: 'Movie name to search for'
}

// Register paths
// health check
registry.registerPath({
  method: 'get',
  path: '/',
  summary: 'Health check',
  responses: {
    200: {
      description: 'Server is running',
      content: {
        'application/json': {
          schema: {
            type: 'object',
            properties: {
              message: { type: 'string', example: 'Server is running' }
            }
          }
        }
      }
    }
  }
})

// Register path for getting all movies or filtering by name via query parameter
registry.registerPath({
  method: 'get',
  path: '/movies',
  summary: 'Get all movies or filter by name',
  description:
    'Retrieve a list of all movies. Optionally, provide a query parameter "name" to filter by a specific movie name.',
  parameters: [MOVIE_NAME_PARAM], // Query param for filtering by name
  responses: {
    200: {
      description:
        'List of movies or a specific movie if the "name" query parameter is provided',
      content: { 'application/json': { schema: GetMovieResponseUnionSchema } }
    },
    404: {
      description:
        'Movie not found if the name is provided and does not match any movie',
      content: { 'application/json': { schema: MovieNotFoundResponseSchema } }
    }
  }
})

// Register path for getting a movie by ID
registry.registerPath({
  method: 'get',
  path: '/movies/{id}',
  summary: 'Get a movie by ID',
  description: 'Retrieve a single movie by its ID',
  parameters: [MOVIE_ID_PARAM], // This ensures {id} is documented as a path param
  responses: {
    200: {
      description: 'Movie found',
      content: { 'application/json': { schema: GetMovieResponseUnionSchema } }
    },
    404: {
      description: 'Movie not found',
      content: { 'application/json': { schema: MovieNotFoundResponseSchema } }
    }
  }
})

// add movie
registry.registerPath({
  method: 'post',
  path: '/movies',
  summary: 'Create a new movie',
  description: 'Create a new movie in the system',
  request: {
    body: {
      content: {
        'application/json': { schema: CreateMovieSchema }
      }
    }
  },
  responses: {
    200: {
      description: 'Movie created successfully',
      content: { 'application/json': { schema: CreateMovieResponseSchema } }
    },
    400: { description: 'Invalid request body or validation error' },
    409: {
      description: 'Movie already exists',
      content: {
        'application/json': { schema: ConflictMovieResponseSchema }
      }
    },
    500: { description: 'Unexpected error occurred' }
  }
})

// delete movie
registry.registerPath({
  method: 'delete',
  path: '/movies/{id}',
  summary: 'Delete a movie by ID',
  parameters: [MOVIE_ID_PARAM],
  responses: {
    200: {
      description: 'Movie {id} has been deleted',
      content: {
        'application/json': { schema: DeleteMovieResponseSchema }
      }
    },
    404: {
      description: 'Movie not found',
      content: { 'application/json': { schema: MovieNotFoundResponseSchema } }
    }
  }
})

// update movie
registry.registerPath({
  method: 'put',
  path: '/movies/{id}',
  summary: 'Update a movie by ID',
  description:
    'Update the details of an existing movie by providing a movie ID',
  parameters: [MOVIE_ID_PARAM], // Movie ID is required for update
  request: {
    body: {
      content: {
        'application/json': { schema: UpdateMovieSchema }
      }
    }
  },
  responses: {
    200: {
      description: 'Movie updated successfully',
      content: { 'application/json': { schema: UpdateMovieResponseSchema } }
    },
    404: {
      description: 'Movie not found',
      content: { 'application/json': { schema: MovieNotFoundResponseSchema } }
    },
    500: { description: 'Internal server error' }
  }
})

// 3) Generate OpenAPI document
const generator = new OpenApiGeneratorV31(registry.definitions)
export const openApiDoc = generator.generateDocument({
  openapi: '3.1.0',
  info: {
    title: 'Movies API',
    version: '11.0.0',
    description: 'API for managing movies'
  },
  servers: [
    {
      url: 'http://localhost:3000',
      description: 'Local development server'
    },
    {
      url: 'https://api.myapp.com',
      description: 'Production server'
    }
  ]
})

/*
Steps to Generate OpenAPI Docs with Zod (For Express, Lambda, or any other framework):

1) Define the schemas with Zod + zod-to-openapi.
(You should also link up the schemas with your types using `z.infer`, and begin to utilize zod's `safeParse`)

2) Register Schemas with the OpenAPI Registry

3) Generate OpenAPI Document: Use OpenApiGeneratorV31 to generate the full OpenAPI document. 
This document can be serialized to JSON or YAML and served by our API or Lambda function.

4.a) Static File Generation: If you prefer to generate the OpenAPI documentation as a static file (e.g., JSON or YAML), 

// json 
import fs from 'fs'
import { openApiDoc } from './doc-generator'

fs.writeFileSync('openapi.json', JSON.stringify(openApiDoc, null, 2))


// yml (npm install yaml)
import fs from 'fs'
import { openApiDoc } from './doc-generator'  // Our OpenAPI document
import { stringify } from 'yaml'

// Convert the OpenAPI document to YAML format
const yamlDoc = stringify(openApiDoc)

// Write the YAML file
fs.writeFileSync('openapi.yml', yamlDoc)

console.log('OpenAPI documentation generated in YAML format')

4.b) Serving the OpenAPI Document (For Express): If you're using Express, 
you can serve the generated OpenAPI document through an endpoint using middleware like swagger-ui-express.

npm install swagger-ui-express

import swaggerUi from 'swagger-ui-express'
import { openApiDoc } from './@types' // Import the generated OpenAPI doc

server.use('/api-docs', swaggerUi.serve, swaggerUi.setup(openApiDoc))

By visiting http://localhost:3000/api-docs, you’ll be able to view the documentation in a browser 
and interact with the API using Swagger's UI interface.

4.c) Generating and Serving in Lambda (or Serverless Environments): For Lambda, or any serverless environment, 
you'll generate the OpenAPI document as part of our deployment/build process a
nd serve it either as a static JSON file or through an HTTP API.

import { APIGatewayProxyHandler } from 'aws-lambda'
import { openApiDoc } from './doc-generator'  // Our OpenAPI document

export const getDocs: APIGatewayProxyHandler = async (event, context) => {
  return {
    statusCode: 200,
    headers: {
      'Content-Type': 'application/json',
    },
    body: JSON.stringify(openApiDoc),
  }
}

Example URL for Lambda:
If your Lambda is deployed to API Gateway with the base URL:
https://example-api-id.execute-api.us-east-1.amazonaws.com/prod

and you are serving the OpenAPI doc at /docs,
https://example-api-id.execute-api.us-east-1.amazonaws.com/prod/docs


*/



================================================
FILE: src/api-docs/openapi-writer.ts
================================================
import fs from 'node:fs'
import path from 'node:path'
import { stringify } from 'yaml'
import { openApiDoc } from './openapi-generator'

// Generate OpenAPI docs with Zod

// convert OpenAPI document to YML
const ymlDoc = stringify(openApiDoc)

const scriptDir = path.resolve(__dirname)
// write the YML file
fs.writeFileSync(`${scriptDir}/openapi.yml`, ymlDoc)

console.log('OpenAPI document generated in YML format.')

// Json version
const jsonDoc = JSON.stringify(openApiDoc, null, 2)

// Write the JSON file
fs.writeFileSync(`${scriptDir}/openapi.json`, jsonDoc)

console.log('OpenAPI document generated in JSON format.')



================================================
FILE: src/api-docs/openapi.json
================================================
{
  "openapi": "3.1.0",
  "info": {
    "title": "Movies API",
    "version": "11.0.0",
    "description": "API for managing movies"
  },
  "servers": [
    {
      "url": "http://localhost:3000",
      "description": "Local development server"
    },
    {
      "url": "https://api.myapp.com",
      "description": "Production server"
    }
  ],
  "components": {
    "schemas": {
      "CreateMovieRequest": {
        "type": "object",
        "properties": {
          "id": {
            "type": "integer",
            "description": "Movie ID ",
            "example": 1
          },
          "name": {
            "type": "string",
            "minLength": 1,
            "description": "Movie name",
            "example": "Inception"
          },
          "year": {
            "type": "integer",
            "minimum": 1900,
            "maximum": 2024,
            "description": "Release year",
            "example": 2010
          },
          "rating": {
            "type": "number",
            "description": "Rating",
            "example": 7.5
          },
          "director": {
            "type": "string",
            "minLength": 1,
            "description": "Director",
            "example": "Christopher Nolan"
          }
        },
        "required": [
          "name",
          "year",
          "rating",
          "director"
        ]
      },
      "CreateMovieResponse": {
        "type": "object",
        "properties": {
          "status": {
            "type": "integer",
            "description": "Response status code",
            "example": 200
          },
          "data": {
            "type": "object",
            "properties": {
              "id": {
                "type": "integer",
                "description": "Movie ID",
                "example": 1
              },
              "name": {
                "type": "string",
                "description": "Movie name",
                "example": "Inception"
              },
              "year": {
                "type": "integer",
                "description": "Release year",
                "example": 2010
              },
              "rating": {
                "type": "number",
                "description": "Rating",
                "example": 7.5
              },
              "director": {
                "type": "string",
                "description": "Director",
                "example": "Christopher Nolan"
              }
            },
            "required": [
              "id",
              "name",
              "year",
              "rating",
              "director"
            ]
          },
          "error": {
            "type": "string",
            "description": "Error message, if any"
          }
        },
        "required": [
          "status",
          "data"
        ]
      },
      "GetMovieResponse": {
        "type": "object",
        "properties": {
          "status": {
            "type": "integer",
            "description": "Response status code",
            "example": 200
          },
          "data": {
            "anyOf": [
              {
                "type": "object",
                "properties": {
                  "id": {
                    "type": "number",
                    "description": "Movie ID",
                    "example": 1
                  },
                  "name": {
                    "type": "string",
                    "description": "Movie name",
                    "example": "Inception"
                  },
                  "year": {
                    "type": "number",
                    "description": "Release year",
                    "example": 2010
                  },
                  "rating": {
                    "type": "number",
                    "description": "Rating",
                    "example": 7.5
                  },
                  "director": {
                    "type": "string",
                    "description": "Director",
                    "example": "Christopher Nolan"
                  }
                },
                "required": [
                  "id",
                  "name",
                  "year",
                  "rating",
                  "director"
                ]
              },
              {
                "type": "array",
                "items": {
                  "type": "object",
                  "properties": {
                    "id": {
                      "type": "number",
                      "description": "Movie ID",
                      "example": 1
                    },
                    "name": {
                      "type": "string",
                      "description": "Movie name",
                      "example": "Inception"
                    },
                    "year": {
                      "type": "number",
                      "description": "Release year",
                      "example": 2010
                    },
                    "rating": {
                      "type": "number",
                      "description": "Rating",
                      "example": 7.5
                    },
                    "director": {
                      "type": "string",
                      "description": "Director",
                      "example": "Christopher Nolan"
                    }
                  },
                  "required": [
                    "id",
                    "name",
                    "year",
                    "rating",
                    "director"
                  ]
                },
                "description": "List of movies or an empty array if no movies exist",
                "example": []
              },
              {
                "type": "null"
              }
            ]
          },
          "error": {
            "type": [
              "string",
              "null"
            ],
            "description": "Error message if an error occurred, otherwise null"
          }
        },
        "required": [
          "status",
          "data"
        ]
      },
      "MovieNotFound": {
        "type": "object",
        "properties": {
          "status": {
            "type": "integer",
            "description": "Response status code",
            "example": 404
          },
          "error": {
            "type": "string",
            "description": "Error message",
            "example": "Movie not found"
          }
        },
        "required": [
          "status",
          "error"
        ]
      },
      "DeleteMovieMessage": {
        "type": "object",
        "properties": {
          "status": {
            "type": "integer",
            "description": "Response status code",
            "example": 200
          },
          "message": {
            "type": "string",
            "description": "Success message for the deleted movie",
            "example": "Movie {id} has been deleted"
          }
        },
        "required": [
          "status",
          "message"
        ]
      },
      "ConflictMovieResponse": {
        "type": "object",
        "properties": {
          "status": {
            "type": "integer",
            "description": "Conflict status code",
            "example": 409
          },
          "error": {
            "type": "string",
            "description": "Error message",
            "example": "Movie already exists"
          }
        },
        "required": [
          "status",
          "error"
        ]
      },
      "UpdateMovieRequest": {
        "type": "object",
        "properties": {
          "id": {
            "type": "number",
            "description": "Movie ID",
            "example": 1
          },
          "name": {
            "type": "string",
            "minLength": 1,
            "description": "Movie name",
            "example": "Inception"
          },
          "year": {
            "type": "integer",
            "minimum": 1900,
            "maximum": 2024,
            "description": "Release year",
            "example": 2010
          },
          "rating": {
            "type": "number",
            "description": "Rating",
            "example": 7.5
          },
          "director": {
            "type": "string",
            "minLength": 1,
            "description": "Director",
            "example": "Christopher Nolan"
          }
        }
      },
      "UpdateMovieResponse": {
        "type": "object",
        "properties": {
          "status": {
            "type": "integer",
            "description": "Response status code",
            "example": 200
          },
          "data": {
            "type": "object",
            "properties": {
              "id": {
                "type": "number",
                "description": "Movie ID",
                "example": 1
              },
              "name": {
                "type": "string",
                "description": "Movie name",
                "example": "Inception"
              },
              "year": {
                "type": "number",
                "description": "Release year",
                "example": 2010
              },
              "rating": {
                "type": "number",
                "description": "Rating",
                "example": 7.5
              },
              "director": {
                "type": "string",
                "description": "Director",
                "example": "Christopher Nolan"
              }
            },
            "required": [
              "id",
              "name",
              "year",
              "rating",
              "director"
            ],
            "description": "Updated movie data"
          },
          "error": {
            "type": "string",
            "description": "Error message, if any"
          }
        },
        "required": [
          "status",
          "data"
        ]
      },
      "UpdatedMovieResponse": {
        "type": "object",
        "properties": {
          "status": {
            "type": "integer",
            "description": "Response status code",
            "example": 200
          },
          "data": {
            "type": "object",
            "properties": {
              "id": {
                "type": "number",
                "description": "Movie ID",
                "example": 1
              },
              "name": {
                "type": "string",
                "description": "Movie name",
                "example": "Inception"
              },
              "year": {
                "type": "number",
                "description": "Release year",
                "example": 2010
              },
              "rating": {
                "type": "number",
                "description": "Rating",
                "example": 7.5
              },
              "director": {
                "type": "string",
                "description": "Director",
                "example": "Christopher Nolan"
              }
            },
            "required": [
              "id",
              "name",
              "year",
              "rating",
              "director"
            ],
            "description": "Updated movie data"
          },
          "error": {
            "type": "string",
            "description": "Error message, if any"
          }
        },
        "required": [
          "status",
          "data"
        ]
      }
    },
    "parameters": {}
  },
  "paths": {
    "/": {
      "get": {
        "summary": "Health check",
        "responses": {
          "200": {
            "description": "Server is running",
            "content": {
              "application/json": {
                "schema": {
                  "type": "object",
                  "properties": {
                    "message": {
                      "type": "string",
                      "example": "Server is running"
                    }
                  }
                }
              }
            }
          }
        }
      }
    },
    "/movies": {
      "get": {
        "summary": "Get all movies or filter by name",
        "description": "Retrieve a list of all movies. Optionally, provide a query parameter \"name\" to filter by a specific movie name.",
        "parameters": [
          {
            "name": "name",
            "in": "query",
            "required": false,
            "schema": {
              "type": "string"
            },
            "description": "Movie name to search for"
          }
        ],
        "responses": {
          "200": {
            "description": "List of movies or a specific movie if the \"name\" query parameter is provided",
            "content": {
              "application/json": {
                "schema": {
                  "$ref": "#/components/schemas/GetMovieResponse"
                }
              }
            }
          },
          "404": {
            "description": "Movie not found if the name is provided and does not match any movie",
            "content": {
              "application/json": {
                "schema": {
                  "type": "object",
                  "properties": {
                    "status": {
                      "type": "integer",
                      "description": "Response status code",
                      "example": 404
                    },
                    "error": {
                      "type": "string",
                      "description": "Error message",
                      "example": "Movie not found"
                    }
                  },
                  "required": [
                    "status",
                    "error"
                  ]
                }
              }
            }
          }
        }
      },
      "post": {
        "summary": "Create a new movie",
        "description": "Create a new movie in the system",
        "requestBody": {
          "content": {
            "application/json": {
              "schema": {
                "$ref": "#/components/schemas/CreateMovieRequest"
              }
            }
          }
        },
        "responses": {
          "200": {
            "description": "Movie created successfully",
            "content": {
              "application/json": {
                "schema": {
                  "$ref": "#/components/schemas/CreateMovieResponse"
                }
              }
            }
          },
          "400": {
            "description": "Invalid request body or validation error"
          },
          "409": {
            "description": "Movie already exists",
            "content": {
              "application/json": {
                "schema": {
                  "type": "object",
                  "properties": {
                    "status": {
                      "type": "integer",
                      "description": "Conflict status code",
                      "example": 409
                    },
                    "error": {
                      "type": "string",
                      "description": "Error message",
                      "example": "Movie already exists"
                    }
                  },
                  "required": [
                    "status",
                    "error"
                  ]
                }
              }
            }
          },
          "500": {
            "description": "Unexpected error occurred"
          }
        }
      }
    },
    "/movies/{id}": {
      "get": {
        "summary": "Get a movie by ID",
        "description": "Retrieve a single movie by its ID",
        "parameters": [
          {
            "name": "id",
            "in": "path",
            "required": true,
            "schema": {
              "type": "string"
            },
            "description": "Movie ID"
          }
        ],
        "responses": {
          "200": {
            "description": "Movie found",
            "content": {
              "application/json": {
                "schema": {
                  "$ref": "#/components/schemas/GetMovieResponse"
                }
              }
            }
          },
          "404": {
            "description": "Movie not found",
            "content": {
              "application/json": {
                "schema": {
                  "type": "object",
                  "properties": {
                    "status": {
                      "type": "integer",
                      "description": "Response status code",
                      "example": 404
                    },
                    "error": {
                      "type": "string",
                      "description": "Error message",
                      "example": "Movie not found"
                    }
                  },
                  "required": [
                    "status",
                    "error"
                  ]
                }
              }
            }
          }
        }
      },
      "delete": {
        "summary": "Delete a movie by ID",
        "parameters": [
          {
            "name": "id",
            "in": "path",
            "required": true,
            "schema": {
              "type": "string"
            },
            "description": "Movie ID"
          }
        ],
        "responses": {
          "200": {
            "description": "Movie {id} has been deleted",
            "content": {
              "application/json": {
                "schema": {
                  "type": "object",
                  "properties": {
                    "status": {
                      "type": "integer",
                      "description": "Response status code",
                      "example": 200
                    },
                    "message": {
                      "type": "string",
                      "description": "Success message for the deleted movie",
                      "example": "Movie {id} has been deleted"
                    }
                  },
                  "required": [
                    "status",
                    "message"
                  ]
                }
              }
            }
          },
          "404": {
            "description": "Movie not found",
            "content": {
              "application/json": {
                "schema": {
                  "type": "object",
                  "properties": {
                    "status": {
                      "type": "integer",
                      "description": "Response status code",
                      "example": 404
                    },
                    "error": {
                      "type": "string",
                      "description": "Error message",
                      "example": "Movie not found"
                    }
                  },
                  "required": [
                    "status",
                    "error"
                  ]
                }
              }
            }
          }
        }
      },
      "put": {
        "summary": "Update a movie by ID",
        "description": "Update the details of an existing movie by providing a movie ID",
        "parameters": [
          {
            "name": "id",
            "in": "path",
            "required": true,
            "schema": {
              "type": "string"
            },
            "description": "Movie ID"
          }
        ],
        "requestBody": {
          "content": {
            "application/json": {
              "schema": {
                "$ref": "#/components/schemas/UpdateMovieRequest"
              }
            }
          }
        },
        "responses": {
          "200": {
            "description": "Movie updated successfully",
            "content": {
              "application/json": {
                "schema": {
                  "$ref": "#/components/schemas/UpdatedMovieResponse"
                }
              }
            }
          },
          "404": {
            "description": "Movie not found",
            "content": {
              "application/json": {
                "schema": {
                  "type": "object",
                  "properties": {
                    "status": {
                      "type": "integer",
                      "description": "Response status code",
                      "example": 404
                    },
                    "error": {
                      "type": "string",
                      "description": "Error message",
                      "example": "Movie not found"
                    }
                  },
                  "required": [
                    "status",
                    "error"
                  ]
                }
              }
            }
          },
          "500": {
            "description": "Internal server error"
          }
        }
      }
    }
  },
  "webhooks": {}
}


================================================
FILE: src/api-docs/openapi.yml
================================================
openapi: 3.1.0
info:
  title: Movies API
  version: 11.0.0
  description: API for managing movies
servers:
  - url: http://localhost:3000
    description: Local development server
  - url: https://api.myapp.com
    description: Production server
components:
  schemas:
    CreateMovieRequest:
      type: object
      properties:
        id:
          type: integer
          description: "Movie ID "
          example: 1
        name:
          type: string
          minLength: 1
          description: Movie name
          example: Inception
        year:
          type: integer
          minimum: 1900
          maximum: 2024
          description: Release year
          example: 2010
        rating:
          type: number
          description: Rating
          example: 7.5
        director:
          type: string
          minLength: 1
          description: Director
          example: Christopher Nolan
      required:
        - name
        - year
        - rating
        - director
    CreateMovieResponse:
      type: object
      properties:
        status:
          type: integer
          description: Response status code
          example: 200
        data:
          type: object
          properties:
            id:
              type: integer
              description: Movie ID
              example: 1
            name:
              type: string
              description: Movie name
              example: Inception
            year:
              type: integer
              description: Release year
              example: 2010
            rating:
              type: number
              description: Rating
              example: 7.5
            director:
              type: string
              description: Director
              example: Christopher Nolan
          required:
            - id
            - name
            - year
            - rating
            - director
        error:
          type: string
          description: Error message, if any
      required:
        - status
        - data
    GetMovieResponse:
      type: object
      properties:
        status:
          type: integer
          description: Response status code
          example: 200
        data:
          anyOf:
            - type: object
              properties:
                id:
                  type: number
                  description: Movie ID
                  example: 1
                name:
                  type: string
                  description: Movie name
                  example: Inception
                year:
                  type: number
                  description: Release year
                  example: 2010
                rating:
                  type: number
                  description: Rating
                  example: 7.5
                director:
                  type: string
                  description: Director
                  example: Christopher Nolan
              required:
                - id
                - name
                - year
                - rating
                - director
            - type: array
              items:
                type: object
                properties:
                  id:
                    type: number
                    description: Movie ID
                    example: 1
                  name:
                    type: string
                    description: Movie name
                    example: Inception
                  year:
                    type: number
                    description: Release year
                    example: 2010
                  rating:
                    type: number
                    description: Rating
                    example: 7.5
                  director:
                    type: string
                    description: Director
                    example: Christopher Nolan
                required:
                  - id
                  - name
                  - year
                  - rating
                  - director
              description: List of movies or an empty array if no movies exist
              example: []
            - type: "null"
        error:
          type:
            - string
            - "null"
          description: Error message if an error occurred, otherwise null
      required:
        - status
        - data
    MovieNotFound:
      type: object
      properties:
        status:
          type: integer
          description: Response status code
          example: 404
        error:
          type: string
          description: Error message
          example: Movie not found
      required:
        - status
        - error
    DeleteMovieMessage:
      type: object
      properties:
        status:
          type: integer
          description: Response status code
          example: 200
        message:
          type: string
          description: Success message for the deleted movie
          example: Movie {id} has been deleted
      required:
        - status
        - message
    ConflictMovieResponse:
      type: object
      properties:
        status:
          type: integer
          description: Conflict status code
          example: 409
        error:
          type: string
          description: Error message
          example: Movie already exists
      required:
        - status
        - error
    UpdateMovieRequest:
      type: object
      properties:
        id:
          type: number
          description: Movie ID
          example: 1
        name:
          type: string
          minLength: 1
          description: Movie name
          example: Inception
        year:
          type: integer
          minimum: 1900
          maximum: 2024
          description: Release year
          example: 2010
        rating:
          type: number
          description: Rating
          example: 7.5
        director:
          type: string
          minLength: 1
          description: Director
          example: Christopher Nolan
    UpdateMovieResponse:
      type: object
      properties:
        status:
          type: integer
          description: Response status code
          example: 200
        data:
          type: object
          properties:
            id:
              type: number
              description: Movie ID
              example: 1
            name:
              type: string
              description: Movie name
              example: Inception
            year:
              type: number
              description: Release year
              example: 2010
            rating:
              type: number
              description: Rating
              example: 7.5
            director:
              type: string
              description: Director
              example: Christopher Nolan
          required:
            - id
            - name
            - year
            - rating
            - director
          description: Updated movie data
        error:
          type: string
          description: Error message, if any
      required:
        - status
        - data
    UpdatedMovieResponse:
      type: object
      properties:
        status:
          type: integer
          description: Response status code
          example: 200
        data:
          type: object
          properties:
            id:
              type: number
              description: Movie ID
              example: 1
            name:
              type: string
              description: Movie name
              example: Inception
            year:
              type: number
              description: Release year
              example: 2010
            rating:
              type: number
              description: Rating
              example: 7.5
            director:
              type: string
              description: Director
              example: Christopher Nolan
          required:
            - id
            - name
            - year
            - rating
            - director
          description: Updated movie data
        error:
          type: string
          description: Error message, if any
      required:
        - status
        - data
  parameters: {}
paths:
  /:
    get:
      summary: Health check
      responses:
        "200":
          description: Server is running
          content:
            application/json:
              schema:
                type: object
                properties:
                  message:
                    type: string
                    example: Server is running
  /movies:
    get:
      summary: Get all movies or filter by name
      description: Retrieve a list of all movies. Optionally, provide a query
        parameter "name" to filter by a specific movie name.
      parameters:
        - name: name
          in: query
          required: false
          schema:
            type: string
          description: Movie name to search for
      responses:
        "200":
          description: List of movies or a specific movie if the "name" query parameter is
            provided
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/GetMovieResponse"
        "404":
          description: Movie not found if the name is provided and does not match any movie
          content:
            application/json:
              schema:
                type: object
                properties:
                  status:
                    type: integer
                    description: Response status code
                    example: 404
                  error:
                    type: string
                    description: Error message
                    example: Movie not found
                required:
                  - status
                  - error
    post:
      summary: Create a new movie
      description: Create a new movie in the system
      requestBody:
        content:
          application/json:
            schema:
              $ref: "#/components/schemas/CreateMovieRequest"
      responses:
        "200":
          description: Movie created successfully
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/CreateMovieResponse"
        "400":
          description: Invalid request body or validation error
        "409":
          description: Movie already exists
          content:
            application/json:
              schema:
                type: object
                properties:
                  status:
                    type: integer
                    description: Conflict status code
                    example: 409
                  error:
                    type: string
                    description: Error message
                    example: Movie already exists
                required:
                  - status
                  - error
        "500":
          description: Unexpected error occurred
  /movies/{id}:
    get:
      summary: Get a movie by ID
      description: Retrieve a single movie by its ID
      parameters:
        - &a1
          name: id
          in: path
          required: true
          schema:
            type: string
          description: Movie ID
      responses:
        "200":
          description: Movie found
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/GetMovieResponse"
        "404":
          description: Movie not found
          content:
            application/json:
              schema:
                type: object
                properties:
                  status:
                    type: integer
                    description: Response status code
                    example: 404
                  error:
                    type: string
                    description: Error message
                    example: Movie not found
                required:
                  - status
                  - error
    delete:
      summary: Delete a movie by ID
      parameters:
        - *a1
      responses:
        "200":
          description: Movie {id} has been deleted
          content:
            application/json:
              schema:
                type: object
                properties:
                  status:
                    type: integer
                    description: Response status code
                    example: 200
                  message:
                    type: string
                    description: Success message for the deleted movie
                    example: Movie {id} has been deleted
                required:
                  - status
                  - message
        "404":
          description: Movie not found
          content:
            application/json:
              schema:
                type: object
                properties:
                  status:
                    type: integer
                    description: Response status code
                    example: 404
                  error:
                    type: string
                    description: Error message
                    example: Movie not found
                required:
                  - status
                  - error
    put:
      summary: Update a movie by ID
      description: Update the details of an existing movie by providing a movie ID
      parameters:
        - *a1
      requestBody:
        content:
          application/json:
            schema:
              $ref: "#/components/schemas/UpdateMovieRequest"
      responses:
        "200":
          description: Movie updated successfully
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/UpdatedMovieResponse"
        "404":
          description: Movie not found
          content:
            application/json:
              schema:
                type: object
                properties:
                  status:
                    type: integer
                    description: Response status code
                    example: 404
                  error:
                    type: string
                    description: Error message
                    example: Movie not found
                required:
                  - status
                  - error
        "500":
          description: Internal server error
webhooks: {}



================================================
FILE: src/events/kafka-cluster.yml
================================================
# This docker-compose file can be used to start Kafka and its dependencies locally.
# If Kafka is not running, movie CRUD operations will still work but the movie events will not be published.

version: '3.8'  # Version of Docker Compose file format

services:
  kafka:
    image: bitnami/kafka:latest  # Kafka Docker image from Bitnami repository (multi-architecture support).
    platform: linux/amd64  # Ensures compatibility with AMD64 architecture to avoid ARM issues on Apple Silicon.
    depends_on:
      - zookeeper  # Kafka requires Zookeeper for managing configurations and cluster state.
    ports:
      - '29092:29092'  # Maps external port 29092 to Kafka's listener for external access.
    expose:
      - '29092'  # Makes port 29092 available for other containers in the same Docker network.
    environment:
      KAFKA_BROKER_ID: 1  # Unique identifier for this Kafka broker instance.

      KAFKA_CFG_ZOOKEEPER_CONNECT: 'zookeeper:2181'  
      # Specifies Zookeeper's connection string (host and port) to enable Kafka to use it.

      KAFKA_CFG_LISTENERS: PLAINTEXT://:9092,EXTERNAL://:29092  
      # Defines Kafka's listeners:
      # - PLAINTEXT listener for internal Docker communication.
      # - EXTERNAL listener for connections outside the container via port 29092.

      KAFKA_CFG_ADVERTISED_LISTENERS: PLAINTEXT://kafka:9092,EXTERNAL://localhost:29092  
      # Specifies how Kafka advertises its listeners to clients:
      # - Internal Docker network: 'PLAINTEXT://kafka:9092' (accessible by other containers).
      # - External access: 'EXTERNAL://localhost:29092' (accessible by external clients).

      KAFKA_CFG_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,EXTERNAL:PLAINTEXT  
      # Maps the listeners (PLAINTEXT and EXTERNAL) to the PLAINTEXT security protocol. 
      # This avoids encryption/authentication and keeps it simple for local development.

      KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT  
      # Specifies that Kafka brokers communicate with each other using the PLAINTEXT listener.

      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1  
      # Sets the replication factor for Kafka's internal `__consumer_offsets` topic. 
      # Since it's a single-node setup, replication is set to 1.

    volumes:
      - kafka_data:/var/lib/kafka/data  
      # Maps a persistent volume to store Kafka logs and data, preventing data loss on restarts.

  init-kafka:
    image: bitnami/kafka:latest  # Kafka image, the same as the main Kafka broker
    depends_on:
      - kafka  # Will run after the Kafka broker is up and running
    entrypoint: ['/bin/sh', '-c']  # Defines the shell entry point for this container
    command: |
      "
      # Wait for Kafka to be ready
      /opt/bitnami/kafka/bin/kafka-topics.sh --bootstrap-server kafka:9092 --list

      # Create the 'movies' topic
      echo -e 'Creating kafka topics'
      /opt/bitnami/kafka/bin/kafka-topics.sh --bootstrap-server kafka:9092 --create --if-not-exists --topic movies --replication-factor 1 --partitions 1

      echo -e 'Successfully created the following topics:'
      /opt/bitnami/kafka/bin/kafka-topics.sh --bootstrap-server kafka:9092 --list
      "

  kafka-ui:
    image: provectuslabs/kafka-ui:latest  # Kafka UI tool for managing and viewing topics and brokers
    ports:
      - 8085:8080  # Exposes the Kafka UI on port 8085 (localhost:8085 in the browser)
    environment:
      KAFKA_CLUSTERS_0_NAME: local  # Names the Kafka cluster in the UI as 'local'
      KAFKA_CLUSTERS_0_BOOTSTRAPSERVERS: kafka:9092  # Connects the UI to the Kafka broker
      DYNAMIC_CONFIG_ENABLED: 'true'  # Enables dynamic configuration in the UI

  zookeeper:
    image: confluentinc/cp-zookeeper:6.0.14  # Zookeeper image for managing Kafka configurations and metadata
    platform: linux/amd64  # Ensures compatibility with AMD64 architecture
    ports:
      - '22181:2181'  # Exposes Zookeeper on port 2181 for external access
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181  # Default client port for Zookeeper communication
      ZOOKEEPER_TICK_TIME: 2000  # Zookeeper heartbeat interval in milliseconds

volumes:
  kafka_data:
    driver: local  # Define a Docker volume to persist Kafka data



================================================
FILE: src/events/log-file-path.ts
================================================
export const logFilePath = './cypress/movie-events.log'



================================================
FILE: src/events/movie-events.test.ts
================================================
import { produceMovieEvent } from './movie-events'
import { Kafka } from 'kafkajs'
import type { Movie } from '@prisma/client'
import { generateMovieWithId } from '../test-helpers/factories'

// Mock kafkajs
jest.mock('kafkajs', () => ({
  Kafka: jest.fn().mockImplementation(() => ({
    producer: jest.fn(() => ({
      connect: jest.fn().mockResolvedValue(undefined),
      send: jest.fn(),
      disconnect: jest.fn()
    }))
  }))
}))

// Mock fs
jest.mock('node:fs/promises', () => ({
  appendFile: jest.fn().mockResolvedValue(undefined)
}))

// Mock console.table and console.error
global.console.table = jest.fn()
global.console.error = jest.fn()

describe('produceMovieEvent', () => {
  const mockMovie: Movie = generateMovieWithId()
  const key = mockMovie.id.toString() // the key is always a string in Kafka

  beforeEach(() => {
    jest.clearAllMocks()
  })

  it('should produce a movie event successfully', async () => {
    const kafkaInstance = new Kafka({
      clientId: 'test-client',
      brokers: ['localhost:9092']
    })
    const event = {
      topic: 'movie-created',
      messages: [{ key, value: JSON.stringify(mockMovie) }]
    }
    const producer = kafkaInstance.producer()
    await producer.connect()
    await producer.send(event)
    await producer.disconnect()

    const result = await produceMovieEvent(mockMovie, 'created')

    expect(Kafka).toHaveBeenCalledWith(expect.any(Object))
    expect(producer.connect).toHaveBeenCalled()
    expect(producer.send).toHaveBeenCalledWith(event)
    expect(producer.disconnect).toHaveBeenCalled()
    expect(console.table).toHaveBeenCalled()
    expect(result).toEqual({
      topic: 'movie-created',
      messages: [{ key, value: mockMovie }]
    })
  })
})



================================================
FILE: src/events/movie-events.ts
================================================
// producing Kafka events is purely optional
// for them to be seen in action, the provider repo has to be started
// docker has to be started, and kafka:start script has be executed in the provider repo
// we have e2e tests in the provider that execute if kafka is up
// the real intent is to test events with pact while no kafka is running

import type { Movie } from '@prisma/client'
import { Kafka } from 'kafkajs'
import fs from 'node:fs/promises'
import type { MovieEvent, MovieAction } from '../@types'
import { logFilePath } from './log-file-path'

const kafka = new Kafka({
  clientId: 'movie-provider',
  brokers: ['localhost:29092'],
  // reduce retries and delays
  // so that those who don't start docker still have their crud fast
  retry: {
    retries: 2, // default 5
    initialRetryTime: 100, // delay initial (default 300 ms)
    maxRetryTime: 300 // delay between retries (default 30 secs)
  }
})
const producer = kafka.producer()

// console log it and write the event to a file, so we can somewhat verify them
// in the real world, you might check db, other services, or any other external side effects
const logEvent = async (event: MovieEvent, logFilePath: string) => {
  console.table(event)

  return new Promise<void>((resolve) => {
    setTimeout(async () => {
      await fs.appendFile(logFilePath, `${JSON.stringify(event)}\n`)
      resolve()
    }, 1000)
  })
}

export const produceMovieEvent = async (movie: Movie, action: MovieAction) => {
  const event: MovieEvent = {
    topic: `movie-${action}`,
    messages: [{ key: movie.id.toString(), value: JSON.stringify(movie) }]
  }

  try {
    await producer.connect()
    await producer.send(event)
    logEvent(event, logFilePath)
    await producer.disconnect()

    return parseEvent(event)
  } catch (err) {
    console.error(
      'Kafka broker unavailable, skipping event publication: ',
      err instanceof Error ? err.message : 'Unknown error'
    )
    // optionally rethrow the error
    // if you want to let the caller handle it further with a try-catch of their own
    // throw err

    return parseEvent(event)
  }
}

/**
 * Parses the Kafka event for Pact testing.
 *
 * Kafka requires the `messages.value` field to be stringified when sending the event,
 * but for Pact testing, we want to return the parsed object version of the event
 * to simulate the original message.
 *
 * @param {MovieEvent} event - The event that was sent to Kafka.
 * @returns {MovieEvent} - The parsed event with `messages.value` converted from a string to an object. */
const parseEvent = (event: MovieEvent) => ({
  ...event,
  messages: event.messages.map((msg) => ({
    key: msg.key,
    value: typeof msg.value === 'string' ? JSON.parse(msg.value) : msg.value
  }))
})



================================================
FILE: src/middleware/auth-middleware.test.ts
================================================
import type { Request, Response, NextFunction } from 'express'
import { authMiddleware } from './auth-middleware'

describe('authMiddleware', () => {
  let mockRequest: Partial<Request>
  let mockResponse: Partial<Response>
  let nextFunction: NextFunction

  beforeEach(() => {
    mockRequest = {
      headers: {}
    }
    mockResponse = {
      status: jest.fn().mockReturnThis(),
      json: jest.fn()
    }
    nextFunction = jest.fn()
  })

  it('should call next() exactly once for valid token', () => {
    const validDate = new Date()
    mockRequest.headers = { authorization: `Bearer ${validDate.toISOString()}` }
    authMiddleware(
      mockRequest as Request,
      mockResponse as Response,
      nextFunction
    )

    expect(nextFunction).toHaveBeenCalledTimes(1)
    expect(mockResponse.status).not.toHaveBeenCalled()
    expect(mockResponse.json).not.toHaveBeenCalled()
  })

  it('should return 401 when no token is provided', () => {
    authMiddleware(
      mockRequest as Request,
      mockResponse as Response,
      nextFunction
    )

    expect(mockResponse.status).toHaveBeenCalledWith(401)
    expect(mockResponse.json).toHaveBeenCalledWith({
      error: 'Unauthorized; no Authorization header.',
      status: 401
    })
    expect(nextFunction).not.toHaveBeenCalled()
  })

  it('should return 401 for expired token', () => {
    const expiredDate = new Date(Date.now() - 3601 * 1000) // 1 hour and 1 second ago
    mockRequest.headers = {
      authorization: `Bearer ${expiredDate.toISOString()}`
    }
    authMiddleware(
      mockRequest as Request,
      mockResponse as Response,
      nextFunction
    )

    expect(mockResponse.status).toHaveBeenCalledWith(401)
    expect(mockResponse.json).toHaveBeenCalledWith({
      error: 'Unauthorized; not valid timestamp.',
      status: 401
    })
    expect(nextFunction).not.toHaveBeenCalled()
  })
})



================================================
FILE: src/middleware/auth-middleware.ts
================================================
import type { Request, Response, NextFunction } from 'express'

// In Express, a middleware is a function that sits between a request and the response.
// It checks or modifies the request as it moves along.
// Think of it as a "checkpoint" where the request stops briefly, gets processed,
// and then moves on to the next step or to the final response.

// define a type for the token's structure, which contains the issuedAt date.
type Token = {
  issuedAt: Date // the token contains a precise Date object
}

// Function to check if the token's timestamp is within 1 hour
const isValidAuthTimeStamp = (token: Token) => {
  const tokenTime = token.issuedAt.getTime() // get time in milliseconds
  const currentTime = new Date().getTime() // current time in milliseconds
  const diff = (currentTime - tokenTime) / 1000 // difference in seconds

  return diff >= 0 && diff <= 3600 // Token valid for 1 hour
}
export function authMiddleware(
  req: Request,
  res: Response,
  next: NextFunction
) {
  const authHeader = req.headers.authorization
  if (!authHeader)
    return res
      .status(401)
      .json({ error: 'Unauthorized; no Authorization header.', status: 401 })

  const tokenStr = authHeader.replace('Bearer ', '')
  const token: Token = { issuedAt: new Date(tokenStr) }

  if (!isValidAuthTimeStamp(token))
    return res
      .status(401)
      .json({ error: 'Unauthorized; not valid timestamp.', status: 401 })

  next() // proceed if valid
}



================================================
FILE: src/middleware/validate-movie-id.test.ts
================================================
import type { Request, Response, NextFunction } from 'express'
import { validateId } from './validate-movie-id'

describe('validateId middleware', () => {
  let mockRequest: Partial<Request>
  let mockResponse: Partial<Response>
  let nextFunction: NextFunction

  beforeEach(() => {
    mockRequest = {
      params: {}
    }
    mockResponse = {
      status: jest.fn().mockReturnThis(), // mocked to return this (the mockResponse object), allowing method chaining like res.status().json().
      json: jest.fn()
    }
    nextFunction = jest.fn()
  })

  it('should pass valid movie ID', () => {
    mockRequest.params = { id: '123' }
    validateId(mockRequest as Request, mockResponse as Response, nextFunction)

    expect(mockRequest.params.id).toBe('123')
    expect(nextFunction).toHaveBeenCalled()
    expect(mockResponse.status).not.toHaveBeenCalled()
    expect(mockResponse.json).not.toHaveBeenCalled()
  })

  it('should return 400 for invalid movie ID', () => {
    mockRequest.params = { id: 'abc' }
    validateId(mockRequest as Request, mockResponse as Response, nextFunction)

    expect(mockResponse.status).toHaveBeenCalledWith(400)
    expect(mockResponse.json).toHaveBeenCalledWith({
      error: 'Invalid movie ID provided'
    })
    expect(nextFunction).not.toHaveBeenCalled()
  })

  it('should handle missing ID parameter', () => {
    validateId(mockRequest as Request, mockResponse as Response, nextFunction)

    expect(mockResponse.status).toHaveBeenCalledWith(400)
    expect(mockResponse.json).toHaveBeenCalledWith({
      error: 'Invalid movie ID provided'
    })
    expect(nextFunction).not.toHaveBeenCalled()
  })
})



================================================
FILE: src/middleware/validate-movie-id.ts
================================================
import type { Request, Response, NextFunction } from 'express'

/** middleware for validating movie id in the request url */
export function validateId(req: Request, res: Response, next: NextFunction) {
  const movieId = parseInt(req.params.id!)

  if (isNaN(movieId))
    return res.status(400).json({ error: 'Invalid movie ID provided' })

  req.params.id = movieId.toString() // pass validated MovieId forward

  next() // pass to the next middleware or route handler
}



================================================
FILE: src/test-helpers/factories.ts
================================================
import { faker } from '@faker-js/faker'
import type { Movie } from '@prisma/client'

export const generateMovieWithoutId = (): Omit<Movie, 'id'> => {
  return {
    name: faker.lorem.words(3), // random 3-word title
    year: faker.date.past({ years: 50 }).getFullYear(), // random year between the past 50 years
    rating: faker.number.float({ min: 1, max: 10, fractionDigits: 1 }), // random rating between 1 and 10 with 1 decimal place
    director: faker.lorem.words(3)
  }
}

export const generateMovieWithId = (): Movie => {
  return {
    id: faker.number.int({ min: 1, max: 1000 }), // random ID between 1 and 1000
    name: faker.lorem.words(3),
    year: faker.date.past({ years: 50 }).getFullYear(),
    rating: faker.number.float({ min: 1, max: 10, fractionDigits: 1 }),
    director: faker.lorem.words(3)
  }
}



================================================
FILE: src/test-helpers/message-providers.ts
================================================
import { providerWithMetadata } from '@pact-foundation/pact'
import type { Movie } from '@prisma/client'
import { produceMovieEvent } from '../events/movie-events'
import { generateMovieWithId } from './factories'

const movie: Movie = generateMovieWithId()

// These are the messages the provider should produce
// Each key is an event (e.g., 'movie-created') linked to a handler (providerWithMetadata) that generates the message.
// Metadata like contentType ensures correct message format interpretation.

export const messageProviders = {
  'a movie-created event': providerWithMetadata(
    () => produceMovieEvent(movie, 'created'),
    {
      contentType: 'application/json'
    }
  ),
  'a movie-updated event': providerWithMetadata(
    () => produceMovieEvent(movie, 'updated'),
    {
      contentType: 'application/json'
    }
  ),
  'a movie-deleted event': providerWithMetadata(
    () => produceMovieEvent(movie, 'deleted'),
    {
      contentType: 'application/json'
    }
  )
}



================================================
FILE: src/test-helpers/state-handlers.ts
================================================
import type { MessageStateHandlers } from '@pact-foundation/pact'
import type { AnyJson } from '@pact-foundation/pact/src/common/jsonTypes'
import type { StateHandlers } from '@pact-foundation/pact/src/dsl/verifier/proxy/types'
import { PrismaClient, type Movie } from '@prisma/client'
import { MovieService } from '../movie-service'
import { MovieAdapter } from '../movie-adapter'
import { truncateTables } from '../../scripts/truncate-tables'

// define the shape of the params passed in from the consumer
type HasMovieWithSpecificIDParams = Omit<Movie, 'name' | 'year'>
type ExistingMovieParams = Omit<Movie, 'id'>

const prisma = new PrismaClient()
const movieAdapter = new MovieAdapter(prisma)
const movieService = new MovieService(movieAdapter)

export const stateHandlers: StateHandlers & MessageStateHandlers = {
  'Has a movie with a specific ID': async (params: AnyJson) => {
    const { id } = params as HasMovieWithSpecificIDParams

    // Check if the movie with the given id already exists
    const res = await movieService.getMovieById(id)

    if (res.status !== 200) {
      // If the movie doesn't exist, create it
      const movieData: Omit<Movie, 'id'> = {
        name: `Movie Title ${Math.random().toString(36).substring(7)}`,
        year: 2022,
        rating: 7.5,
        director: `Movie Director ${Math.random().toString(36).substring(7)}`
      }
      console.log('MOVIE DATA:', movieData)

      await movieService.addMovie(movieData, id)
      console.log(`Movie with ID ${id} successfully created.`)
    } else {
      console.log(`Movie with ID ${id} already exists, skipping creation.`)
    }

    return {
      description: `Movie with ID ${id} is set up.`
    }
  },
  'An existing movie exists': async (params: AnyJson) => {
    const { name, year, rating, director } = params as ExistingMovieParams

    // Check if the movie already exists by name
    const res = await movieService.getMovieByName(name)

    if (res.status !== 200) {
      // Insert the movie if it doesn't exist
      await movieService.addMovie({ name, year, rating, director })
      console.log(`Movie with name "${name}" added.`)
    } else {
      console.log(
        `Movie with name "${name}" already exists, skipping creation.`
      )
    }

    return {
      description: `Movie with name "${name}" is set up.`
    }
  },
  'No movies exist': async () => {
    console.log('Truncating tables...')
    await truncateTables()

    return {
      description: 'State with no movies achieved.'
    }
  }

  // // @ts-expect-error: https://github.com/pact-foundation/pact-js/issues/1164
  // 'No movies exist': {
  //   setup: async () => {
  //     console.log('Truncating tables...')
  //     await truncateTables()
  //   },
  //   teardown: async () => {
  //     console.log('Teardown of state No movies exist ran...')
  //     // Logic to restore default movies or clean up further can go here.
  //     // If you're using fixtures or need to reset the database, handle that here.
  //   }
  // }
}

/*
 Note about PROVIDER STATES: we can simulate certain states of the API (like an empty or non-empty DB)
 in order to cover different scenarios
 The state could have many more variables; it is a good practice to represent it as an object
 Note that the consumer state name should match the provider side

 * The purpose of the stateHandlers is to ensure that the provider is in the correct state
 to fulfill the consumer's expectations as defined in the contract tests.
 * In a real-world scenario, you would typically set up this state by interacting with your service's database
 * or through an API provided by the service itself (locally).
 * This ensures that the provider test runs in a controlled environment where all the necessary data
 and conditions are met, allowing for accurate verification of the consumer's expectations.

Pact docs mention state setup and teardown
https://docs.pact.io/implementation_guides/javascript/docs/provider#provider-state-setup-and-teardown

but it doesn't work with TS at the moment
https://github.com/pact-foundation/pact-js/issues/1164

StateHandlers can either use:

* a single function: this is only used for the setup phase, where you define a function that sets up the provider state. 
It cannot handle teardown.

* an object with separate setup and teardown properties: this allows you to specify distinct functions 
for both the setup and teardown phases. The setup function will initialize the required state, 
and the teardown function will clean up after the tests have run.

What is the distinction between setup & teardown vs beforeEach & afterEach in options?
TL, DR; granularity

afterEach in options runs after every single test
the teardown in stateHandlers runs only after the tests which use that specific state

beforeEach in options runs before every single test
the setup in stateHandlers runs only before the tests which use that specific state

*/



================================================
FILE: src/test-helpers/pact-utils/build-verifier-options.ts
================================================
import type {
  MessageProviders,
  MessageStateHandlers,
  PactMessageProviderOptions,
  VerifierOptions
} from '@pact-foundation/pact'
import type {
  ProxyOptions,
  StateHandlers
} from '@pact-foundation/pact/src/dsl/verifier/proxy/types'
import {
  handlePactBrokerUrlAndSelectors,
  getProviderVersionTags
} from './handle-url-and-selectors'
import { noOpRequestFilter } from './pact-request-filter'

/**
 * Builds a `VerifierOptions` object for Pact verification, encapsulating
 * common provider test setup options, including conditional handling for
 * breaking changes and dynamically generated consumer version selectors.
 *
 * This function is designed to modularize the setup of Pact verification for providers
 * and streamline common configurations, such as state handlers, consumer version selectors,
 * and pact broker options.
 *
 * @param provider - The name of the provider being verified.
 * @param port - The port on which the provider service runs.
 * @param logLevel - (Optional) The log level for Pact verification output (`info`, `debug`, etc.).
 * @param stateHandlers - (Optional) Handlers to simulate provider states based on consumer expectations.
 * @param beforeEach - (Optional) A hook that runs before each consumer interaction.
 * @param afterEach - (Optional) A hook that runs after each consumer interaction.
 * @param includeMainAndDeployed - (Required) Flag indicating whether to include `mainBranch` and `deployedOrReleased` selectors. Should be explicitly controlled.
 * @param consumer - (Optional) A specific consumer to run verification for. If not provided, all consumers will be verified.
 * @param enablePending - (Optional, defaults to `false`) Use this if breaking changes from a consumer somehow got in main, and the provider cannot release (allow blasphemy!)
 * @param requestFilter - (Optional) A custom request filter function to modify incoming requests (e.g., for authentication).
 * @param publishVerificationResult - (Optional, defaults to `true`) Whether to publish the verification result to the Pact Broker.
 * @param pactBrokerToken - (Optional) Token for authentication with the Pact Broker, defaults to environment variable.
 * @param providerVersion - (Optional) The version of the provider, typically tied to a Git commit or build.
 * @param providerVersionBranch - (Optional) The branch of the provider being verified.
 * @param providerVersionTags - (Optional) Tags to associate with the provider version, such as branch names or environment names.
 * @param pactBrokerUrl - (Optional) URL of the Pact Broker, defaults to an environment variable.
 * @param pactPayloadUrl - (Optional) Direct URL for Pact payloads, typically used in CI environments.
 *
 * @returns A fully configured `VerifierOptions` object for running Pact verification tests.
 *
 * @example
 * // Running verification for all consumers
 * const options = buildVerifierOptions({
 *   provider: 'MoviesAPI',
 *   includeMainAndDeployed: process.env.PACT_BREAKING_CHANGE !== 'true',
 *   port: '3001',
 *   stateHandlers,
 * })
 *
 * @example
 * // Running verification for a specific consumer, with debug logging
 * const options = buildVerifierOptions({
 *   provider: 'MoviesAPI',
 *   consumer: 'WebConsumer',
 *   includeMainAndDeployed: process.env.PACT_BREAKING_CHANGE !== 'true',
 *   port: '3001',
 *   stateHandlers,
 *   logLevel: 'debug',
 * })
 */
export function buildVerifierOptions({
  provider,
  port,
  logLevel = 'info', // 'debug' is also useful
  stateHandlers,
  beforeEach,
  afterEach,
  includeMainAndDeployed,
  consumer,
  enablePending = false,
  requestFilter = noOpRequestFilter,
  publishVerificationResult = true,
  pactBrokerToken = process.env.PACT_BROKER_TOKEN,
  providerVersion = process.env.GITHUB_SHA || 'unknown',
  providerVersionBranch = process.env.GITHUB_BRANCH || 'main', // default to 'main' if provider branch is not set
  providerVersionTags = getProviderVersionTags(),
  pactBrokerUrl = process.env.PACT_BROKER_BASE_URL,
  pactPayloadUrl = process.env.PACT_PAYLOAD_URL
}: {
  provider: string
  port: string
  logLevel?: ProxyOptions['logLevel']
  stateHandlers?: StateHandlers & MessageStateHandlers
  beforeEach?: ProxyOptions['beforeEach']
  afterEach?: ProxyOptions['afterEach']
  includeMainAndDeployed: boolean
  consumer?: string
  enablePending?: boolean
  requestFilter?: ProxyOptions['requestFilter']
  publishVerificationResult?: boolean
  pactBrokerToken?: string
  providerVersion?: string
  providerVersionBranch?: string
  providerVersionTags?: string[]
  pactBrokerUrl?: string
  pactPayloadUrl?: string
}): VerifierOptions {
  console.table({
    Provider: provider,
    Port: port,
    'Log Level': logLevel,
    'State Handlers': stateHandlers ? 'Provided' : 'Not Provided',
    'Include Main and Deployed': includeMainAndDeployed,
    Consumer: consumer || 'All Consumers',
    PACT_BREAKING_CHANGE: process.env.PACT_BREAKING_CHANGE,
    PACT_BROKER_TOKEN: pactBrokerToken ? 'Provided' : 'Not Provided',
    'Provider Version': providerVersion,
    'Provider Version Branch': providerVersionBranch,
    'Provider Version Tags': providerVersionTags.join(', ') || 'None',
    'Pact Broker URL': pactBrokerUrl,
    'Pact Payload URL': pactPayloadUrl || 'Not Provided',
    'Enable Pending': enablePending,
    'Request Filter':
      requestFilter === noOpRequestFilter
        ? 'Default (No-Op)'
        : 'Custom Provided'
  })

  const options: VerifierOptions = {
    provider,
    logLevel,
    stateHandlers,
    beforeEach,
    afterEach,
    requestFilter,
    providerBaseUrl: `http://localhost:${port}`,
    publishVerificationResult,
    pactBrokerToken,
    providerVersion,
    providerVersionBranch,
    providerVersionTags,
    enablePending // Use this if breaking changes from a consumer somehow got in main, and the provider cannot release (allow blasphemy!)
  }

  // When the CI triggers the provider tests, we need to use the PACT_PAYLOAD_URL
  // To use the PACT_PAYLOAD_URL, we need to update the provider options to use this URL instead.
  handlePactBrokerUrlAndSelectors({
    pactPayloadUrl,
    pactBrokerUrl,
    consumer,
    includeMainAndDeployed,
    options
  })

  return options
}

/**
 * Builds a `PactMessageProviderOptions` object for message-based Pact verification,
 * encapsulating common provider test setup options for message handlers, Pact Broker options,
 * and dynamically generated consumer version selectors for message interactions.
 *
 * @param provider - The name of the provider being verified.
 * @param messageProviders - Handlers that map to specific message interactions defined by the consumer Pact.
 * @param includeMainAndDeployed - Flag to include `mainBranch` and `deployedOrReleased` selectors for verifying consumer interactions.
 * @param stateHandlers - (Optional) Handlers to simulate provider states based on consumer expectations.
 * @param consumer - (Optional) A specific consumer to run verification for. If not provided, all consumers will be verified.
 * @param enablePending - (Optional, defaults to `false`) Whether to enable pending pacts.
 * @param logLevel - (Optional) Log level for debugging (e.g., 'info', 'debug').
 * @param publishVerificationResult - (Optional, defaults to `true`) Whether to publish verification results.
 * @param pactBrokerToken - (Optional) Token for authentication with the Pact Broker.
 * @param providerVersion - (Optional) The version of the provider, typically tied to a Git commit or build.
 * @param providerVersionBranch - (Optional) The branch of the provider being verified.
 * @param providerVersionTags - (Optional) Tags to associate with the provider version, such as branch names or environment names.
 * @param pactBrokerUrl - (Optional) URL of the Pact Broker.
 * @param pactPayloadUrl - (Optional) URL for fetching the pact payload (used in CI environments).
 *
 * @returns A fully configured `PactMessageProviderOptions` object for message-based Pact verification.
 *
 * @example
 * const options = buildMessageVerifierOptions({
 *   provider: 'MoviesAPI',
 *   messageProviders,
 *   includeMainAndDeployed: true,
 *   pactBrokerUrl: process.env.PACT_BROKER_BASE_URL
 * })
 */
export function buildMessageVerifierOptions({
  provider,
  messageProviders,
  includeMainAndDeployed,
  stateHandlers,
  consumer,
  enablePending = false,
  logLevel = 'info',
  publishVerificationResult = true,
  pactBrokerToken = process.env.PACT_BROKER_TOKEN,
  providerVersion = process.env.GITHUB_SHA || 'unknown',
  providerVersionBranch = process.env.GITHUB_BRANCH || 'main', // default to 'main' if provider branch is not set
  providerVersionTags = getProviderVersionTags(),
  pactBrokerUrl = process.env.PACT_BROKER_BASE_URL,
  pactPayloadUrl = process.env.PACT_PAYLOAD_URL
}: {
  provider: string
  messageProviders: MessageProviders
  includeMainAndDeployed: boolean
  stateHandlers?: StateHandlers & MessageStateHandlers
  consumer?: string
  enablePending?: boolean
  logLevel?: ProxyOptions['logLevel']
  publishVerificationResult?: boolean
  pactBrokerToken?: string
  providerVersion?: string
  providerVersionBranch?: string
  providerVersionTags?: string[]
  pactBrokerUrl?: string
  pactPayloadUrl?: string
}): PactMessageProviderOptions {
  console.table({
    Provider: provider,
    'Message Handlers': messageProviders ? 'Provided' : 'Not Provided',
    'State Handlers': stateHandlers ? 'Provided' : 'Not Provided',
    'Include Main and Deployed': includeMainAndDeployed,
    Consumer: consumer || 'All Consumers',
    PACT_BROKER_TOKEN: pactBrokerToken ? 'Provided' : 'Not Provided',
    'Provider Version': providerVersion,
    'Provider Version Branch': providerVersionBranch,
    'Provider Version Tags': providerVersionTags.join(', ') || 'None',
    'Pact Broker URL': pactBrokerUrl || 'Not Provided',
    'Pact Payload URL': pactPayloadUrl || 'Not Provided',
    'Enable Pending': enablePending,
    'Log Level': logLevel
  })

  const options: PactMessageProviderOptions = {
    provider,
    messageProviders,
    stateHandlers,
    logLevel,
    publishVerificationResult,
    pactBrokerToken,
    providerVersion,
    providerVersionBranch,
    providerVersionTags,
    enablePending // Use this if breaking changes from a consumer somehow got in main, and the provider cannot release (allow blasphemy!)
  }

  handlePactBrokerUrlAndSelectors({
    pactPayloadUrl,
    pactBrokerUrl,
    consumer,
    includeMainAndDeployed,
    options
  })

  return options
}



================================================
FILE: src/test-helpers/pact-utils/handle-url-and-selectors.ts
================================================
import type {
  PactMessageProviderOptions,
  VerifierOptions
} from '@pact-foundation/pact'
import type { ConsumerVersionSelector } from '@pact-foundation/pact-core'
// eslint-disable-next-line @typescript-eslint/no-require-imports
const isCI = require('is-ci')

/**
 * Handles the conditional logic for selecting the Pact Broker URL and consumer version selectors.
 * It updates the verifier options accordingly based on the availability of the Pact payload URL or
 * Pact Broker base URL, and includes relevant consumer version selectors if needed.
 *
 * @param pactPayloadUrl - The URL for Pact payloads, used when CI triggers provider tests.
 * @param pactBrokerUrl - The base URL for the Pact Broker.
 * @param consumer - (Optional) A specific consumer to verify. If not provided, all consumers are verified.
 * @param includeMainAndDeployed - Flag indicating whether to include `mainBranch` and `deployedOrReleased` selectors.
 * @param options - The options object to update with Pact URL or Pact Broker information.
 */
export function handlePactBrokerUrlAndSelectors({
  pactPayloadUrl,
  pactBrokerUrl,
  consumer,
  includeMainAndDeployed,
  options
}: {
  pactPayloadUrl?: string
  pactBrokerUrl?: string
  consumer?: string
  includeMainAndDeployed: boolean
  options: PactMessageProviderOptions | VerifierOptions
}) {
  // If pactPayloadUrl is provided, attempt to use it
  if (pactPayloadUrl) {
    const usedPayloadUrl = processPactPayloadUrl(
      pactPayloadUrl,
      consumer,
      options
    )
    if (usedPayloadUrl) {
      return // Successfully used the Pact payload URL, no need to proceed further
    }
    // If not used, continue to set up options using the Pact Broker URL and selectors
  }

  // Use the Pact Broker URL and consumer version selectors
  usePactBrokerUrlAndSelectors({
    pactBrokerUrl,
    consumer,
    includeMainAndDeployed,
    options
  })
}

/**
 * Processes the Pact payload URL to determine if it should be used for verification.
 *
 * @param pactPayloadUrl - The URL of the Pact payload.
 * @param consumer - (Optional) The name of the consumer.
 * @param options - The verifier options to update.
 * @returns `true` if the Pact payload URL was used; otherwise, `false`.
 */
function processPactPayloadUrl(
  pactPayloadUrl: string,
  consumer: string | undefined,
  options: PactMessageProviderOptions | VerifierOptions
): boolean {
  console.log(`Pact payload URL provided: ${pactPayloadUrl}`)

  const parsed = parseProviderAndConsumerFromUrl(pactPayloadUrl)

  // If we got the provider and consumer names from the URL
  if (parsed) {
    const { provider: pactUrlProvider, consumer: pactUrlConsumer } = parsed
    console.log(`Pact URL Provider: ${pactUrlProvider}`)
    console.log(`Pact URL Consumer: ${pactUrlConsumer}`)

    // Compare the provider and consumer names with the intended/provided provider and consumer
    const providerMatches = options.provider === pactUrlProvider
    // If no consumer is provided, ignore the consumer name, allowing all consumers to match.
    // Otherwise, verify only the specified consumer.
    const consumerMatches = !consumer || consumer === pactUrlConsumer

    if (providerMatches && consumerMatches) {
      usePactPayloadUrl(pactPayloadUrl, options)
      return true // Indicate that the Pact payload URL was used
    } else {
      console.log(
        `PACT_PAYLOAD_URL does not match the provider (${options.provider}) and consumer (${consumer || 'all'}), ignoring it`
      )
    }
  } else {
    console.log(
      'Could not parse provider and consumer from PACT_PAYLOAD_URL, ignoring it'
    )
  }

  return false // Indicate that the Pact payload URL was not used
}

/**
 * Parses the provider and consumer names from the given Pact payload URL. *
 * @param pactPayloadUrl - The URL of the Pact payload.
 * @returns An object containing the provider and consumer names if parsing is successful; otherwise, null.
 * */
function parseProviderAndConsumerFromUrl(
  pactPayloadUrl: string
): { provider: string; consumer: string } | null {
  // match url pattern: /pacts/provider/{provider_name}/consumer/{consumer_name}/
  // with 2 capture groups: provider_name and consumer_name
  const regex = /\/pacts\/provider\/([^/]+)\/consumer\/([^/]+)\//
  const match = regex.exec(pactPayloadUrl)

  if (match) {
    const provider = decodeURIComponent(match[1] as string)
    const consumer = decodeURIComponent(match[2] as string)
    return { provider, consumer }
  }

  return null
}

/**
 * Configures the verifier options to use the Pact payload URL for verification.
 *
 * @param pactPayloadUrl - The URL of the Pact payload.
 * @param options - The verifier options to update.
 */
function usePactPayloadUrl(
  pactPayloadUrl: string,
  options: PactMessageProviderOptions | VerifierOptions
) {
  console.log(
    'PACT_PAYLOAD_URL matches the provider and consumer, using it for verification'
  )
  options.pactUrls = [pactPayloadUrl]

  // remove pactBrokerUrl and consumerVersionSelectors if set
  delete options.pactBrokerUrl
  delete options.consumerVersionSelectors
}

/**
 * Configures the verifier options to use the Pact Broker URL and consumer version selectors.
 *
 * @param pactBrokerUrl - The base URL of the Pact Broker.
 * @param consumer - (Optional) The name of the consumer.
 * @param includeMainAndDeployed - Whether to include main and deployed/released selectors.
 * @param options - The verifier options to update.
 */
function usePactBrokerUrlAndSelectors({
  pactBrokerUrl,
  consumer,
  includeMainAndDeployed,
  options
}: {
  pactBrokerUrl: string | undefined
  consumer: string | undefined
  includeMainAndDeployed: boolean
  options: PactMessageProviderOptions | VerifierOptions
}) {
  if (!pactBrokerUrl) {
    throw new Error('PACT_BROKER_BASE_URL is required but not set.')
  }

  console.log(`Using Pact Broker Base URL: ${pactBrokerUrl}`)

  options.pactBrokerUrl = pactBrokerUrl
  options.consumerVersionSelectors = buildConsumerVersionSelectors(
    consumer,
    includeMainAndDeployed
  )

  if (consumer) {
    console.log(`Running verification for consumer: ${consumer}`)
  } else {
    console.log('Running verification for all consumers')
  }

  if (includeMainAndDeployed) {
    console.log(
      'Including main branch and deployedOrReleased in the verification'
    )
  } else {
    console.log(
      'Only running the matching branch, this is useful when introducing breaking changes'
    )
  }

  // Log the consumer version selectors for debugging
  console.log(
    'Consumer Version Selectors:',
    JSON.stringify(options.consumerVersionSelectors, null, 2)
  )
}

/**
 * Generates an array of tags to associate with the provider version.
 * Tags can include the current branch name, environment, or other identifiers.
 * Tags are only used in Webhooks, therefore we use is-ci
 *
 * @returns An array of strings representing the provider version tags.
 *
 * @example
 * // In a CI environment with GITHUB_BRANCH set to 'refs/heads/feature-branch'
 * const tags = getProviderVersionTags()
 * // tags => ['feature-branch']
 */
export function getProviderVersionTags(): string[] {
  const tags = []

  if (isCI) {
    // only include dev if it's not a breaking change
    // Convert PACT_BREAKING_CHANGE to boolean
    const isBreakingChange = process.env.PACT_BREAKING_CHANGE === 'true'
    console.log({ isBreakingChange })
    // Only include 'dev' if it's not a breaking change
    if (!isBreakingChange) {
      tags.push('dev')
    }

    // Include the branch name as a tag
    if (process.env.GITHUB_BRANCH) {
      const branchName = process.env.GITHUB_BRANCH
      tags.push(branchName)
    }
  } else {
    tags.push('local')
  }

  console.log('providerVersionTags:', tags)
  return tags
}

/**
 * Builds an array of `ConsumerVersionSelector` objects for Pact verification.
 *
 * This function generates selectors that determine which consumer pacts should be verified against the provider.
 * By default, it includes pacts from branches matching the provider's branch, and optionally includes pacts from
 * the consumer's `main` branch and deployed or released versions.
 *
 * **Note:** The `branch: '*'` selector has been removed to prevent the provider from verifying pacts from all
 * consumer branches, which can include irrelevant or unverified branches.
 *
 * @param consumer - The name of the consumer to verify against. If `undefined`, applies to all consumers.
 * @param includeMainAndDeployed - When `true` (default), includes `mainBranch` and `deployedOrReleased` selectors for broader verification.
 *                                 When `false`, only verifies pacts from matching branches.
 * @returns An array of `ConsumerVersionSelector` objects for Pact verification.
 *
 * @example
 * // Verify pacts for a specific consumer, including main and deployed versions (default behavior)
 * const selectors = buildConsumerVersionSelectors('WebConsumer');
 * // Result:
 * // [
 * //   { consumer: 'WebConsumer', matchingBranch: true },
 * //   { consumer: 'WebConsumer', mainBranch: true },
 * //   { consumer: 'WebConsumer', deployedOrReleased: true }
 * // ]
 *
 * @example
 * // Verify pacts for a specific consumer, excluding mainBranch and deployedOrReleased
 * const selectors = buildConsumerVersionSelectors('WebConsumer', false);
 * // Result:
 * // [
 * //   { consumer: 'WebConsumer', matchingBranch: true }
 * // ]
 *
 * @example
 * // Verify pacts for all consumers, including main and deployed versions
 * const selectors = buildConsumerVersionSelectors(undefined);
 * // Result:
 * // [
 * //   { matchingBranch: true },
 * //   { mainBranch: true },
 * //   { deployedOrReleased: true }
 * // ]
 *
 * @example
 * // Verify pacts for all consumers, excluding mainBranch and deployedOrReleased
 * const selectors = buildConsumerVersionSelectors(undefined, false);
 * // Result:
 * // [
 * //   { matchingBranch: true }
 * // ]
 *
 * @see https://docs.pact.io/pact_broker/advanced_topics/consumer_version_selectors
 */
function buildConsumerVersionSelectors(
  consumer: string | undefined,
  includeMainAndDeployed = true
): ConsumerVersionSelector[] {
  // Create the base selector object.
  // If a specific consumer is provided, include it in the selector.
  const baseSelector: Partial<ConsumerVersionSelector> = consumer
    ? { consumer }
    : {}

  // Start with selectors that always apply.
  // - 'matchingBranch: true' includes branches that match the provider's branch.
  const selectors: ConsumerVersionSelector[] = [
    { ...baseSelector, matchingBranch: true } // Includes matching branches
  ]

  // If 'includeMainAndDeployed' is true, include selectors for:
  // - The main branch of the consumer (mainBranch: true)
  // - Deployed or released versions of the consumer (deployedOrReleased: true)
  if (includeMainAndDeployed) {
    selectors.push({ ...baseSelector, mainBranch: true }) // Includes the main branch of the consumer
    selectors.push({ ...baseSelector, deployedOrReleased: true }) // Includes deployed or released consumer versions
  }

  // The 'branch: "*"' selector has been intentionally removed to prevent
  // verification of pacts from all branches, which may include irrelevant or
  // unverified branches.

  return selectors
}



================================================
FILE: src/test-helpers/pact-utils/pact-request-filter.ts
================================================
import type { ProxyOptions } from '@pact-foundation/pact/src/dsl/verifier/proxy/types'

/* 
why? read https://dev.to/muratkeremozcan/building-custom-request-filters-for-pactjs-verifications-in-express-and-non-express-environments-4b5e
TL,DR;
This setup allows Pact tests to handle authorization tokens flexibly,
ensuring they’re present in HTTP requests for both Express and non-Express environments. 

The higher-order function pattern and handleExpressEnv function provide compatibility with Pact's request expectations,
letting the same code seamlessly support Express-style middleware (next() function) and other environments, 
like Lambda, where middleware may not be used. 

This design also permits custom token generation, a feature for tests needing dynamic tokens w
without persisting them in Pact files.
*/

// generic HttpRequest structure to accommodate both Express and non-Express environments
type HttpRequest = {
  headers: Record<string, string | string[] | undefined>
  body?: unknown
}

type NextFunction = () => void | undefined

// allows customization of token generation logic
type RequestFilterOptions = {
  tokenGenerator?: () => string
}

/**
 * Handles environments with and without Express-like `next()` middleware.
 * If `next()` is present, it will call it; otherwise, it returns the modified request.
 * @param {HttpRequest} req - The incoming HTTP request object.
 * @param {NextFunction} next - The Express-style `next()` function, if available.
 * @returns {HttpRequest | undefined} - The modified request or undefined if `next()` was called. */
const handleExpressEnv = (
  req: HttpRequest,
  next: NextFunction
): HttpRequest | undefined => {
  // If this is an Express environment, call next()
  if (next && typeof next === 'function') {
    next()
  } else {
    // In a non-Express environment, return the modified request
    return req
  }
}

/**
 * Creates a request filter function that adds an Authorization header if not present.
 * The function is designed as a higher-order function to allow for customization of token generation
 * and also to fulfill Pact's express-like type requirements of handling three arguments : `req`, `res`, and `next`.
 *
 * @param {RequestFilterOptions} [options] - Options to customize the token generation logic.
 * @returns {ProxyOptions['requestFilter']} - A request filter that adds Authorization header. */
const createRequestFilter =
  (options?: RequestFilterOptions): ProxyOptions['requestFilter'] =>
  (req, _, next) => {
    const defaultTokenGenerator = () => new Date().toISOString()
    const tokenGenerator = options?.tokenGenerator || defaultTokenGenerator

    // add an authorization header if not present
    if (!req.headers['Authorization']) {
      req.headers['Authorization'] = `Bearer ${tokenGenerator()}`
    }

    return handleExpressEnv(req, next)
  }

// if you have a token generator, pass it as an option
// createRequestFilter({ tokenGenerator: myCustomTokenGenerator })
export const requestFilter = createRequestFilter()

export const noOpRequestFilter: ProxyOptions['requestFilter'] = (
  req,
  _,
  next
) => handleExpressEnv(req, next)



================================================
FILE: src/utils/format-response.ts
================================================
import type { Response } from 'express'
import type {
  ConflictMovieResponse,
  CreateMovieResponse,
  DeleteMovieResponse,
  GetMovieResponse,
  MovieNotFoundResponse,
  UpdateMovieResponse
} from '../@types'

type MovieResponse =
  | DeleteMovieResponse
  | GetMovieResponse
  | UpdateMovieResponse
  | CreateMovieResponse
  | MovieNotFoundResponse
  | ConflictMovieResponse

export function formatResponse(res: Response, result: MovieResponse): Response {
  if ('error' in result && result.error) {
    return res
      .status(result.status)
      .json({ status: result.status, error: result.error })
  } else if ('data' in result) {
    if (result.data === null) {
      return res
        .status(result.status)
        .json({ status: result.status, error: 'No movies found' })
    }
    return res
      .status(result.status)
      .json({ status: result.status, data: result.data })
  } else if ('message' in result) {
    // Handle delete movie case with a success message
    return res
      .status(result.status)
      .json({ status: result.status, message: result.message })
  } else {
    return res.status(500).json({ error: 'Unexpected error occurred' })
  }
}



================================================
FILE: .github/PULL_REQUEST_TEMPLATE.md
================================================
### Pact Breaking Change?

- [ ] Pact breaking change (check if this PR introduces a breaking change, which relaxes Pact verification to only run vs the matching branch of the consumer).



================================================
FILE: .github/workflows/contract-test-publish-openapi.yml
================================================
# Once the PR is merged into the main branch,
# we publish the provider contract (the OpenAPI spec) to Pact broker.
# The schema already got tested in the e2e job.

name: Publish Pact OpenApi

on:
  push:
    branches:
      - main
  workflow_dispatch:

env:
  PACT_BROKER_BASE_URL: ${{ secrets.PACT_BROKER_BASE_URL }}
  PACT_BROKER_TOKEN: ${{ secrets.PACT_BROKER_TOKEN }}
  GITHUB_SHA: ${{ github.sha }}
  GITHUB_BRANCH: ${{ github.head_ref }}

jobs:
  publish-pact-openapi:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
        with:
          ref: ${{ github.head_ref }} # Ensure you're on the correct branch

      - name: Read Node version from .nvmrc
        id: node_version
        run: echo "NODE_VERSION=$(cat .nvmrc)" >> $GITHUB_ENV

      - uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}

      - name: Install dependencies
        run: npm ci

      - name: Publish Provider OpenApi to Pact
        run: npm run publish:pact-openapi

      - name: Record provider deployment
        if: github.ref == 'refs/heads/main'
        run: npm run record:provider:bidirectional:deployment --env=dev



================================================
FILE: .github/workflows/contract-test.yml
================================================
name: Run contract tests

on:
  pull_request:
    types: [opened, synchronize, reopened, edited]
  push:
    branches:
      - main

concurrency:
  group: ${{ github.workflow }}-${{ github.head_ref || github.ref }}
  cancel-in-progress: true
  
env:
  PACT_BROKER_BASE_URL: ${{ secrets.PACT_BROKER_BASE_URL }}
  PACT_BROKER_TOKEN: ${{ secrets.PACT_BROKER_TOKEN }}
  GITHUB_SHA: ${{ github.sha }}
  GITHUB_BRANCH: ${{ github.head_ref || github.ref_name }}
  DATABASE_URL: 'file:./dev.db'
  PORT: 3001

jobs:
  contract-test:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          # During a pull_request event, it checks out the PR branch.
          # During a push event, it checks out the branch that was pushed to (e.g., main)
          ref: ${{ github.head_ref || github.ref_name }}
          fetch-depth: 0 # Ensure full git history is available

      - name: Read Node version from .nvmrc
        id: node_version
        run: echo "NODE_VERSION=$(cat .nvmrc)" >> $GITHUB_ENV

      - uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}

      # Set PACT_BREAKING_CHANGE based on PR description during pull_request events
      - name: Set PACT_BREAKING_CHANGE based on PR description checkbox (PR event)
        if: ${{ github.event_name == 'pull_request' }}
        uses: actions/github-script@v7
        with:
          script: |
            const prBody = context.payload.pull_request.body || '';

            // Check if the PR description contains a checked checkbox for Pact breaking change
            if (prBody.includes('[x] Pact breaking change')) {
              core.exportVariable('PACT_BREAKING_CHANGE', 'true');
              console.log('PACT_BREAKING_CHANGE set to true based on PR description checkbox.');
            } else {
              core.exportVariable('PACT_BREAKING_CHANGE', 'false');
              console.log('PACT_BREAKING_CHANGE remains false.');
            }

      # Set PACT_BREAKING_CHANGE based on merged PR description during push events
      - name: Set PACT_BREAKING_CHANGE based on merged PR description (push to main)
        if: ${{ github.event_name == 'push' && github.ref == 'refs/heads/main' }}
        uses: actions/github-script@v7
        with:
          script: |
            const commitSha = context.sha;
            const { data: prs } = await github.rest.repos.listPullRequestsAssociatedWithCommit({
              owner: context.repo.owner,
              repo: context.repo.repo,
              commit_sha: commitSha,
            });
            const mergedPr = prs.find(pr => pr.merged_at !== null && pr.merge_commit_sha === commitSha);
            if (mergedPr) {
              const prBody = mergedPr.body || '';
              if (prBody.includes('[x] Pact breaking change')) {
                core.exportVariable('PACT_BREAKING_CHANGE', 'true');
                console.log('PACT_BREAKING_CHANGE set to true based on merged PR description checkbox.');
              } else {
                core.exportVariable('PACT_BREAKING_CHANGE', 'false');
                console.log('PACT_BREAKING_CHANGE remains false.');
              }
            } else {
              core.exportVariable('PACT_BREAKING_CHANGE', 'false');
              console.log('No merged PR found for this commit. PACT_BREAKING_CHANGE remains false.');
            }

      # - name: Debug Environment Variables
      #   run: printenv | sort
      #   shell: bash

      - name: Install dependencies
        run: npm ci

      - name: Run provider contract tests
        run: |
          echo "Running provider contract tests with PACT_BREAKING_CHANGE=$PACT_BREAKING_CHANGE"
          npm run test:provider-ci

      - name: Can I deploy provider? # if breaking change, deploy without checking if we can
        if: env.PACT_BREAKING_CHANGE == 'false'
        run: npm run can:i:deploy:provider

      - name: Record provider deployment
        if: github.ref == 'refs/heads/main'
        run: npm run record:provider:deployment --env=dev



================================================
FILE: .github/workflows/e2e-test-cy.yml
================================================
name: Run e2e tests with cy
on:
  pull_request:
  workflow_dispatch:

# if this branch is pushed back to back, cancel the older branch's workflow
concurrency:
  group: ${{ github.workflow }}-${{ github.head_ref || github.ref }}
  cancel-in-progress: true
  
permissions:
  contents: write

env:
  DATABASE_URL: 'file:./dev.db'
  PORT: 3001
  GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
  CYPRESS_RECORD_KEY: ${{ secrets.CYPRESS_RECORD_KEY }}
  KAFKAJS_NO_PARTITIONER_WARNING: 1 # less kafka noise

jobs:
  cy-e2e-test:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
        with:
          ref: ${{ github.head_ref }}

      - name: Read Node version from .nvmrc
        id: node_version
        run: echo "NODE_VERSION=$(cat .nvmrc)" >> $GITHUB_ENV

      - uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}

      - name: Generate OpenAPI docs from code
        run: |
          npm install -D tsx
          npm run generate:openapi

      # Start Kafka before running the tests
      # Locally if no Kafka, the kafka version of the e2e test just doesn't run

      - name: Start Kafka
        continue-on-error: true # if we hit the docker pull limit, no kafka
        run: docker compose -f ./src/events/kafka-cluster.yml up -d --no-recreate

      - name: Cypress e2e tests 🧪
        id: cypress-tests
        uses: cypress-io/github-action@v6.7.10
        with:
          start: npm start
          config-file: cypress/config/local.config.ts
          record: true
          group: local
          tag: local

      # We do schema testing within the api e2e
      # We publish the OpenAPI spec on main, once after the PR is merged
      # Pact likes to have some file/evidence that the OpenAPI spec was tested
      # This section handles that need

      - name: Generate Verification Result for Success
        if: steps.cypress-tests.conclusion == 'success'
        run: echo "All Cypress tests passed." > cypress/verification-result.txt

      - name: Generate Verification Result for Failure
        if: steps.cypress-tests.conclusion != 'success'
        run: echo "Not all Cypress tests passed." > cypress/verification-result.txt

      - name: Commit and push verification result
        uses: EndBug/add-and-commit@v9
        with:
          author_name: 'GitHub Actions'
          author_email: 'actions@github.com'
          message: 'Update verification results'
          add: 'cypress/verification-result.txt'
          push: true

      # Stop Kafka after tests are completed
      - name: Stop Kafka
        continue-on-error: true
        if: always()
        run: docker compose -f ./src/events/kafka-cluster.yml down



================================================
FILE: .github/workflows/e2e-test-pw.yml
================================================
name: Run e2e tests with pw
on:
  push:
  workflow_dispatch:

# if this branch is pushed back to back, cancel the older branch's workflow
concurrency:
  group: ${{ github.workflow }}-${{ github.head_ref || github.ref }}
  cancel-in-progress: true

env:
  DATABASE_URL: 'file:./dev.db'
  PORT: 3001
  GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
  CYPRESS_RECORD_KEY: ${{ secrets.CYPRESS_RECORD_KEY }}
  KAFKAJS_NO_PARTITIONER_WARNING: 1 # less kafka noise

jobs:
  pw-e2e-test:
    timeout-minutes: 10
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
        with:
          ref: ${{ github.head_ref }}

      - name: Read Node version from .nvmrc
        id: node_version
        run: echo "NODE_VERSION=$(cat .nvmrc)" >> $GITHUB_ENV

      - uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}

      - name: Cache Playwright Browsers
        uses: actions/cache@v4
        with:
          path: ~/.cache/ms-playwright
          key: playwright-${{ runner.os }}-${{ github.sha }}
          restore-keys: |
            playwright-${{ runner.os }}-

      - name: Install dependencies
        run: npm ci

      - name: Install Playwright Chromium Only
        run: npx playwright install chromium

      # Start Kafka
      - name: Start Kafka
        continue-on-error: true # If Kafka fails to start, tests without Kafka can still run
        run: docker compose -f ./src/events/kafka-cluster.yml up -d --no-recreate

      - name: Run Playwright tests
        run: npm run pw:run-local

      # Stop Kafka after tests
      - name: Stop Kafka
        continue-on-error: true
        if: always()
        run: docker compose -f ./src/events/kafka-cluster.yml down

      - uses: actions/upload-artifact@v4
        if: ${{ !cancelled() }}
        with:
          name: playwright-artifacts
          path: |
            playwright-report/
            test-results/
          retention-days: 3



================================================
FILE: .github/workflows/merge-gatekeeper.yml
================================================
name: Merge Gatekeeper

on:
  pull_request:
    branches:
      - main

jobs:
  merge-gatekeeper:
    runs-on: ubuntu-latest
    permissions:
      checks: read
      statuses: read
    steps:
      - name: Run Merge Gatekeeper
        uses: upsidr/merge-gatekeeper@v1
        with:
          token: ${{ secrets.GITHUB_TOKEN }}



================================================
FILE: .github/workflows/pr-checks.yml
================================================
name: Run PR checks
on:
  pull_request:
  workflow_dispatch:

# if this branch is pushed back to back, cancel the older branch's workflow
concurrency:
  group: ${{ github.workflow }}-${{ github.head_ref || github.ref }}
  cancel-in-progress: true

jobs:
  pr-check:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4

      - name: Read Node version from .nvmrc
        id: node_version
        run: echo "NODE_VERSION=$(cat .nvmrc)" >> $GITHUB_ENV

      - uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}

      - name: Install dependencies
        run: npm ci

      - name: Run typecheck
        run: npm run typecheck

      - name: Run lint
        run: npm run lint

      - name: Run unit test
        run: npm run test



================================================
FILE: .github/workflows/schema-validation.yml
================================================
name: Run schema validation
on:
  pull_request:
  workflow_dispatch:

# if this branch is pushed back to back, cancel the older branch's workflow
concurrency:
  group: ${{ github.workflow }}-${{ github.head_ref || github.ref }}
  cancel-in-progress: true

# needed for Commit and push OpenAPI changes to work
permissions:
  contents: write

jobs:
  schema-validation:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
        with:
          # needed for Commit and push OpenAPI changes to work
          ref: ${{ github.head_ref }}
          persist-credentials: true

      - uses: actions/setup-node@v4
      - name: Read Node version from .nvmrc
        id: node_version
        run: echo "NODE_VERSION=$(cat .nvmrc)" >> $GITHUB_ENV

      - uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}

      - name: Install dependencies
        run: npm ci

      - name: Optic lint base OpenAPI spec ahead of other checks
        run: npm run optic:lint

      # This workflow exists so we do not have to locally generate the OpenAPI spec.
      # If the OpenAPI spec has changed, it commits and pushes those changes back to the PR branch
      - name: Generate OpenAPI spec from code
        run: npm run generate:openapi

      - name: Generate api docs for Github Pages (html)
        run: npm run generate:api-docs

      - name: Check if OpenAPI spec and/or API docs for Github Pages (html) have changed
        id: check_changes
        run: |
          if git diff --quiet src/api-docs/openapi.yml src/api-docs/openapi.json docs/api-docs.html; then
            echo "changes=false" >> $GITHUB_ENV
          else
            echo "changes=true" >> $GITHUB_ENV
          fi

      - name: Commit and push OpenAPI spec and API docs for Github Pages (html) changes
        if: env.changes == 'true'
        uses: EndBug/add-and-commit@v9
        with:
          author_name: 'GitHub Actions'
          author_email: 'actions@github.com'
          message: 'Update OpenAPI spec and API docs'
          add: 'src/api-docs/openapi.yml src/api-docs/openapi.json docs/api-docs.html'
          push: true
          github_token: ${{ secrets.PAT_TOKEN }}

      - name: Create empty commit to re-run checks
        if: env.changes == 'true'
        run: |
          git config --local user.email "actions@github.com"
          git config --local user.name "GitHub Actions"
          git commit --allow-empty -m "Re-run checks after OpenAPI update"
          git push origin HEAD:${{ github.head_ref }}

      # Schema validation
      - name: Fetch main branch for Optic (Begin schema validation)
        run: git fetch --depth=1 origin main:main

      - name: Optic diff (OpenAPI diff vs snapshot on main)
        run: npm run optic:diff



================================================
FILE: .github/workflows/webhook.yml
================================================
name: Webhook-triggered Provider Contract Test

# read https://dev.to/muratkeremozcan/-streamlining-pact-verification-in-cicd-with-github-actions-extracting-consumer-branch-names-and-dynamic-provider-testing-22g4

on:
  repository_dispatch:
    types:
      - contract_requiring_verification_published

concurrency:
  group: ${{ github.ref }} && ${{ github.workflow }}
  cancel-in-progress: true

env:
  PACT_PAYLOAD_URL: ${{ github.event.client_payload.pact_url }}
  PACT_BROKER_BASE_URL: ${{ secrets.PACT_BROKER_BASE_URL }}
  PACT_BROKER_TOKEN: ${{ secrets.PACT_BROKER_TOKEN }}
  GITHUB_REPO_OWNER: 'muratkeremozcan'
  GITHUB_REPO_NAME: 'pact-js-example-provider'
  DATABASE_URL: 'file:./dev.db'
  PORT: 3001

jobs:
  verify_pact:
    runs-on: ubuntu-latest
    steps:
      # Step 1: Log Payload Variables
      # This step logs the initial variables received from the event payload.
      # It's useful for debugging and ensuring variables are correctly passed.
      - name: Log Payload Variables
        run: |
          echo "PACT_PAYLOAD_URL: ${{ env.PACT_PAYLOAD_URL }}"
          echo "GITHUB_SHA: ${{ github.event.client_payload.sha }}"
          echo "GITHUB_BRANCH: ${{ github.event.client_payload.branch }}"
          echo "PACT_BROKER_BASE_URL: ${{ env.PACT_BROKER_BASE_URL }}"

      # Step 2: Install jq
      # jq is a lightweight and flexible command-line JSON processor.
      # We use it to parse JSON responses from the Pact Broker.
      - name: Install jq
        run: |
          sudo apt-get update
          sudo apt-get install -y jq

      # Step 3: Extract consumer branch name
      # This step fetches the consumer's branch name from the Pact Broker
      # and sets CONSUMER_BRANCH environment variable for use in subsequent steps.
      - name: Extract consumer branch name and set PACT_BREAKING_CHANGE
        shell: bash
        env:
          PACT_BROKER_TOKEN: ${{ secrets.PACT_BROKER_TOKEN }}
          PACT_PAYLOAD_URL: ${{ env.PACT_PAYLOAD_URL }}
        run: |
          echo "Starting extraction of consumer branch name from Pact Broker..."

          # Fetch the pact JSON from the Pact Broker using the PACT_PAYLOAD_URL
          PACT_JSON=$(curl -s -H "Authorization: Bearer $PACT_BROKER_TOKEN" "$PACT_PAYLOAD_URL")

          # Extract the consumer version URL from the pact JSON using jq
          CONSUMER_VERSION_URL=$(echo "$PACT_JSON" | jq -r '._links."pb:consumer-version".href')
          echo "DEBUG: Consumer Version URL: $CONSUMER_VERSION_URL"

          # Fetch the consumer version JSON
          CONSUMER_VERSION_JSON=$(curl -s -H "Authorization: Bearer $PACT_BROKER_TOKEN" "$CONSUMER_VERSION_URL")

          # Extract branch name directly from branchVersions
          CONSUMER_BRANCH=$(echo "$CONSUMER_VERSION_JSON" | jq -r '._embedded.branchVersions[0].name // "main"')
          echo "DEBUG: Selected consumer branch: $CONSUMER_BRANCH"

          # Determine if it's a breaking change
          if [[ "${CONSUMER_BRANCH,,}" == *"breaking"* && "${CONSUMER_BRANCH,,}" != "main" ]]; then
            echo "DEBUG: Setting PACT_BREAKING_CHANGE=true"
            echo "PACT_BREAKING_CHANGE=true" >> $GITHUB_ENV
            echo "Breaking change detected in branch: $CONSUMER_BRANCH"
          else
            echo "DEBUG: Setting PACT_BREAKING_CHANGE=false"
            echo "PACT_BREAKING_CHANGE=false" >> $GITHUB_ENV
            echo "No breaking change detected in branch: $CONSUMER_BRANCH"
          fi

          # Set the branch name in the environment
          echo "CONSUMER_BRANCH=$CONSUMER_BRANCH" >> $GITHUB_ENV

          # Final debug output
          echo "Final state:"
          echo "- Consumer Branch: $CONSUMER_BRANCH"
          echo "- PACT_BREAKING_CHANGE: $(cat $GITHUB_ENV | grep 'PACT_BREAKING_CHANGE' | cut -d'=' -f2)"

      # Step 4: Checkout code using actions/checkout
      # We use actions/checkout to clone the repository and fetch all branches.
      - uses: actions/checkout@v4
        with:
          # Fetch all branches and history so we can switch branches
          fetch-depth: 0
          # Specify the repository to check out
          repository: ${{ env.GITHUB_REPO_OWNER }}/${{ env.GITHUB_REPO_NAME }}

      # Step 5: Checkout matching branch or default to main
      # Attempts to checkout the branch that matches the consumer branch.
      # If it doesn't exist in the provider repo, defaults to 'main'.
      - name: Checkout matching branch or default to main
        shell: bash
        run: |
          # Fetch all remote branches
          git fetch --all
          # Check if the branch exists in the remote repository
          if git ls-remote --exit-code --heads origin "${CONSUMER_BRANCH}"; then
            echo "Branch '${CONSUMER_BRANCH}' exists in the remote repository."
            git checkout "${CONSUMER_BRANCH}"
            echo "GITHUB_BRANCH=${CONSUMER_BRANCH}" >> $GITHUB_ENV
          else
            echo "Branch '${CONSUMER_BRANCH}' does not exist in the remote repository. Using 'main' branch."
            git checkout main
            echo "GITHUB_BRANCH=main" >> $GITHUB_ENV
          fi

      # Step 6: Install dependencies
      - name: Install dependencies
        run: npm ci

      # Step 7: Run provider tests
      # Executes the provider tests using the test:provider-ci script.
      # Environment variables are set for use within the test scripts.
      - name: Run provider tests
        env:
          PACT_PAYLOAD_URL: ${{ env.PACT_PAYLOAD_URL }}
          PACT_BROKER_BASE_URL: ${{ env.PACT_BROKER_BASE_URL }}
          PACT_BROKER_TOKEN: ${{ secrets.PACT_BROKER_TOKEN }}
          GITHUB_SHA: ${{ github.event.client_payload.sha }}
          GITHUB_BRANCH: ${{ env.GITHUB_BRANCH }}
          DATABASE_URL: ${{ env.DATABASE_URL }}
          PORT: ${{ env.PORT }}
          PACT_BREAKING_CHANGE: ${{ env.PACT_BREAKING_CHANGE }}
        run: |
          echo "Running provider contract tests with PACT_BREAKING_CHANGE=$PACT_BREAKING_CHANGE"
          npm run test:provider-ci


