Directory structure:
└── noriste-ui-testing-best-practices/
    ├── README.md
    ├── README.ZH.md
    ├── LICENSE
    ├── assets/
    │   └── images/
    │       ├── viconblue.PNG
    │       ├── perf-testing/
    │       │   └── insights.PNG
    │       └── ui-state/
    │           └── devtools-network.PNG
    └── sections/
        ├── draft.md
        ├── template.md
        ├── advanced/
        │   ├── combinatorial-testing.md
        │   ├── combinatorial-testing.zh.md
        │   ├── email-testing.md
        │   ├── email-testing.zh.md
        │   ├── performance-testing.md
        │   ├── performance-testing.zh.md
        │   ├── test-flake.md
        │   ├── test-flake.zh.md
        │   ├── test-states.md
        │   └── test-states.zh.md
        ├── beginners/
        │   ├── top-to-bottom-approach.md
        │   └── top-to-bottom-approach.zh.md
        ├── generic-best-practices/
        │   ├── await-dont-sleep.md
        │   ├── await-dont-sleep.zh.md
        │   ├── name-test-files-wisely.md
        │   ├── name-test-files-wisely.zh.md
        │   ├── reaching-ui-state.md
        │   ├── reaching-ui-state.zh.md
        │   ├── test-code-with-debugging-in-mind.md
        │   ├── test-code-with-debugging-in-mind.zh.md
        │   ├── ui-tests-debugging-best-practices.md
        │   ├── ui-tests-debugging-best-practices.zh.md
        │   ├── use-your-testing-tool-as-your-primary-development-tool.md
        │   └── use-your-testing-tool-as-your-primary-development-tool.zh.md
        ├── real-life-examples/
        │   ├── from-unreadable-react-component-tests-to-simple-ones.md
        │   ├── from-unreadable-react-component-tests-to-simple-ones.zh.md
        │   ├── test-front-end-with-integration-back-end-with-e2e.md
        │   └── test-front-end-with-integration-back-end-with-e2e.zh.md
        ├── server-communication-testing/
        │   ├── monitoring-tests.md
        │   ├── monitoring-tests.zh.md
        │   ├── test-request-and-response-payload.md
        │   └── test-request-and-response-payload.zh.md
        ├── testing-perks/
        │   ├── tests-as-documentation.md
        │   └── tests-as-documentation.zh.md
        ├── testing-strategy/
        │   ├── avoid-perfectionism.md
        │   ├── avoid-perfectionism.zh.md
        │   ├── choose-a-reference-browser.md
        │   ├── choose-a-reference-browser.zh.md
        │   ├── component-vs-integration-vs-e2e-testing.md
        │   ├── component-vs-integration-vs-e2e-testing.zh.md
        │   ├── small-tests-or-long-ones.md
        │   ├── small-tests-or-long-ones.zh.md
        │   ├── write-test-then-fix-bug.md
        │   └── write-test-then-fix-bug.zh.md
        └── tools/
            ├── cypress-and-storybook-exposing-component-from-story.md
            ├── cypress-and-storybook-exposing-component-from-story.zh.md
            ├── cypress-and-storybook.md
            ├── cypress-and-storybook.zh.md
            ├── cypress-react-component-test.md
            ├── cypress-react-component-test.zh.md
            ├── ui-testing-problems-cypress.md
            ├── ui-testing-problems-cypress.zh.md
            ├── visual-regression-testing.md
            └── visual-regression-testing.zh.md

================================================
FILE: README.md
================================================
<!-- markdownlint-disable MD041 -->
<!-- markdownlint-disable MD033 -->
<div align="right"><strong>🇬🇧 English version</strong>  | <strong><a href="./README.ZH.md">🇨🇳 中文 (Chinese version)</a></strong></div>
<!-- markdownlint-disable MD041 -->
<!-- markdownlint-disable MD033 -->

# UI Testing Best Practices

<h1 align="center">
  <img src="assets/images/banner-2.png" alt="UI testing Best Practices">
</h1>

<br/>

<div align="center">
  <img src="https://img.shields.io/badge/⚙%20Item%20count%20-%2026%20Chapters-blue.svg" alt="26 items"> <img src="https://img.shields.io/badge/%F0%9F%93%85%20Last%20update%20-%20Jun%202025-green.svg" alt="Last update: June, 2025">
</div>

<br/>

**Follow us on Twitter or LinkedIn!**:
- [**@NoriSte**](https://twitter.com/NoriSte/) - [Stefano Magni](https://www.linkedin.com/in/noriste/)
- [**@MuratKeremOzcan**](https://twitter.com/MuratKeremOzcan/) - [Murat Ozcan](https://www.linkedin.com/in/murat-ozcan-3489898/)

and reach out to us if you need a consultancy or a course.

###### Built and maintained by our [Steering Committee](#steering-committee) and [Collaborators](#collaborators)

## Table of Contents

1.  [Testing strategies (5)](#1-testing-strategies)
2.  [Generic Best Practices (6)](#2-generic-best-practices)
3.  [Server Communication Testing (3)](#3-server-communication-testing)
4.  [Beginners (1)](#4-beginners)
5.  [Generic testing perks (1)](#5-generic-testing-perks)
6.  [Tools (2)](#6-tools)
7.  [Advanced (5)](#7-advanced)
8.  [Real Life Examples (2)](#8-real-life-examples)
9.  [Obsolete chapters (3)](#9-obsolete-chapters)

<br/><br/>

# `1. Testing strategies`

## 1.1 Component tests vs (UI) Integration tests vs E2E tests

**TL;DR:** Identifying the test types is the starting point to understand and master all the UI testing strategies, the tools, and the pro/cons of them. UI integration tests are the most effective ones (you are going to love them), E2E tests give you the highest confidence, and Component tests allow you to test the units of the UI in isolation.

**Otherwise:** You end up writing a lot of E2E tests without leveraging other simpler kind of tests. E2E tests are the most confident type of tests but even the hardest, slowest and most brittle ones.

🔗 [**Read More: Component vs (UI) Integration vs E2E tests**](/sections/testing-strategy/component-vs-integration-vs-e2e-testing.md)

<br/>

## 1.2 In the beginning, avoid perfectionism

**TL;DR:** Software Testing is an amazing topic but a limited experience could make you fighting with a new enemy instead of relying on a new ally. Avoid, if you can, to test every complex user flows since the beginning of your UI testing journey. The simpler your first tests are, the sooner you get the advantages.

**Otherwise:** You create complex and hard to be debugged tests. This kind of tests slow down your work and do not have any kind of usefulness.

🔗 [**Read More: In the beginning, avoid perfectionism**](/sections/testing-strategy/avoid-perfectionism.md)

<br/>

## 1.3 Choose a reference browser

**TL;DR:** Cross-browser testing is way overrated. It's an important topic and it's the first thing you can think while starting evaluating the right testing tool. Don't worry: start by splitting functional testing from visual testing, that's the first step to correctly evaluate the need for cross-browser support (and to choose the right testing tool, too). Visual testing can be integrated into every testing tool, thank services like Applitools and Percy.

**Otherwise:** You could choose the wrong testing tool based on the cross-browser support.

🔗 [**Read More: Choose a reference browser**](/sections/testing-strategy/choose-a-reference-browser.md)

<br/>

## 1.4 Found a bug? Write the test, then fix it

**TL;DR:** A test is a good ally when you need to be sure that you are able to systematically reproducing a bug. A test allows you to speed up the fixing flow and to be 100% confident that the same bug is caught forever.

**Otherwise:** You could not identify correctly the bug and you can not be sure that the bug will not present again in the future.

🔗 [**Read More: Found a bug? Write the test, then fix it**](/sections/testing-strategy/write-test-then-fix-bug.md)

<br/>

## 1.5 One long E2E test or small, independent ones?

**TL;DR:** When dealing with E2E tests and their difficulties, opting for a lot of small and independent tests or for a long one is not an obvious choice. Either the solutions have pros and cons, deriving from the inner complexity of the E2E tests where you deal with a real back-end and real data.

**Otherwise:** You could create hard-to-maintain E2E tests.

🔗 [**Read More: One long E2E test or small, independent ones?**](/sections/testing-strategy/small-tests-or-long-ones.md)

<br/><br/>

# `2. Generic Best Practices`

## 2.1 Await, don't sleep

**TL;DR:** When testing your UI, you define a sort of key points the app must pass through. Reaching these key
points is an asynchronous process because, almost 100% of the times, your UI does not update
synchronously. Those key points are called **deterministic events**, as known as something that you
know that must happen. You need to wait for these events to make your tests robust.

**Otherwise:** Sleeping the tests make your tests slow and brittle, it's one of the most common and biggest errors in UI testing.

🔗 [**Read More: Await, don't sleep**](/sections/generic-best-practices/await-dont-sleep.md)

<br/>

## 2.2 Name your test files wisely

**TL;DR:** Lot of times you need to launch just a type of tests and it's super easy if you follow a
common pattern while naming your testing files.

**Otherwise:** You need to launch a long test suite just to have some of them run.

🔗 [**Read More: Name the test files
wisely**](/sections/generic-best-practices/name-test-files-wisely.md)

<br/>

## 2.3 UI Tests Debugging Best Practices

**TL;DR:** Debugging a UI test could be really hard, especially if you use generic browser automation tools. Here is a list of simple rules that are at the base of the debugging process.

**Otherwise:** You are going to waste a lot of time without taming the exponential complexity of a UI test.

🔗 [**Read More: UI Tests Debugging Best Practices**](/sections/generic-best-practices/ui-tests-debugging-best-practices.md)

<br/>

## 2.4 Reaching UI state for tests without using the UI

**TL;DR:** As a developer who wants to ensure quality, it is important to think about cost of tests vs the value they provide. Where reasonable, strive to not duplicate effort, and still get high value by considering alternatives for setting up state for a test.

🔗 [**Read More: Reaching UI state**](./sections/generic-best-practices/reaching-ui-state.md)

<br/>

## 2.5 Use your testing tool as your primary development tool

**TL;DR:** Leveraging your testing tool to avoid manual tests is one of the biggest improvements you
could do to speed up your working flow. Testing tools are faster than you and the most modern ones include
some UI utilities that make easy to use them as a development tool.

**Otherwise:** You code the app the old way, losing a lot of time interacting manually with the UI itself.

🔗 [**Read More: Use your testing tool as your primary development tool**](/sections/generic-best-practices/use-your-testing-tool-as-your-primary-development-tool.md)

<br/>

## 2.6 Keep abstraction low to ease debugging the tests

**TL;DR:** Tests should be written with readability and debuggability in mind. Abstraction may be good in some instances, but it always incurs a cost in debuggability and therefore sometimes may not be worth it. This is especially important for UI tests; consequent of the complex stack, it can get harder to understand the real source of failures. Reducing abstraction for the sake of easier debugging is key for future proofing the test code.


**Otherwise:** There is a balance between abstraction and debuggability; the higher the abstraction, the harder it is going to be to debug the tests in the future.

🔗 [**Read More: Keep abstraction low to ease debugging the tests**](/sections/generic-best-practices/test-code-with-debugging-in-mind.md)

<br/><br/>

# `3. Server Communication Testing`

## 3.1 Test the request and response payloads

**TL;DR:** The UI communicates continuously with the back-end, and usually every communication is critical. A bad request or a bad response could cause inconsistent data and inconsistent UI state. Remember that all the business is built around data and the user experience is scratched by every single UI failure. So, every single XHR request must be checked carefully. XHR request checks make your test more robust too, correct XHR management and testing are one of the most important aspects of a UI test.

**Otherwise:** You could miss some relevant communication inconsistencies and when you need to debug them, you are going to waste a lot of time because the test will not drive you directly to the issue.

🔗 [**Read More: Test the request and response payloads**](/sections/server-communication-testing/test-request-and-response-payload.md)

<br/>

## 3.2 Test the server schema

**TL;DR:** A lot of times, the front-end application breaks because of a change in the back-end. Ask your back-end colleagues to allow you to export every schema that describes the back-end entities and the communication with the front-end. Some examples could be the GraphQL schema, the TypeScript types, the ElasticSearch mapping, the Pact contract, a Postman configuration etc. more in general, everything that can warn you that something changed in the back-end. Every back-end change could impact the front-end and you must discover it as soonest as possible.

**Otherwise:** You could miss some back-end change and your front-end application could break inadvertently.

<br/>

## 3.3 Monitoring tests

**TL;DR:** The more the test suites are launched periodically, the more confident you are that everything works as expected. UI tests should be based on the user perspective but there are a lot of small tests that could give you a lot of immediate feedback without debugging the expected user flows. Monitoring small and taken-for-granted tech details helps you preventing bigger test failures.

**Otherwise:** You mix tech-details tests with the user-oriented ones.

🔗 [**Read More: Monitoring tests**](/sections/server-communication-testing/monitoring-tests.md)

<br/><br/>

# `4. Beginners`

## 4.1 Approach the testing pyramid from the top!

**TL;DR:** Approaching the testing world could be inefficient and not satisfactory. You start writing some unit tests but you are left with a lot of doubts. UI Testing allows you to start with a high confidence since the very first day.

**Otherwise:** The wrong approach could condition the way you think about testing and could leave you with the false idea of testing the right way when the truth is you're testing nothing.

🔗 [**Read More: Approach the testing pyramid from the top!**](/sections/beginners/top-to-bottom-approach.md)

<br/><br/>

# `5. Generic testing perks`

## 5.1 Software tests as a documentation tool

**TL;DR:** Tests are a good way to have a concise, code-coupled, and updated documentation. Good storytelling test descriptions could make the comprehension of a codebase or a new project very simple.

**Otherwise:** You rely on the code documentation or, worse, on the readability of the code to comprehend that the code does.

🔗 [**Read More: Software tests as a documentation tool**](/sections/testing-perks/tests-as-documentation.md)

<br/><br/>

# `6. Tools`

## 6.1 Some UI testing problems and the Cypress way

**TL;DR:** Why is testing a web application so hard? Why generic browser automation tools do not fit well the UI/E2E testing needs? Why does Cypress outstand?

**Otherwise:** A generic features comparison is not enough to understand what are the main UI Testing pains and how Cypress removes them.

> [!NOTE]
> All the modern front-end testing tools (Playwright, Storybook, Cypress, TestCafé) all have the similar functionalities and UI tools, so this same contents applies to all of them, not just Cypress.

🔗 [**Read More: Some UI testing problems and the Cypress way**](/sections/tools/ui-testing-problems-cypress.md)



<br/><br/>

## 6.2 Visual Regression Testing

**TL;DR:** Visual regression tests hard and why we should rely on premium services.

**Otherwise:** Another continuous chore for regressions we do not care about. Possibility of missing out visual differences.

🔗 [**Read More: Visual Regression Testing**](/sections/tools/visual-regression-testing.md)

<br/><br/>



# `7. Advanced`

## 7.1 Test States

**TL;DR:** Tests should be repeatable, modular and should handle their own state setup. UI Tests should not be repeated in order to achieve state for another test.

🔗 [**Read More: Test States**](./sections/advanced/test-states.md)

<br/>

## 7.2 Test Flake

**TL;DR:** Tests must produce consistent results every time. Repeatable pipeline execution results are the quorum.
If a test cannot produce reliable results, it reduces confidence in the tests and requires maintenance which reduces all value. In these cases it is best to manually test the functionality.

🔗 [**Read More: Test Flake**](./sections/advanced/test-flake.md)

<br/>

## 7.3 Combinatorial Testing

**TL;DR:** Most software bugs and failures are caused by one or two parameters. Testing parameter combinations can provide more efficient fault detection than conventional methods. Combinatorial Testing is a proven method for more effective software testing at a lower cost.

🔗 [**Read More: Combinatorial Testing**](./sections/advanced/combinatorial-testing.md)

<br/>

## 7.4 Performance Testing

**TL;DR:** Although this is a vast topic, Performance testing from a web development perspective can be simplified with modern tools and understanding. It is highly effective in ensuring user experience, satisfying non-functional requirements (NFRS), and detecting possible system-flake early on.

🔗 [**Read More: Performance Testing**](./sections/advanced/performance-testing.md)

<br/>

## 7.5 Email Testing

**TL;DR:** Email testing is [critical for business success](https://www.industrialmarketer.com/why-email-testing-is-critical-for-email-marketing-success/). Modern services not only allow automated email testing but also provide a stateless, scalable solution while testing SaaS applications.

🔗 [**Read More: Email Testing**](./sections/advanced/email-testing.md)

<br/><br/>

# `8. Real Life Examples`

## 8.1 Siemens - Test the front-end with the integration tests, the back-end with the E2E ones - in reference to [Component vs Integration vs E2e Testing](./sections/testing-strategy/component-vs-integration-vs-e2e-testing.md)

**TL;DR:** UI tests with a stubbed server are reliable and faster compared to full E2E tests. Full E2E tests are not always necessary to ensure front-end quality. We can instead have high confidence in front-end quality by using lower-cost UI integration tests and saving higher cost E2E tests for the back-end.

**Otherwise:** You waste time and resources with slow and brittle E2E tests while you can get a lot of confidence with a lot of UI integrations tests.

🔗 [**Read More: Test the front-end with the integration tests, the back-end with the E2E ones**](./sections/real-life-examples/test-front-end-with-integration-back-end-with-e2e.md)

<br/>

## 8.2 WorkWave - From unreadable React Component Tests to simple, stupid ones

**TL;DR:** The test's code must be as straightforward as possible. The benefit is to save a lot of time to understand, update, refactor, fix it when needed. At the opposite, a terrible scenario happens when you are not able to read some tests, even if you are the author! Here are reported some examples explaining why the test's code is hard, and how they have been refactored.

**Otherwise:** You waste a lot of time reading and understanding the tests when you have to update or fix them.

🔗 [**Read More: From unreadable React Component Tests to simple, stupid ones**](./sections/real-life-examples/from-unreadable-react-component-tests-to-simple-ones.md)

<br/> <br/>

# `9. Obsolete chapters`

## Unit Testing React components with Cypress

*This section is now marked as obsolete because it refers to a very old version of Cypress (that now fully supports component tests).*

**TL;DR:** Cypress v4.5.0 release allowed Unit Testing React components, an external tool like Storybook is not necessary anymore to test isolated components.

🔗 [**Read More: Unit Testing React components with Cypress.**](/sections/tools/cypress-react-component-test.md)

<br/>

## [@daedalius](https://github.com/daedalius)'s approach: Exposing components from Storybook separating stories from tests

*This section is now marked as obsolete because it refers to a very old version of Cypress and Storybook (either of them now fully support component tests).*

**TL;DR:** You may expose the component reference from Storybook Story to test it whatever you wish in Cypress without breaking testing logic into pieces.

**Otherwise:** Splitted test logic and test data will make it difficult to read and support.

🔗 [**Read More: Cypress + Storybook. Keeping test scenario, data and component rendering in one place.**](/sections/tools/cypress-and-storybook-exposing-component-from-story.md)

## [@NoriSte](https://github.com/NoriSte)'s approach: Testing a component with Cypress and Storybook

*This section is now marked as obsolete because it refers to a very old version of Cypress and Storybook (either of them now fully support component tests).*

**TL;DR:** Components ar the building blocks of your app, testing them in isolation is important to discover, as soon as possible, iof there is something wrong with them.

**Otherwise:** UI Tests without lower-level tests do not allow you to understand the source of the problem.

🔗 [**Read More: Testing a component with Cypress and Storybook**](/sections/tools/cypress-and-storybook.md)

<br/> <br/>

## Steering Committee

Meet the steering committee members - the people who work together to provide guidance and future direction to the project.

<div>
<img align="left" width="100" height="100" src="assets/images/members/noriste.png">

Stefano Magni - [Twitter](https://twitter.com/NoriSte),
[GitHub](https://github.com/NoriSte),
[LinkedIn](https://www.linkedin.com/in/noriste/)



Passionate, positive-minded / Front-end Senior Engineer (design system) at [Preply](https://preply.com/) / Speaker / Instructor / Remote worker.

<br/>
<br/>
</div>

<div>

<img align="left" width="100" height="100" src="assets/images/members/muratkeremozcan.png">


Murat Ozcan - [Twitter](https://twitter.com/MuratKeremOzcan),
[GitHub](https://github.com/muratkeremozcan),
[LinkedIn](https://www.linkedin.com/in/murat-ozcan-3489898/), [YouTube](https://www.youtube.com/@MuratKeremOzcan), [Udemy](https://www.youtube.com/@MuratKeremOzcan)



Tech enthusiast in love with testing, development, devops, web and cloud. Staff Engineer, Test Architect at [Seon](https://seon.io/).

<br/>
<br/>

</div>


## Thank You Notes

We appreciate any contribution, from a single word fix to a new best practice. Below is a list of everyone who contributed to this project. A 🌻 marks a successful pull request and a ⭐ marks an approved new best practice.

### Stars

An approved new best practice Be the first to collect a ⭐, contribute to this repository 😁

⭐ [Murat Ozcan](https://github.com/muratkeremozcan)
⭐ [Dmitriy Tishin](https://github.com/daedalius)
⭐ [Nao](https://github.com/naodeng)

### Flowers

A successful PR gives you a 🌻, be the first to collect it.

🌻 [Anoop Kumar Gupta](https://github.com/anoop-gupt)
🌻 [Ferdinando Santacroce](https://github.com/jesuswasrasta)
🌻 [Luca Piazzoni](https://github.com/bioz87)
🌻 [Luca Previtali](https://www.linkedin.com/in/previtaliluca/)
🌻 [Luca Previtali](https://www.linkedin.com/in/previtaliluca/)
🌻 [Filip Hric](https://github.com/filiphric)
🌻 [Dorottya K.](https://github.com/DoreyKiss)

<br/><br/><br/>

This repository is inspired by the [nodebestpractices](https://github.com/i0natan/nodebestpractices) one, thank you [Yoni](https://github.com/i0natan) and the whole [steering team](https://github.com/i0natan/nodebestpractices#steering-committee) to keep it updated and to allow the creation of this repository.

<br/><br/><br/>



================================================
FILE: README.ZH.md
================================================
<!-- markdownlint-disable MD041 -->
<!-- markdownlint-disable MD033 -->
<div align="right"><strong><a href="./README.md">🇬🇧 English version</a></strong>  | <strong>🇨🇳 中文 (Chinese version)</strong></div>
<!-- markdownlint-disable MD041 -->
<!-- markdownlint-disable MD033 -->

# UI 测试最佳实践

<h1 align="center">
  <img src="assets/images/banner-2.png" alt="UI testing Best Practices">
</h1>

<br/>

<div align="center">
  <img src="https://img.shields.io/badge/⚙%20Item%20count%20-%2026%20Chapters-blue.svg" alt="26 items"> <img src="https://img.shields.io/badge/%F0%9F%93%85%20Last%20update%20-%20Jun%202025-green.svg" alt="Last update: June, 2025">
</div>

<br/>

**在 Twitter 上关注我们！**:

- [**@NoriSte**](https://twitter.com/NoriSte/)
- [**@MuratKeremOzcan**](https://twitter.com/MuratKeremOzcan/)

<br/>

###### 由我们的[指导委员会](#指导委员会)和[合作者](#collaborators)构建和维护

## 目录

1. [测试策略 (5)](#1-测试策略)
2. [通用最佳实践 (6)](#2-通用最佳实践)
3. [服务通信测试 (3)](#3-服务通信测试)
4. [初学者 (1)](#4-初学者)
5. [通用测试的好处 (1)](#5-通用测试的好处)
6. [工具 (2)](#6-工具)
7. [进阶 (5)](#7-进阶)
8. [真实案例 (2)](#8-真实案例)
9. [过时章节 (3)](#9-过时章节)

<br/><br/>

# `1-测试策略`

## 1.1 组件测试 vs 集成测试 vs E2E 测试

**简而言之：** 辨识测试类型是理解和掌握所有 UI 测试策略、工具以及它们的利弊的起点。UI 集成测试是最有效的（你会喜欢上它们的），E2E 测试提供最高的信心，而组件测试则允许你独立测试 UI 的各个单元。

**反之：** 否则，你可能会陷入过多编写 E2E 测试的困境，而忽略其他更简单的测试类型。E2E 测试是最为可靠的测试类型，但同时也是最难、最慢且最脆弱的一种。

🔗 [**阅读更多：组件测试 vs (UI) 集成测试 vs E2E 测试**](/sections/testing-strategy/component-vs-integration-vs-e2e-testing.zh.md)

<br/>

## 1.2 在开始阶段，避免追求完美主义

**简而言之：** 软件测试是一个令人惊叹的话题，但有限的经验可能使你陷入与新敌人的斗争，而不是依赖新盟友。如果可能的话，在 UI 测试旅程的初期避免测试每个复杂的用户流程。你的第一个测试越简单，你越早获得优势。

**反之：** 你将创建复杂且难以调试的测试。这种类型的测试会拖慢你的工作，而且毫无用处。

🔗 [**阅读更多：在开始阶段，避免追求完美主义**](/sections/testing-strategy/avoid-perfectionism.zh.md)

<br/>

## 1.3 选择一个参考浏览器

**简而言之：** 跨浏览器测试被高估了。虽然这是一个重要的主题，也是在开始评估合适的测试工具时首先考虑的事项，但不必过于担心。首先，要将功能测试与视觉测试分开，这是正确评估是否需要跨浏览器支持的第一步，也是选择合适的测试工具的关键。视觉测试可以集成到每个测试工具中，这得益于诸如 Applitools 和 Percy 这样的服务。

**反之：** 基于跨浏览器支持做出选择，可能导致选择错误的测试工具。

🔗 [**阅读更多：选择一个参考浏览器**](/sections/testing-strategy/choose-a-reference-browser.zh.md)

<br/>

## 1.4 发现了 bug？先编写测试，然后再着手修复

**简而言之：** 在你需要确保能够有系统性地重现某个程序漏洞时，测试是一个极佳的助手。测试可以加速修复流程，同时让你百分之百确信同样的漏洞永远都能被捕捉到。

**反之：** 如果你不能正确地辨别漏洞，那么你无法确定这个漏洞将来是否还会再次出现。

🔗 [**阅读更多：发现了 bug？先编写测试，然后再着手修复**](/sections/testing-strategy/write-test-then-fix-bug.zh.md)

<br/>

## 1.5 单个长的端到端测试还是多个小的独立测试？

**简而言之：** 在处理端到端测试及其困难时，选择进行一次长时间的测试还是选择许多小而独立的测试并非显而易见。这两种解决方案都有各自的优劣，这源于端到端测试的内在复杂性，其中涉及真实后端和真实数据。

**反之：** 你可能会创建难以维护的端到端测试。

🔗 [**阅读更多：单个长的端到端测试还是多个小的独立测试？**](/sections/testing-strategy/small-tests-or-long-ones.zh.md)

<br/><br/>

# `2-通用最佳实践`

## 2.1 等待，不要休眠

**简而言之：** 在测试用户界面时，你要定义应用程序必须经过的关键点。达到这些关键点是一个异步的过程，因为几乎百分之百的情况下，用户界面不会同步更新。这些关键点被称为**确定性事件**，即你知道必须发生的事情。你需要等待这些事件以确保你的测试更加健壮。

**反之：** 让测试休眠会使测试变得缓慢而脆弱，这是用户界面测试中最常见且最严重的错误之一。

🔗 [**阅读更多：等待，不要休眠**](/sections/generic-best-practices/await-dont-sleep.zh.md)

<br/>

## 2.2 明智地为测试文件命名

**简而言之：** 很多时候，你可能只需要运行某一类测试，如果你在为测试文件命名时遵循一种常见的模式，那将非常方便。

**反之：** 你可能需要运行一个冗长的测试套件，而实际上只是为了运行其中的一些测试。

🔗 [**阅读更多：明智地为测试文件命名**](/sections/generic-best-practices/name-test-files-wisely.zh.md)

<br/>

## 2.3 UI 测试调试最佳实践

**简而言之：** 调试 UI 测试可能非常困难，特别是当你使用通用的浏览器自动化工具时。以下是调试过程中的一些基本规则。

**反之：** 你将会花费大量时间，而无法应对 UI 测试的指数复杂性。

🔗 [**阅读更多：UI 测试调试最佳实践**](/sections/generic-best-practices/ui-tests-debugging-best-practices.zh.md)

<br/>

## 2.4 在测试中达到 UI 状态而无需使用 UI

**简而言之：** 作为一个追求质量的开发者，思考测试的成本与它们提供的价值是至关重要的。在合理的情况下，努力避免重复努力，并通过考虑为测试设置状态的替代方案，依然能够获得高价值。

🔗 [**阅读更多：达到 UI 状态**](./sections/generic-best-practices/reaching-ui-state.zh.md)

<br/>

## 2.5 将你的测试工具用作主要的开发工具

**简而言之：** 利用测试工具来避免手动测试是提高工作效率的最大改进之一。测试工具比你更快，而且大多数现代工具都包含一些 UI 工具，使得将其用作开发工具变得更加容易。

**反之：** 以传统方式编写应用程序，花费大量时间手动与 UI 进行交互。

🔗 [**阅读更多：将你的测试工具用作主要的开发工具**](/sections/generic-best-practices/use-your-testing-tool-as-your-primary-development-tool.zh.md)

<br/>

## 2.6 保持低抽象度以便于调试测试

**简而言之：** 编写测试时应考虑可读性和可调试性。在某些情况下，抽象可能是有益的，但它总是会增加调试的成本，因此有时可能不值得。这对于 UI 测试尤为重要；由于复杂的技术栈，理解故障的真实源头可能变得更加困难。为了更容易调试，降低抽象度是未来测试代码的关键。

**反之：** 抽象度和可调试性之间存在平衡；抽象度越高，将来调试测试就越困难。

🔗 [**阅读更多：保持低抽象度以便于调试测试**](/sections/generic-best-practices/test-code-with-debugging-in-mind.zh.md)

<br/><br/>

# `3-服务通信测试`

## 3.1 检验请求和响应负载

**简而言之：** UI 与后端持续通信，通常每次通信都至关重要。不良的请求或响应可能导致不一致的数据和不一致的 UI 状态。请记住，所有业务都围绕数据构建，而每次 UI 失败都会影响用户体验。因此，必须仔细检查每个 XHR 请求。XHR 请求的检查还能使测试更为健壮，正确的 XHR 管理和测试是 UI 测试中最重要的方面之一。

**反之：** 你可能会错过一些相关的通信不一致性，当你需要调试时，由于测试不会直接指引你找到问题，你将浪费大量时间。

🔗 [**阅读更多：检验请求和响应负载**](/sections/server-communication-testing/test-request-and-response-payload.zh.md)

<br/>

## 3.2 审查服务器架构

**简而言之：** 前端应用很多时候会因后端的变化而出现故障。请向后端同事请求允许你导出描述后端实体和与前端通信的每个架构的所有模式。一些示例可能包括 GraphQL 架构、TypeScript 类型、ElasticSearch 映射、Pact 合同、Postman 配置等，更一般地说，一切都可以提醒你后端发生了变化。每次后端更改都可能影响前端，你必须尽早发现。

**反之：** 你可能会错过一些后端更改，导致前端应用不经意间崩溃。

<br/>

## 3.3 测试监控

**简而言之：** 测试套件定期启动的次数越多，你对一切都按预期工作的信心就越足。UI 测试应该基于用户的视角，但有许多小测试可以为你提供大量即时反馈，而无需调试用户流程。监控那些看似微不足道的技术细节有助于预防更大的测试失败。

**反之：** 你会将技术细节测试与用户导向的测试混为一谈。

🔗 [**阅读更多：测试监控**](/sections/server-communication-testing/monitoring-tests.zh.md)

<br/><br/>

# `4-初学者`

## 4.1 从金字塔顶层入手测试

**简而言之：** 以金字塔顶层作为测试入手可能效率低下且不令人满意。你开始编写一些单元测试，但仍然存在许多疑虑。通过 UI 测试，你可以从第一天就以较高的信心开始测试。

**反之：** 错误的方法可能会影响你对测试的思考方式，使你产生错误的测试方式的错误观念，而实际上你并没有进行有效的测试。

🔗 [**阅读更多：从金字塔顶层入手测试！**](/sections/beginners/top-to-bottom-approach.zh.md)

<br/><br/>

# `5-通用测试的好处`

## 5.1 将测试视为文档工具

**简而言之：** 测试是一种简洁、与代码紧密关联且不断更新的文档方式。通过具有良好叙述的测试描述，可以使对代码库或新项目的理解变得非常简单。

**反之：** 如果不依赖于代码文档，甚至更糟糕的是依赖于代码的可读性来理解代码的作用。

🔗 [**阅读更多：将测试视为文档工具**](/sections/testing-perks/tests-as-documentation.zh.md)

<br/><br/>

# `6-工具`

## 6.1 一些 UI 测试问题及 Cypress 的解决方案

**简而言之：** 为什么测试 Web 应用这么难？通用的浏览器自动化工具为什么不太适用于 UI/E2E 测试的需求？Cypress 为什么如此出色？

**否则：** 仅仅通过通用功能比较无法理解 UI 测试的主要问题，以及 Cypress 是如何解决它们的。

> [!NOTE]
> 所有现代前端测试工具（Playwright、Storybook、Cypress、TestCafé）都具有类似的功能和 UI 工具，因此相同的内容适用于所有工具，而不仅仅是 Cypress。

🔗 [**阅读更多：一些 UI 测试问题及 Cypress 的解决方案**](/sections/tools/ui-testing-problems-cypress.zh.md)

<br/><br/>

## 6.2 视觉回归测试

**简而言之：** 视觉回归测试为什么如此困难，以及为什么我们应该依赖高级服务。

**反之：** 又是一个我们不在意的回归测试工作。有可能会漏掉视觉差异。

🔗 [**阅读更多：视觉回归测试**](/sections/tools/visual-regression-testing.zh.md)

<br/><br/>

# `7-进阶`

## 7.1 测试状态

**简而言之：** 测试应该是可重复的、模块化的，并且应该处理自身的状态设置。为了实现其他测试的状态，不应重复执行 UI 测试。

🔗 [**阅读更多：测试状态**](./sections/advanced/test-states.zh.md)

<br/>

## 7.2 不稳定的测试

**简而言之：** 每次测试应产生一致的结果。可重复的流水线执行结果是选举的基准。
如果测试无法产生可靠的结果，它会降低对测试的信心并需要维护，从而降低所有价值。在这些情况下，最好手动测试功能。

🔗 [**阅读更多：不稳定的测试**](./sections/advanced/test-flake.zh.md)

<br/>

## 7.3 组合测试

**简而言之：** 大多数软件错误和故障是由一个或两个参数引起的。测试参数组合可以比传统方法更有效地检测故障。组合测试是一种经过验证的、成本更低的更有效的软件测试方法。

🔗 [**阅读更多：组合测试**](./sections/advanced/combinatorial-testing.zh.md)

<br/>

## 7.4 性能测试

**简而言之：** 尽管这是一个庞大的主题，但从 Web 开发的角度来看，性能测试可以通过现代工具和理解来简化。它在确保用户体验、满足非功能性需求（NFRS）以及及早检测可能的系统故障方面非常有效。

🔗 [**阅读更多：性能测试**](./sections/advanced/performance-testing.zh.md)

<br/>

## 7.5 电子邮件测试

**简而言之：** 电子邮件测试对于业务成功至关重要。现代服务不仅允许自动化的电子邮件测试，而且在测试 SaaS 应用程序时还提供了一种无状态、可扩展的解决方案。

🔗 [**阅读更多：电子邮件测试**](./sections/advanced/email-testing.zh.md)

---

<br/><br/>

# `8-真实案例`

## 8.1 Siemens - 用集成测试测试前端，用 E2E 测试测试后端 - 参考 [组件测试 vs（UI）集成测试 vs E2E 测试](./sections/testing-strategy/component-vs-integration-vs-e2e-testing.zh.md)

**简而言之：** 使用带有存根服务器的 UI 测试相比完整的 E2E 测试更为可靠且更快。并非总是需要完整的 E2E 测试来确保前端质量。我们可以通过使用成本较低的 UI 集成测试对前端质量具有高度信心，并将成本较高的 E2E 测试保留给后端。

**反之：** 在进行缓慢且脆弱的 E2E 测试时浪费时间和资源，而通过进行大量的 UI 集成测试可以获得高度的信心。

🔗 [**阅读更多：用集成测试测试前端，用 E2E 测试测试后端**](./sections/real-life-examples/test-front-end-with-integration-back-end-with-e2e.zh.md)

<br/>

## 8.2 WorkWave - 从难以理解的 React 组件测试到简单愚蠢的测试

**简而言之：** 测试代码必须尽可能简单明了。这样可以在需要时节省大量的理解、更新、重构和修复时间。相反，如果甚至作者自己也无法阅读某些测试，那就会发生可怕的情况！这里提供了一些解释测试代码难以理解的例子，并展示了它们的重构过程。

**反之：** 当您必须更新或修复测试时，花费大量时间阅读和理解测试。

🔗 [**阅读更多：从难以理解的 React 组件测试到简单愚蠢的测试**](./sections/real-life-examples/from-unreadable-react-component-tests-to-simple-ones.zh.md)

<br/> <br/>

# `9-过时章节`

## 使用 Cypress 进行 React 组件的单元测试

*此部分现已标记为过时，因为它涉及到一个非常旧的 Cypress 版本（现在已完全支持组件测试）。

**简而言之：** Cypress v4.5.0 发布允许对 React 组件进行单元测试，不再需要类似 Storybook 的外部工具来测试孤立的组件。

🔗 [**阅读更多：使用 Cypress 进行 React 组件的单元测试**](/sections/tools/cypress-react-component-test.zh.md)

<br/>

## [@daedalius](https://github.com/daedalius) 的方法：从 Storybook 中公开组件，将故事与测试分离

*此部分现已标记为过时，因为它涉及到一个非常旧的 Cypress 和 Storybook 版本（现在它们都完全支持组件测试）。

**简而言之：** 你可以从 Storybook 故事中公开组件引用，以在 Cypress 中测试任何你希望测试的内容，而不会将测试逻辑分解成多个部分。

**反之：** 将测试逻辑和测试数据拆分开会使其难以阅读和维护。

🔗 [**阅读更多：Cypress + Storybook。保持测试场景、数据和组件渲染在一个地方。**](/sections/tools/cypress-and-storybook-exposing-component-from-story.zh.md)

## [@NoriSte](https://github.com/NoriSte) 的方法：使用 Cypress 和 Storybook 进行组件测试

*此部分现已标记为过时，因为它涉及到一个非常旧的 Cypress 和 Storybook 版本（现在它们都完全支持组件测试）。

**简而言之：** 组件是你的应用程序的构建块，在孤立状态下测试它们对于尽早发现问题非常重要。

**反之：** 没有底层测试的 UI 测试无法让你了解问题的根源。

🔗 [**阅读更多：使用 Cypress 和 Storybook 进行组件测试**](/sections/tools/cypress-and-storybook.zh.md)

<br/> <br/>

## 指导委员会

了解指导委员会成员 - 一起为项目提供指导和未来方向的人们。

<div>
<img align="left" width="100" height="100" src="assets/images/members/noriste.png">

[Stefano Magni](https://github.com/NoriSte)
<a href="https://twitter.com/NoriSte"><img src="assets/images/twitter-s.png" width="16" height="16"></img></a>
<a href="https://github.com/NoriSte"><picture><source media="(prefers-color-scheme: dark)" srcset="assets/images/github-dark.png"><img alt="GitHub" src="assets/images/github-light.png" width="16" height="16"></picture>
<a href="https://www.linkedin.com/in/noriste/"><img src="assets/images/linkedin.png" width="16" height="16"></img></a>

</img></a>

充满激情，积极乐观 / 前端技术领导者（平台）[Hasura](https://hasura.io/) / 演讲者 / 讲师 / 远程工作者。

<br/>
<br/>
</div>

<div>

<img align="left" width="100" height="100" src="assets/images/members/muratkeremozcan.png">

[Murat Ozcan](https://github.com/NoriSte)
<a href="https://twitter.com/MuratKeremOzcan"><img src="assets/images/twitter-s.png" width="16" height="16"></img></a>
<a href="https://github.com/muratkeremozcan"><picture><source media="(prefers-color-scheme: dark)" srcset="assets/images/github-dark.png"><img alt="GitHub" src="assets/images/github-light.png" width="16" height="16"></picture>
<a href="https://www.linkedin.com/in/murat-ozcan-3489898/"><img src="assets/images/linkedin.png" width="16" height="16"></img></a>

</img></a>

热衷于技术，热爱测试、开发、DevOps、Web 和云。[Extend](https://www.extend.com/) 的技术专家 / 测试架构师。

<br/>
<br/>

</div>

## 感谢信

我们感激任何贡献，无论是单个词汇的修复还是新的最佳实践。下面是为这个项目做出贡献的所有人的列表。🌻标记着成功的拉取请求，⭐标记着被批准的新最佳实践。

### Stars

一个被批准的新最佳实践，成为第一个收到⭐的人，为这个仓库做出贡献 😁

⭐ [Murat Ozcan](https://github.com/muratkeremozcan)
⭐ [Dmitriy Tishin](https://github.com/daedalius)

### 鲜花

一个成功的 PR 会给你一朵 🌻，成为第一个收到它的人。

🌻 [Anoop Kumar Gupta](https://github.com/anoop-gupt)
🌻 [Ferdinando Santacroce](https://github.com/jesuswasrasta)
🌻 [Luca Piazzoni](https://github.com/bioz87)
🌻 [Luca Previtali](https://www.linkedin.com/in/previtaliluca/)
🌻 [Luca Previtali](https://www.linkedin.com/in/previtaliluca/)
🌻 [Filip Hric](https://github.com/filiphric)

<br/><br/><br/>

这个仓库受到了 [nodebestpractices](https://github.com/i0natan/nodebestpractices) 仓库的启发，感谢 [Yoni](https://github.com/i0natan) 和整个 [指导委员会](https://github.com/i0natan/nodebestpractices#steering-committee) 的努力，保持其更新并允许创建这个仓库。

<br/><br/><br/>



================================================
FILE: LICENSE
================================================
## creative commons

# Attribution-ShareAlike 4.0 International

Creative Commons Corporation (“Creative Commons”) is not a law firm and does not provide legal services or legal advice. Distribution of Creative Commons public licenses does not create a lawyer-client or other relationship. Creative Commons makes its licenses and related information available on an “as-is” basis. Creative Commons gives no warranties regarding its licenses, any material licensed under their terms and conditions, or any related information. Creative Commons disclaims all liability for damages resulting from their use to the fullest extent possible.

### Using Creative Commons Public Licenses

Creative Commons public licenses provide a standard set of terms and conditions that creators and other rights holders may use to share original works of authorship and other material subject to copyright and certain other rights specified in the public license below. The following considerations are for informational purposes only, are not exhaustive, and do not form part of our licenses.

* __Considerations for licensors:__ Our public licenses are intended for use by those authorized to give the public permission to use material in ways otherwise restricted by copyright and certain other rights. Our licenses are irrevocable. Licensors should read and understand the terms and conditions of the license they choose before applying it. Licensors should also secure all rights necessary before applying our licenses so that the public can reuse the material as expected. Licensors should clearly mark any material not subject to the license. This includes other CC-licensed material, or material used under an exception or limitation to copyright. [More considerations for licensors](http://wiki.creativecommons.org/Considerations_for_licensors_and_licensees#Considerations_for_licensors).

* __Considerations for the public:__ By using one of our public licenses, a licensor grants the public permission to use the licensed material under specified terms and conditions. If the licensor’s permission is not necessary for any reason–for example, because of any applicable exception or limitation to copyright–then that use is not regulated by the license. Our licenses grant only permissions under copyright and certain other rights that a licensor has authority to grant. Use of the licensed material may still be restricted for other reasons, including because others have copyright or other rights in the material. A licensor may make special requests, such as asking that all changes be marked or described. Although not required by our licenses, you are encouraged to respect those requests where reasonable. [More considerations for the public](http://wiki.creativecommons.org/Considerations_for_licensors_and_licensees#Considerations_for_licensees).

## Creative Commons Attribution-ShareAlike 4.0 International Public License

By exercising the Licensed Rights (defined below), You accept and agree to be bound by the terms and conditions of this Creative Commons Attribution-ShareAlike 4.0 International Public License ("Public License"). To the extent this Public License may be interpreted as a contract, You are granted the Licensed Rights in consideration of Your acceptance of these terms and conditions, and the Licensor grants You such rights in consideration of benefits the Licensor receives from making the Licensed Material available under these terms and conditions.

### Section 1 – Definitions.

a. __Adapted Material__ means material subject to Copyright and Similar Rights that is derived from or based upon the Licensed Material and in which the Licensed Material is translated, altered, arranged, transformed, or otherwise modified in a manner requiring permission under the Copyright and Similar Rights held by the Licensor. For purposes of this Public License, where the Licensed Material is a musical work, performance, or sound recording, Adapted Material is always produced where the Licensed Material is synched in timed relation with a moving image.

b. __Adapter's License__ means the license You apply to Your Copyright and Similar Rights in Your contributions to Adapted Material in accordance with the terms and conditions of this Public License.

c. __BY-SA Compatible License__ means a license listed at [creativecommons.org/compatiblelicenses](http://creativecommons.org/compatiblelicenses), approved by Creative Commons as essentially the equivalent of this Public License.

d. __Copyright and Similar Rights__ means copyright and/or similar rights closely related to copyright including, without limitation, performance, broadcast, sound recording, and Sui Generis Database Rights, without regard to how the rights are labeled or categorized. For purposes of this Public License, the rights specified in Section 2(b)(1)-(2) are not Copyright and Similar Rights.

e. __Effective Technological Measures__ means those measures that, in the absence of proper authority, may not be circumvented under laws fulfilling obligations under Article 11 of the WIPO Copyright Treaty adopted on December 20, 1996, and/or similar international agreements.

f. __Exceptions and Limitations__ means fair use, fair dealing, and/or any other exception or limitation to Copyright and Similar Rights that applies to Your use of the Licensed Material.

g. __License Elements__ means the license attributes listed in the name of a Creative Commons Public License. The License Elements of this Public License are Attribution and ShareAlike.

h. __Licensed Material__ means the artistic or literary work, database, or other material to which the Licensor applied this Public License.

i. __Licensed Rights__ means the rights granted to You subject to the terms and conditions of this Public License, which are limited to all Copyright and Similar Rights that apply to Your use of the Licensed Material and that the Licensor has authority to license.

j. __Licensor__ means the individual(s) or entity(ies) granting rights under this Public License.

k. __Share__ means to provide material to the public by any means or process that requires permission under the Licensed Rights, such as reproduction, public display, public performance, distribution, dissemination, communication, or importation, and to make material available to the public including in ways that members of the public may access the material from a place and at a time individually chosen by them.

l. __Sui Generis Database Rights__ means rights other than copyright resulting from Directive 96/9/EC of the European Parliament and of the Council of 11 March 1996 on the legal protection of databases, as amended and/or succeeded, as well as other essentially equivalent rights anywhere in the world.

m. __You__ means the individual or entity exercising the Licensed Rights under this Public License. Your has a corresponding meaning.

### Section 2 – Scope.

a. ___License grant.___

   1. Subject to the terms and conditions of this Public License, the Licensor hereby grants You a worldwide, royalty-free, non-sublicensable, non-exclusive, irrevocable license to exercise the Licensed Rights in the Licensed Material to:

       A. reproduce and Share the Licensed Material, in whole or in part; and

       B. produce, reproduce, and Share Adapted Material.

   2. __Exceptions and Limitations.__ For the avoidance of doubt, where Exceptions and Limitations apply to Your use, this Public License does not apply, and You do not need to comply with its terms and conditions.

   3. __Term.__ The term of this Public License is specified in Section 6(a).

   4. __Media and formats; technical modifications allowed.__ The Licensor authorizes You to exercise the Licensed Rights in all media and formats whether now known or hereafter created, and to make technical modifications necessary to do so. The Licensor waives and/or agrees not to assert any right or authority to forbid You from making technical modifications necessary to exercise the Licensed Rights, including technical modifications necessary to circumvent Effective Technological Measures. For purposes of this Public License, simply making modifications authorized by this Section 2(a)(4) never produces Adapted Material.

   5. __Downstream recipients.__

       A. __Offer from the Licensor – Licensed Material.__ Every recipient of the Licensed Material automatically receives an offer from the Licensor to exercise the Licensed Rights under the terms and conditions of this Public License.

       B. __Additional offer from the Licensor – Adapted Material. Every recipient of Adapted Material from You automatically receives an offer from the Licensor to exercise the Licensed Rights in the Adapted Material under the conditions of the Adapter’s License You apply.

       C. __No downstream restrictions.__ You may not offer or impose any additional or different terms or conditions on, or apply any Effective Technological Measures to, the Licensed Material if doing so restricts exercise of the Licensed Rights by any recipient of the Licensed Material.

   6. __No endorsement.__ Nothing in this Public License constitutes or may be construed as permission to assert or imply that You are, or that Your use of the Licensed Material is, connected with, or sponsored, endorsed, or granted official status by, the Licensor or others designated to receive attribution as provided in Section 3(a)(1)(A)(i).

b. ___Other rights.___

   1. Moral rights, such as the right of integrity, are not licensed under this Public License, nor are publicity, privacy, and/or other similar personality rights; however, to the extent possible, the Licensor waives and/or agrees not to assert any such rights held by the Licensor to the limited extent necessary to allow You to exercise the Licensed Rights, but not otherwise.

   2. Patent and trademark rights are not licensed under this Public License.

   3. To the extent possible, the Licensor waives any right to collect royalties from You for the exercise of the Licensed Rights, whether directly or through a collecting society under any voluntary or waivable statutory or compulsory licensing scheme. In all other cases the Licensor expressly reserves any right to collect such royalties.

### Section 3 – License Conditions.

Your exercise of the Licensed Rights is expressly made subject to the following conditions.

a. ___Attribution.___

   1. If You Share the Licensed Material (including in modified form), You must:

       A. retain the following if it is supplied by the Licensor with the Licensed Material:

         i. identification of the creator(s) of the Licensed Material and any others designated to receive attribution, in any reasonable manner requested by the Licensor (including by pseudonym if designated);

         ii. a copyright notice;

         iii. a notice that refers to this Public License;

         iv. a notice that refers to the disclaimer of warranties;

         v. a URI or hyperlink to the Licensed Material to the extent reasonably practicable;

       B. indicate if You modified the Licensed Material and retain an indication of any previous modifications; and

       C. indicate the Licensed Material is licensed under this Public License, and include the text of, or the URI or hyperlink to, this Public License.

   2. You may satisfy the conditions in Section 3(a)(1) in any reasonable manner based on the medium, means, and context in which You Share the Licensed Material. For example, it may be reasonable to satisfy the conditions by providing a URI or hyperlink to a resource that includes the required information.

   3. If requested by the Licensor, You must remove any of the information required by Section 3(a)(1)(A) to the extent reasonably practicable.

b. ___ShareAlike.___

In addition to the conditions in Section 3(a), if You Share Adapted Material You produce, the following conditions also apply.

1. The Adapter’s License You apply must be a Creative Commons license with the same License Elements, this version or later, or a BY-SA Compatible License.

2. You must include the text of, or the URI or hyperlink to, the Adapter's License You apply. You may satisfy this condition in any reasonable manner based on the medium, means, and context in which You Share Adapted Material.

3. You may not offer or impose any additional or different terms or conditions on, or apply any Effective Technological Measures to, Adapted Material that restrict exercise of the rights granted under the Adapter's License You apply.

### Section 4 – Sui Generis Database Rights.

Where the Licensed Rights include Sui Generis Database Rights that apply to Your use of the Licensed Material:

a. for the avoidance of doubt, Section 2(a)(1) grants You the right to extract, reuse, reproduce, and Share all or a substantial portion of the contents of the database;

b. if You include all or a substantial portion of the database contents in a database in which You have Sui Generis Database Rights, then the database in which You have Sui Generis Database Rights (but not its individual contents) is Adapted Material, including for purposes of Section 3(b); and

c. You must comply with the conditions in Section 3(a) if You Share all or a substantial portion of the contents of the database.

For the avoidance of doubt, this Section 4 supplements and does not replace Your obligations under this Public License where the Licensed Rights include other Copyright and Similar Rights.

### Section 5 – Disclaimer of Warranties and Limitation of Liability.

a. __Unless otherwise separately undertaken by the Licensor, to the extent possible, the Licensor offers the Licensed Material as-is and as-available, and makes no representations or warranties of any kind concerning the Licensed Material, whether express, implied, statutory, or other. This includes, without limitation, warranties of title, merchantability, fitness for a particular purpose, non-infringement, absence of latent or other defects, accuracy, or the presence or absence of errors, whether or not known or discoverable. Where disclaimers of warranties are not allowed in full or in part, this disclaimer may not apply to You.__

b. __To the extent possible, in no event will the Licensor be liable to You on any legal theory (including, without limitation, negligence) or otherwise for any direct, special, indirect, incidental, consequential, punitive, exemplary, or other losses, costs, expenses, or damages arising out of this Public License or use of the Licensed Material, even if the Licensor has been advised of the possibility of such losses, costs, expenses, or damages. Where a limitation of liability is not allowed in full or in part, this limitation may not apply to You.__

c. The disclaimer of warranties and limitation of liability provided above shall be interpreted in a manner that, to the extent possible, most closely approximates an absolute disclaimer and waiver of all liability.

### Section 6 – Term and Termination.

a. This Public License applies for the term of the Copyright and Similar Rights licensed here. However, if You fail to comply with this Public License, then Your rights under this Public License terminate automatically.

b. Where Your right to use the Licensed Material has terminated under Section 6(a), it reinstates:

   1. automatically as of the date the violation is cured, provided it is cured within 30 days of Your discovery of the violation; or

   2. upon express reinstatement by the Licensor.

   For the avoidance of doubt, this Section 6(b) does not affect any right the Licensor may have to seek remedies for Your violations of this Public License.

c. For the avoidance of doubt, the Licensor may also offer the Licensed Material under separate terms or conditions or stop distributing the Licensed Material at any time; however, doing so will not terminate this Public License.

d. Sections 1, 5, 6, 7, and 8 survive termination of this Public License.

### Section 7 – Other Terms and Conditions.

a. The Licensor shall not be bound by any additional or different terms or conditions communicated by You unless expressly agreed.

b. Any arrangements, understandings, or agreements regarding the Licensed Material not stated herein are separate from and independent of the terms and conditions of this Public License.t stated herein are separate from and independent of the terms and conditions of this Public License.

### Section 8 – Interpretation.

a. For the avoidance of doubt, this Public License does not, and shall not be interpreted to, reduce, limit, restrict, or impose conditions on any use of the Licensed Material that could lawfully be made without permission under this Public License.

b. To the extent possible, if any provision of this Public License is deemed unenforceable, it shall be automatically reformed to the minimum extent necessary to make it enforceable. If the provision cannot be reformed, it shall be severed from this Public License without affecting the enforceability of the remaining terms and conditions.

c. No term or condition of this Public License will be waived and no failure to comply consented to unless expressly agreed to by the Licensor.

d. Nothing in this Public License constitutes or may be interpreted as a limitation upon, or waiver of, any privileges and immunities that apply to the Licensor or You, including from the legal processes of any jurisdiction or authority.

> Creative Commons is not a party to its public licenses. Notwithstanding, Creative Commons may elect to apply one of its public licenses to material it publishes and in those instances will be considered the “Licensor.” Except for the limited purpose of indicating that material is shared under a Creative Commons public license or as otherwise permitted by the Creative Commons policies published at [creativecommons.org/policies](http://creativecommons.org/policies), Creative Commons does not authorize the use of the trademark “Creative Commons” or any other trademark or logo of Creative Commons without its prior written consent including, without limitation, in connection with any unauthorized modifications to any of its public licenses or any other arrangements, understandings, or agreements concerning use of licensed material. For the avoidance of doubt, this paragraph does not form part of the public licenses.
>
> Creative Commons may be contacted at creativecommons.org



================================================
FILE: assets/images/viconblue.PNG
================================================
[Binary file]


================================================
FILE: assets/images/perf-testing/insights.PNG
================================================
[Binary file]


================================================
FILE: assets/images/ui-state/devtools-network.PNG
================================================
[Binary file]


================================================
FILE: sections/draft.md
================================================
The _Topics list_ could be summarized in the next chapters

- typescrtipt in tests: pros and cons
- importance of assertions speakingness and having a lot of assertions in UI tests
- exporting constants from the code and import in the tests
- base tests on contents
- visual regression test
- add more component testing articles (@makbeth has TestCafé+Storybook tests, re-try cypress-react-unit-test running `npm run component` on [this repo](https://github.com/cypress-io/cypress-example-todomvc-redux)) and improve the whole section. Update "Component tests vs (UI) Integration tests vs E2E tests" speaking about E2E tools + Storybook



================================================
FILE: sections/template.md
================================================
# Title here

<br/><br/>

### One Paragraph Explainer

Text

<br/><br/>

### Code Example – explanation

```javascript
code here
```

<br/><br/>

### Code Example – another

```javascript
code here
```

<br/><br/>

### Blog Quote: "Title"

 From the blog, pouchdb.com ranked 11 for the keywords “Node Promises”

 > …text here

<br/><br/>

 ### Example: Complex methods analysis with CodeClimate (commercial)

![alt text](https://github.com/i0natan/nodebestpractices/blob/master/assets/images/codeanalysis-climate-complex-methods.PNG "Complex methods analysis")

### Example: Code analysis trends and history with CodeClimate (commercial)

![alt text](https://github.com/i0natan/nodebestpractices/blob/master/assets/images/codeanalysis-climate-history.PNG "Code analysis history")

### Example: Code analysis summary and trends with SonarQube (commercial)

![alt text](https://github.com/i0natan/nodebestpractices/blob/master/assets/images/codeanalysis-sonarqube-dashboard.PNG "Code analysis history")


<br/><br/>



================================================
FILE: sections/advanced/combinatorial-testing.md
================================================
# Combinatorial Testing

<br/><br/>

### One Paragraph Explainer

* [Combinatorial Testing](http://csrc.nist.gov/Projects/automated-combinatorial-testing-for-software) is a proven method for more effective software testing at a lower cost.
* The key insight underlying this form of testing is that not every parameter contributes to every failure and most failures are caused by interactions between relatively few parameters.
* Testing parameter combinations can provide more efficient fault detection than conventional methods.


A series of studies by [NIST](https://www.nist.gov/) from 1999 to 2004 showed that most software bugs and failures are caused by one or two parameters, with
progressively fewer by three or more. This finding, referred to as the Interaction Rule, has important implications for software testing because it means that testing parameter combinations can provide more efficient fault detection than conventional methods. The data gathered by NIST and others suggest that software failures are triggered by only a few variables interacting (six or fewer). Pairwise (2-way combinations) testing is sometimes used to obtain reasonably good results at low cost, generally not less than 60% fault coverage, but this may not be sufficient for mission-critical software.

<br/><br/>

### (1) Code Example – product owner question

A product owner once asked:
> "From a best practice standpoint or maybe a practical standpoint, are you supposed to test a system in every possible configuration?
For example, say you have features A, B, C, D, E and customer 1 has features A/B, customer 2 has A/B/C, and customer 3 has A/D, customer 4 has B/D, and customer 5 has A/B/C/D/E....
Are you supposed to test every possible combination of features or do you test each of the individual features and if they work independently you trust them to work as a whole?"


5 customers and 5 features. This would be 25 tests exhaustively.
With the constraints described, it would be 14 tests.
For the purpose of having a code sample, we will use a [CTWedge](https://foselab.unibg.it/ctwedge/) scripted combinatorial model of the described spec. There are many other CT tools listed at [pairwise.org](http://pairwise.org/). Some of the other tools we (at Siemens) have used are [ACTs](https://csrc.nist.gov/projects/automated-combinatorial-testing-for-software) and [CAgen](https://matris.sba-research.org/tools/cagen/#/workspaces).

```
Model POquestion
 Parameters:
   features : {A, B, C, D, E}
   customer:  {1, 2, 3, 4, 5}

 Constraints:
   # customer = 1 => features = A || features = B #
   # customer = 2 => features = A || features = B || features = C #
   # customer = 3 => features = A || features = D #
   # customer = 4 => features = B || features = D #
   # customer = 5 => features = A || features = B || features = C || features = D || features = E #
```

Paste the script in here to generate results [here](http://foselab.unibg.it/ctwedge/).

The goal is to test 2-way (or more) interactions between parameters. When you have only 2 parameters, there is not much profit, because it is exhaustive.

If you have more than 2 parameters, 2-way interaction coverage between them will guarantee to find 60-99% of all possible defects that can arise from that area. 3-way 90%, 4-way 95% , 5-way 97%, 6-way guarantees 100%.

![Combinatorial testing graph](../../assets/images/combinatorial-testing/ct-graph.PNG)

In this example you would profit from adding another *parameter*. Let us name it `configuration` and assume 5 possible configurations / *parameter values*. This would make the exhaustive suite of 125 tests.

```
Model POquestion
 Parameters:
   features : {A, B, C, D, E}
   customer:  {1, 2, 3, 4, 5}
   configuration: {config1, config2, config3, config4, config5}

 Constraints:
   # customer = 1 => features = A || features = B #
   # customer = 2 => features = A || features = B || features = C #
   # customer = 3 => features = A || features = D #
   # customer = 4 => features = B || features = D #
   # customer = 5 => features = A || features = B || features = C || features = D || features = E #
```

Pasting to [CTWedge](https://foselab.unibg.it/ctwedge/) this gives a test suite with 31 tests. If you add some constraints, saying some feature is not supposed to work with some config, you can even lean it further.

Mind that modeling Combinatorial Testing can and does incorporate equivalence partitions, boundary value analysis and other techniques. The more accurate the model is, the higher fault-detecting capabilities the test suite will have.


<br/><br/>

### (2) Code Example – NASA Switchboard with 34 switches

Consider an example of 34 switches at NASA, each switch can be on or off.
There are 17 billion ways to cover the entirety of exhaustive tests.

![](../../assets/images/combinatorial-testing/nasa-switches.PNG)

You do not need to test all 2^34. Modeling with Combinatorial Testing you can make a calculated decision, depending on risk

```
Model NASAswitches

Parameters:
    switch1: Boolean
    switch2: Boolean
    switch3: Boolean
    switch4: Boolean
    switch5: Boolean
    switch6: Boolean
    switch7: Boolean
    switch8: Boolean
    switch9: Boolean
    switch10: Boolean
    switch11: Boolean
    switch12: Boolean
    switch13: Boolean
    switch14: Boolean
    switch15: Boolean
    switch16: Boolean
    switch17: Boolean
    switch18: Boolean
    switch19: Boolean
    switch20: Boolean
    switch21: Boolean
    switch22: Boolean
    switch23: Boolean
    switch24: Boolean
    switch25: Boolean
    switch26: Boolean
    switch27: Boolean
    switch28: Boolean
    switch29: Boolean
    switch30: Boolean
    switch31: Boolean
    switch32: Boolean
    switch33: Boolean
    switch34: Boolean
```
Switch the number of interactions to test using the dropdown in [CTWedge](https://foselab.unibg.it/ctwedge/).
* 14tests : failures from 2-way interactions between switches - will find 60-99% of all possible failures depending on product
* 33tests : failures from 3-way interactions between switches - will find 90-99% of all possible failures depending on product
* 85 tests : failures from 4-way interactions between switches - will find 95-99% of all possible failures depending on product
* 220 tests: failures from 5-way interactions between switches - will find above 99% of all possible failures
* 538 tests: failures from 6-way interactions between switches - will find 100% of all possible failures

<br/><br/>

### (2) Code Example - [Siemens Building Operator CI configuration](https://cypress.slides.com/cypress-io/siemens-case-study#/16)

Refer to the slides link above or the [webcast](https://www.youtube.com/watch?v=aMPkaLOpyns&t=1624s) for a detailed explanation on how to measure combinatorial coverage with [CAMetrics](https://matris.sba-research.org/tools/cametrics/#/new). Essentially, you generate a CSV file with any Combinatorial Testing tool and drag&drop it to CAMetrics. After that, CAMetrics can give you various combinatorial coverage reports.

> Mind that it is trivial to [convert csv to JSON](https://www.csvjson.com/csv2json), then use the JSON file for data-driven testing in any test framework of choice.

```
Model CI
 Parameters:
   deployment_UI : { branch, development, staging }
   deployment_API:  { development, staging }
   spec_suite: { ui_services_stubbed, ui_services, ui_services_hardware, spot_check}
   browser: { chrome, electron, firefox }

 Constraints:
   // one extra constraint for firefox spot checks
   # browser=firefox <=> spec_suite=spot_check #
   // on staging, run all tests
   # spec_suite=ui_services_hardware <=> deployment_API=staging #
   // match dev vs dev, staging vs staging, and when on staging use Chrome
   # deployment_UI=development => deployment_API=development #
   # deployment_UI=staging => deployment_API=staging #
   # deployment_UI=staging && deployment_API=staging => browser=chrome #
   // when on branch, stub the services
   # deployment_UI=branch => spec_suite=ui_services_stubbed #
   // do not stub the services when on UI development
   # deployment_UI=development => spec_suite!=ui_services_stubbed #
```

## References & Further reading

[Automated Combinatorial Testing for Software](https://csrc.nist.gov/Projects/automated-combinatorial-testing-for-software)

[Slides 16-50 : Utilization of Automation and Combinatorial Disciplines In Aid of Exploratory Testing](https://prezi.com/tpffqit1yn87/utilization-of-automation-and-combinatorial-disciplines-in-aid-of-exploratory-testing/)

[Applications of Practical Combinatorial Testing Methods at Siemens Industry Inc., Building Technologies Division](https://ieeexplore.ieee.org/document/7899057?section=abstract)

[An Industrial Study on Applications of Combinatorial Testing in Modern Web Development](https://ieeexplore.ieee.org/document/8728910)

[Introducing Combinatorial Testing In a Large Organization](https://ieeexplore.ieee.org/document/7085645/)

[Input Parameter Modeling for Combination Strategies](http://barbie.uta.edu/~mehra/1%20INPUT%20PARAMETER%20MODELING%20FOR%20COMBINATION%20STRATEGIES.pdf)

[Common Patterns in Combinatorial Models](http://barbie.uta.edu/~mehra/62_Common%20Patterns%20in%20Combinatorial%20Models.pdf)

[Efficient Verification of Equivalence Classes and Simultaneous Testing Using Two-layer Covering Arrays](https://tsapps.nist.gov/publication/get_pdf.cfm?pub_id=917899)



================================================
FILE: sections/advanced/combinatorial-testing.zh.md
================================================
# 组合测试

<br/><br/>

## 一段简要说明

* [组合测试](http://csrc.nist.gov/Projects/automated-combinatorial-testing-for-software) 是一种经过验证的、成本较低的、更为有效的软件测试方法。
* 这种测试的关键思想是，并非每个参数都对每次故障都有影响，而是大多数故障是由相对较少的参数之间的相互作用引起的。
* 与传统方法相比，测试参数组合可以更有效地检测故障。

美国国家标准与技术研究院[NIST](https://www.nist.gov/) 在 1999 年到 2004 年进行的一系列研究表明，大多数软件缺陷和故障是由一个或两个参数引起的，逐渐减少到由三个或更多参数引起的。这一发现被称为“交互规则”，对软件测试具有重要意义，因为这意味着测试参数组合可以比传统方法更有效地检测故障。NIST 和其他机构收集的数据表明，软件故障仅由少数几个变量的相互作用引发（不超过六个）。有时使用成对（2 路组合）测试可以以较低的成本获得相当不错的结果，通常不低于 60% 的故障覆盖率，但这可能对于关键任务的软件来说可能不足够。

<br/><br/>

## (1) 代码示例 – 产品负责人问题

一位产品负责人曾提出一个问题：
> "从最佳实践或实际角度来看，你是否应该在每种可能的配置下测试系统？
例如，假设你有 A、B、C、D、E 五个功能，客户 1 拥有 A/B，客户 2 拥有 A/B/C，客户 3 拥有 A/D，客户 4 拥有 B/D，客户 5 拥有 A/B/C/D/E....
你是否应该测试每种可能的功能组合，还是测试每个功能单独，如果它们在独立测试中能够正常工作，就相信它们整体上也能正常工作？"

5 个客户和 5 个功能，详尽无遗将需要 25 个测试。
在描述的约束条件下，只需要 14 个测试。
为了提供一个代码示例，我们将使用描述规格的[CTWedge](https://foselab.unibg.it/ctwedge/)脚本化组合模型。还有许多其他列在[pairwise.org](http://pairwise.org/)上的 CT 工具。我们（在西门子）使用过的其他一些工具包括[ACTs](https://csrc.nist.gov/projects/automated-combinatorial-testing-for-software)和[CAgen](https://matris.sba-research.org/tools/cagen/#/workspaces)。

```
Model POquestion
 Parameters:
   features : {A, B, C, D, E}
   customer:  {1, 2, 3, 4, 5}

 Constraints:
   # customer = 1 => features = A || features = B #
   # customer = 2 => features = A || features = B || features = C #
   # customer = 3 => features = A || features = D #
   # customer = 4 => features = B || features = D #
   # customer = 5 => features = A || features = B || features = C || features = D || features = E #
```

在这里粘贴脚本以生成结果 [这里](http://foselab.unibg.it/ctwedge/)。

测试的目标是检验参数之间的双向（或更多）相互作用。当只有两个参数时，收益并不太明显，因为这是一种穷举的方法。

如果参数数量超过两个，对它们之间的双向交互进行覆盖将确保找到该领域可能存在的 60-99% 的所有潜在缺陷。三向交互为 90%，四向为 95%，五向为 97%，六向为 100%。

![组合测试图](../../assets/images/combinatorial-testing/ct-graph.PNG)

在这个例子中，通过添加另一个*参数*，我们称之为 `configuration`，并假设有 5 种可能的配置 / *参数值*。这将生成一个包含 125 个测试的详尽套件。

```Text
Model POquestion
 Parameters:
   features : {A, B, C, D, E}
   customer:  {1, 2, 3, 4, 5}
   configuration: {config1, config2, config3, config4, config5}

 Constraints:
   # customer = 1 => features = A || features = B #
   # customer = 2 => features = A || features = B || features = C #
   # customer = 3 => features = A || features = D #
   # customer = 4 => features = B || features = D #
   # customer = 5 => features = A || features = B || features = C || features = D || features = E #
```

将其粘贴到 [CTWedge](https://foselab.unibg.it/ctwedge/) 上，这将生成一个包含 31 个测试的测试套件。如果添加一些约束，表明某些特性不应该与某些配置一起工作，甚至可以进一步精简。

请注意，组合测试的建模可以并且确实包含等价分区、边界值分析和其他技术。模型越准确，测试套件的故障检测能力就越强。

<br/><br/>

## (2) 代码示例 – NASA 的开关板共有 34 个开关

以 NASA 的一个例子为参考，有 34 个开关，每个开关可以处于打开或关闭的状态。要进行详尽的测试，有 170 亿种可能的组合方式。

![ ](../../assets/images/combinatorial-testing/nasa-switches.PNG)

不必测试所有的 2^34 种可能性。通过使用组合测试进行建模，你可以根据风险做出经过计算的决策。

```text
Model NASAswitches

Parameters:
    switch1: Boolean
    switch2: Boolean
    switch3: Boolean
    switch4: Boolean
    switch5: Boolean
    switch6: Boolean
    switch7: Boolean
    switch8: Boolean
    switch9: Boolean
    switch10: Boolean
    switch11: Boolean
    switch12: Boolean
    switch13: Boolean
    switch14: Boolean
    switch15: Boolean
    switch16: Boolean
    switch17: Boolean
    switch18: Boolean
    switch19: Boolean
    switch20: Boolean
    switch21: Boolean
    switch22: Boolean
    switch23: Boolean
    switch24: Boolean
    switch25: Boolean
    switch26: Boolean
    switch27: Boolean
    switch28: Boolean
    switch29: Boolean
    switch30: Boolean
    switch31: Boolean
    switch32: Boolean
    switch33: Boolean
    switch34: Boolean
```

在 [CTWedge](https://foselab.unibg.it/ctwedge/) 中通过下拉菜单开关测试的相互作用次数。

* 14 次测试：通过开关之间的 2 次相互作用引起的故障 - 可根据产品找到 60-99% 的所有潜在故障
* 33 次测试：通过开关之间的 3 次相互作用引起的故障 - 可根据产品找到 90-99% 的所有潜在故障
* 85 次测试：通过开关之间的 4 次相互作用引起的故障 - 可根据产品找到 95-99% 的所有潜在故障
* 220 次测试：通过开关之间的 5 次相互作用引起的故障 - 可找到超过 99% 的所有潜在故障
* 538 次测试：通过开关之间的 6 次相互作用引起的故障 - 可找到所有潜在故障的 100%

<br/><br/>

## (2) 代码示例 - [西门子楼宇操作员 CI 配置](https://cypress.slides.com/cypress-io/siemens-case-study#/16)

参考上面的幻灯片链接或[直播视频](https://www.youtube.com/watch?v=aMPkaLOpyns&t=1624s)以获取有关如何使用[CAMetrics](https://matris.sba-research.org/tools/cametrics/#/new)测量组合覆盖率的详细说明。基本上，你可以使用任何组合测试工具生成一个 CSV 文件，然后将其拖放到 CAMetrics 中。之后，CAMetrics 可以为你提供各种组合覆盖率报告。

> 请注意，将 [CSV 转换为 JSON](https://www.csvjson.com/csv2json) 非常简单，然后可以使用 JSON 文件在所选的任何测试框架中进行数据驱动测试。

```text
Model CI
 Parameters:
   deployment_UI : { branch, development, staging }
   deployment_API:  { development, staging }
   spec_suite: { ui_services_stubbed, ui_services, ui_services_hardware, spot_check}
   browser: { chrome, electron, firefox }

 Constraints:
   // one extra constraint for firefox spot checks
   # browser=firefox <=> spec_suite=spot_check #
   // on staging, run all tests
   # spec_suite=ui_services_hardware <=> deployment_API=staging #
   // match dev vs dev, staging vs staging, and when on staging use Chrome
   # deployment_UI=development => deployment_API=development #
   # deployment_UI=staging => deployment_API=staging #
   # deployment_UI=staging && deployment_API=staging => browser=chrome #
   // when on branch, stub the services
   # deployment_UI=branch => spec_suite=ui_services_stubbed #
   // do not stub the services when on UI development
   # deployment_UI=development => spec_suite!=ui_services_stubbed #
```

## 参考资料和延伸阅读

[自动化组合测试软件](https://csrc.nist.gov/Projects/automated-combinatorial-testing-for-software)

[幻灯片 16-50：探讨自动化和组合纪律在辅助探索性测试方面的应用](https://prezi.com/tpffqit1yn87/utilization-of-automation-and-combinatorial-disciplines-in-aid-of-exploratory-testing/)

[西门子工业公司建筑技术部实际组合测试方法的应用](https://ieeexplore.ieee.org/document/7899057?section=abstract)

[现代 Web 开发中组合测试的工业研究](https://ieeexplore.ieee.org/document/8728910)

[在大型组织中引入组合测试](https://ieeexplore.ieee.org/document/7085645/)

[组合策略的输入参数建模](http://barbie.uta.edu/~mehra/1%20INPUT%20PARAMETER%20MODELING%20FOR%20COMBINATION%20STRATEGIES.pdf)

[组合模型中的常见模式](http://barbie.uta.edu/~mehra/62_Common%20Patterns%20in%20Combinatorial%20Models.pdf)

[等效类和两层覆盖阵的高效验证和同时测试](https://tsapps.nist.gov/publication/get_pdf.cfm?pub_id=917899)



================================================
FILE: sections/advanced/email-testing.md
================================================
# Email Testing

<br/><br/>

### One Paragraph Explainer

Email testing is [critical for business success](https://www.industrialmarketer.com/why-email-testing-is-critical-for-email-marketing-success/) and [boosts email performance](https://litmus.com/blog/3-reasons-why-email-testing-boosts-email-performance).
It is not something we want to forego while testing our web applications because modern email services allow painless automated email testing.
Typically email testing involves validating email fields (from, to, cc, bcc, subject, attachments), HTML content and links in the email. Email services also allow spam checks and visual checks.
The core goal is to enable the last mile of end to end testing, to enable a typical web app to be tested from start to finish.

For example imagine a scenario where a user starts having received an email invite from an organization, through company proprietary services or third party such as LinkedIn invitations.
Then, the user verifies email content, accepts the invite, and joins the organization.
Later, the user can leave the organization - or get removed by an administrator - then receives another email notification.
Using an email service, the entirety of this requirement is possible to automate and execute within seconds.

That being stated, email testing is a fundamental enabler for SaaS test architectures by permitting stateless tests that can scale; tests that independently handle their state and can be executed by _n_ number of entities at the same time.
Check out the topic [**Test States**](./sections/advanced/test-states.md) for further discussion on the topic.

<br/><br/>

## Foreword

If you are using [Gmail tricks](https://www.idownloadblog.com/2018/12/19/gmail-email-address-tricks/) or [AWS Simple Email Service](https://docs.aws.amazon.com/ses/latest/DeveloperGuide/send-email-simulator.html) and these use cases are satisfactory for your test needs without any side effects, only [topic 1](#topic-1) might be of interest to you.

There are plenty of [email testing solutions](https://www.g2.com/search/products?max=10&query=email+testing) available, and combinations of test frameworks that integrate with them.
For the code snippets and working examples, we will be using [Cypress](https://www.cypress.io/) and [Mailosaur](https://mailosaur.com/), but the ideas should generally apply to any tuple of email services and test automation frameworks.

When using Cypress with Mailosaur, there are 3 test-development approaches:

- Implement [Mailosaur API](https://docs.mailosaur.com/reference) using Cypress API testing capabilities using [`cy.request()`](https://docs.cypress.io/api/commands/request.html#Syntax) or [`cy.api()`](https://github.com/bahmutov/cy-api). Utilize plugins and helper utilities to construct test suites.

- Utilize [Mailosaur's Node package](https://www.npmjs.com/package/mailosaur) and implement them using [`cy.task()`](https://docs.cypress.io/api/commands/task.html#Syntax) which allows running node within Cypress.

- Use the [Cypress Mailosaur plugin](https://www.npmjs.com/package/cypress-mailosaur) and abstract away all the complexity!

> Check out [cypress-mailosaur-recipe](https://github.com/muratkeremozcan/cypressExamples/tree/master/cypress-mailosaur) for a working example with these approaches. Note that you will have to start a new Mailosaur trial account and replace environment variables for yourself.

<br/><br/>

## (1) Explanation & Code sample - Enabling stateless, scalable tests <a id="topic-1"></a>

Stateless tests that can scale are a necessity in any modern web application testing. We want tests that independently handle their state and tests that can be executed by _n_ number of entities at the same time.

While testing SaaS applications, which generically have Subscriptions, Users, Organizations (ex: [Slack](https://slack.com/intl/en-sk/help/articles/115004071768-What-is-Slack-#your-team-in-slack), [Cypress Dashboard Service](https://dashboard.cypress.io/organizations), etc.) a lot of the end to end workflows can rely on having unique users. Elsewise only one test execution can happen at a time and they clash with other simultaneous test executions.
This constraint reduces test automation to cron jobs or manually triggered CI.

Some ways to address unique users is by utilizing [Gmail tricks](https://www.idownloadblog.com/2018/12/19/gmail-email-address-tricks/) or [AWS Simple Email Service](https://docs.aws.amazon.com/ses/latest/DeveloperGuide/send-email-simulator.html). It is possible that you do not have to check actual email content (from, to, cc, bcc, subject, attachments etc.) and only want to have unique users, then you are on the right path with stateless tests.
However, these approaches can still be problematic; for example, non-existing emails can prompt bouncing emails to your cloud service and that can be a headache. If you want to avoid such issues and check real email content in automation, email services provide value.

Email services can also provide cost savings in test execution time by receiving emails faster, tests running quicker in the pipeline with less CI resources being consumed and less time waiting for tests to finish. If you are running 1000 pipelines a year, and save 3-4 seconds per pipeline execution, the email service can be already paying for its annual subscription just by providing extra speed.

### Achieving Stateless tests with unique emails

If in every test execution a new, unique user was used and the emails to this unique user could be verified in isolation, it would be possible to achieve a stateless test. The only side effect would be to the email service inbox, but if the test only checked emails by reference and cleaned up after itself, the email service mailbox would not be impacted.

This is easy to achieve with Mailosaur, here are two approaches to this: [Mailosaur's Node package](https://www.npmjs.com/package/mailosaur) or our own util with `faker.js`.

```javascript
// at cypress/plugins/mailosaur-tasks.js

// generates a random email address
// sample output:   ojh788.<serverId>@mailosaur.io
const createEmail = () => mailosaurClient
  .servers
  .generateEmailAddress(envVars.MAILOSAUR_SERVERID);
);

// our custom function at a helper file or commands file. The only difference is the defined prefixed name.
// sample output:  fakerJsName.<serverId>@mailosaur.io
const createMailosaurEmail = randomName =>
  `${randomName}.${Cypress.env('MAILOSAUR_SERVERID')}@mailosaur.io`;
```

<br/><br/>

## (2) Explanation - what to test in an email and how

First, let's elaborate on the setup we need.

### Test Setup and Hybrid Approach: [Mailosaur Rest API](https://docs.mailosaur.com/reference) with `cy.request()` and [Mailosaur's Node package](https://www.npmjs.com/package/mailosaur) with `cy.task()`

Mailosaur provides an [npm package](https://www.npmjs.com/package/mailosaur) and effectively all the Node code samples in the [API documentation](https://docs.mailosaur.com/reference) can be converted to `cy.task()`. Another approach is to implement Mailosaur's Rest API 'from scratch with `cy.request()`.

> Mailosaur released  [Cypress Mailosaur plugin](https://www.npmjs.com/package/cypress-mailosaur) mid 2020, and it abstracts away all the complexity with these 2 approaches. Skip to the end to see code samples and comparison.

### Environment variables

We recommend these values as environment variables. You can grab them from Mailosaur web application by creating a free trial account using any email. The trial account lasts for two weeks.

```json
  "MAILOSAUR_SERVERID": "******",
  "MAILOSAUR_PASSWORD": "******",
  "MAILOSAUR_API_KEY": "*******",
  "MAILOSAUR_API": "https://mailosaur.com/api",
  "MAILOSAUR_SERVERNAME": "user-configurable-server-name"
```

### Modularizing `cy.task()`

You can put all utilities in `cypress/plugins/index.js` file like in [this example](https://github.com/muratkeremozcan/cypressExamples/blob/master/cypress-mailosaur/cypress/plugins/index.js). A neater approach is putting all Mailosaur related tasks in its own module and importing them to the plugins file.

```javascript
// cypress/plugins/index.js

const task = require('some-plugin/task')
const percyHealthCheck = require('@percy/cypress/task') // or any other plugin you may need
const mailosaurTasks = require('./mailosaur-tasks') // our mailosaur module

// This is a pattern to merge all Cypress tasks
const all = Object.assign({}, percyHealthCheck, task, mailosaurTasks)

module.exports = (on, config) => {
  on('task', all)
}

////////

// cypress/plugins/mailosaur-tasks.js (this could be anywhere)

// the npm package
const MailosaurClient = require('mailosaur')
// we used a static file for envVars. cypress.env.json file can cause issues in CI
// There can be other solutions, do your best here.
const envVars = require('../../cypress.json')
const mailosaurClient = new MailosaurClient(envVars.MAILOSAUR_API_KEY)

// replicate Mailosaur's npm code from api docs
// https://docs.mailosaur.com/docs/fetching-messages
/** finds the most recent email message to the given email*/
const findEmailToUser = async (userEmail) => {
  let message = await mailosaurClient.messages.get(
    envVars.MAILOSAUR_SERVERID,
    {
      sentTo: userEmail,
    },
    { timeout: 25000 }
  ) // time to wait for an email to arrive
  return message
}

// other useful utilities can include the below. You can replicate them using the api docs.

// checkServerName()
// createEmail()
// deleteAMessage(messageId)
// listAllMessages()

module.exports = { checkServerName, createEmail, findEmailToUser, listAllMessages, deleteAMessage }
```

### Other Useful helper functions that Mailosaur npm package does not provide _(as far as we know)_

We can harmonize Rest API / `cy.request()` approach with npm package / `cy.task()` to build our own utility.

```javascript
/** Given user email, returns the id of the email to that user. Good example of hybrid utility functions */
const getEmailId = (email) => cy.task('findEmailToUser', email).its('id')

/** Deletes 1 email message by message id. Can be useful if you want to delete the message after running the test. */
const deleteEmailById = (id) => {
  return cy.request({
    method: 'DELETE',
    url: `${Cypress.env('MAILOSAUR_API')}/messages/${id}`,
    headers: {
      // important detail
      authorization: Cypress.env('MAILOSAUR_PASSWORD'),
    },
    auth: {
      // important detail
      user: Cypress.env('MAILOSAUR_API_KEY'),
      password: '', // any pw or empty pw will do
    },
    retryOnStatusCodeFailure: true, // because we can
  })
}

/** Deletes the most recent email sent to the user. Useful for resetting state. */
export const deleteEmail = (email) => getEmailId(email).then((id) => deleteEmailById(id))
```

<br/><br/>

## (3) Code sample - what to test in an email and how

Validating email fields (from, to, cc, bcc, subject, attachments), HTML content and links in the email.

```javascript

// an invite goes out to the recipient from the sender...

// in the cypress spec file > it block...

cy.task('findEmailToUser', recipientEmail).then(emailContent => {
  cy.wrap(emailContent).its('from')..<chain as needed>.should('eq', senderEmail); // from
  cy.wrap(emailContent).its('to')..<chain as needed>.should(..)// to
  cy.wrap(emailContent).its('cc')..<chain as needed>.should(..); // cc
  cy.wrap(emailContent).its('subject')..<chain as needed>.should(..); // subject
  // similar approach with attachments.
  // You can always end with ... .then(console.log) to take a look at the content
  // of you can check out the mailosaur email as JSON content, which makes everything easier!
  // cy.wrap(emailContent).then(console.log);

  // sample utilities to check assertions
  const html = () => cy.wrap(emailContent).its('html');
  const htmlLinks = () => html().its('links');
  const images = html().its('images');

  htmlLinks().should(..); // or chain further
  images().should(..);

  // note that you can use different styles of api assertions with Cypress
  // check out api testing examples at
  // https://github.com/cypress-io/cypress-example-recipes/tree/master/examples/blogs__e2e-api-testing
  // https://github.com/muratkeremozcan/cypressExamples/blob/master/cypress-api-testing/cypress/integration/firstTest.spec.js
});
```

## (4) The overhead is abstracted away with [Cypress Mailosaur plugin](https://www.npmjs.com/package/cypress-mailosaur)

Mailosaur team released a Cypress plugin in mid 2020. With it, we do not have to replicate any complex API utities or use cy.task via Mailosaur npm package; none of what you have seen in section (3) is necessary. There is no need to create cy.task utilities or even hyberdize them. With the Cypress Mailosaur plugin, you can just use the custom Cypress commands Mailosaur team created for us.

All we need is to install the package `npm install cypress-mailosaur --save-dev` and add the following line to cypress/support/index.js:
`import 'cypress-mailosaur'`.

Mailsaur plugin has a few handy functions which help you abtract complex needs.
A full list can be found at at https://github.com/mailosaur/cypress-mailosaur

Here is the plugin version of the above code. The usage is somewhat similar, but we did not have implement any cy.task() utilities, custom helper functions or hybrid helpers. We also get new, easy to use helper functions that work seamlessly.

You can find a working version of this code and the above at the [link](https://github.com/muratkeremozcan/cypressExamples/tree/master/cypress-mailosaur).
```javascript
it('uses the plugin to check the email content (no need for creating complex utilities with cy.task) ', function () {
    const userEmail = createEmail(internet.userName());
    cy.task('sendSimpleEmail', userEmail); // an npm package to send emails, usually your app would do this

    // a convenient helper functions to list mesages
    cy.mailosaurListMessages(Cypress.env('MAILOSAUR_SERVERID')).its('items').its('length').should('not.eq', 0);

    // this helper command replaces the complex cy.task('findEmailToUser') utility we had to create
    cy.mailosaurGetMessage(
      Cypress.env('MAILOSAUR_SERVERID'),
      { sentTo: userEmail },
      // note from Jon at Mailosaur:
      // The get method looks for messages received within the last hour
      // if looking for emails existing before that, you have to add this. Optional otherwise
      // { receivedAfter: new Date('2000-01-01') }
    ).then(emailContent => {
      // this part is the same
      cy.wrap(emailContent).its('from').its(0).its('email').should('contain', 'test@nodesendmail.com');
      cy.wrap(emailContent).its('to').its(0).its('email').should('eq', userEmail);
      cy.wrap(emailContent).its('subject').should('contain', 'MailComposer sendmail');
    });

    // alternate approach to getting message by sent to'
    cy.mailosaurGetMessagesBySentTo(Cypress.env('MAILOSAUR_SERVERID'), userEmail).then(emailItem => {
      // the response is slightly different, but you can modify it to serve the same purpose
      const emailContent = emailItem.items[0];
      cy.wrap(emailContent).its('from').its(0).its('email').should('contain', 'test@nodesendmail.com');
      cy.wrap(emailContent).its('to').its(0).its('email').should('eq', userEmail);
      cy.wrap(emailContent).its('subject').should('contain', 'MailComposer sendmail');
    });

    // an easy to use bonus utility for checking spam score
    cy.mailosaurGetMessagesBySentTo(Cypress.env('MAILOSAUR_SERVERID'), userEmail).its('items').its(0).its('id').then(messageId => {
      // does convenient spam analysis
      cy.mailosaurGetSpamAnalysis(messageId).its('score').should('eq', 0);
      // you can observe the console output with a plain "cy.mailosaurGetSpamAnalysis(messageId);  " and check for deeper assertions
    })
  });


```


================================================
FILE: sections/advanced/email-testing.zh.md
================================================
[Binary file]


================================================
FILE: sections/advanced/performance-testing.md
================================================
# Performance Testing

<br/><br/>

### One Paragraph Explainer

Although performance testing is a vast topic, as Web Developers we can quickly benefit from some of its core principles to improve user experience, satisfy functional and non-functional requirements (NFRs) and detect ambiguous system issues that may leak into production.

<br/><br/>

### (1) Ensuring user experience with Lighthouse

As web developers, our foremost concern is the user perception of performance. Thankfully, Google has made it easy and provided us with a 3rd-party authority evaluation of our web application with [Lighthouse](https://developers.google.com/web/tools/lighthouse).

> *"Lighthouse is an open-source, automated tool for improving the quality of web pages. You can run it against any web page, public or requiring authentication. It has audits for performance, accessibility, progressive web apps, SEO and more."*

For this topic, we will only focus on Performance, but you should consider also benefiting from **Progressive Web App**, **Accessibility**, **Search Engine Optimization** and **Best practices** evaluations of Lighthouse.

Getting started is easy: Chrome > DevTools > Audits > Lighthouse. Then, generate the report. It will look as such and give you precise pointers on what you can do to improve the user experience.

![Lighthouse report](../../assets/images/perf-testing/lighthouse.png)

Once the improvements are made and a baseline rating is agreed on, you can prevent regression by incorporating Lighthouse into your CI.
  * Add Lighthouse as a node_module; `npm i -D lighthouse` or `yarn add --dev lighthouse`.
  * Follow the workflow example at [Lighthouse Git repo](https://github.com/GoogleChrome/lighthouse/blob/master/docs/readme.md#using-programmatically).
  * Prevent the performance rating (and/or other ratings) from regressing upon developer commits!

#### Lighthouse with Cypress

If you are a Cypress user, with [cypress-audit](https://github.com/mfrachet/cypress-audit) you can execute Lighthouse audits in Cypress tests as well as [Pa11y](https://www.npmjs.com/package/pa11y) for automated accessibility testing. 

> In addition to the [usual plugin setup](https://github.com/mfrachet/cypress-audit#preparation), you may need to [workaround cross-origin](https://github.com/cypress-io/cypress/issues/944#issuecomment-788373384) needs of your application until Cypress has official support for it.

Here is a sample test with in-line explanations.

```typescript

// Pass in optional configuration parameters for the Cypress test:
// you may need to increase default timeout for the overall task, if you have a slow app. Mind that Lighthouse is only for Chromium based browsers
describe('Lighthouse audit ', { taskTimeout: 90000, browser: 'chrome' }, () => {
  before(() => {
    // if you are using programmatic login, you might not need to use the cy.forceVisit('/') workaround for cross-origin (linked above)
    cy.login(Cypress.env('USERNAME'), Cypress.env('PASSWORD'));
  });

  // thresholds is the first argument to cy.lighthouse(), most of the performance configuration is done here.
  // a complete list of Lighthouse parameters to use as thresholds can be found at https://github.com/mfrachet/cypress-audit/blob/master/docs/lighthouse.md
  // for an explanation of the parameters, refer to https://web.dev/lighthouse-performance/
  const thresholds = {
    'first-contentful-paint': 20000,
    'largest-contentful-paint': 35000,
    'first-meaningful-paint': 20000,
    'speed-index': 25000,
    interactive: 40000,
    performance: 5,
    accessibility: 50,
    'best-practices': 50,
    seo: 50,
    pwa: 20
  };

  // the 2nd, and optional argument to cy.lighthouse() replicates Lighthouse CLI commands https://github.com/GoogleChrome/lighthouse#cli-options
  const desktopConfig = {
    formFactor: 'desktop',
    screenEmulation: { disabled: true }
  };

  // your app may need this beforeEach and afterEach workaround for cross-origin (linked above)
  beforeEach(() => {
    cy.restoreLocalStorage();
    // Preserve Cookies between tests
    Cypress.Cookies.defaults({
      preserve: /[\s\S]*/
    });
  });

  afterEach(() => {
    cy.saveLocalStorage();
  });

  it('should pass audit for main page ', () => {
    cy.lighthouse(thresholds, desktopConfig);
  });

  it('should pass audit for another page', () => {
    cy.forceVisit('anotherUrl');
    cy.lighthouse(thresholds, desktopConfig);
  });
});

// Commands for working around cross origin, if needed

// -- Save localStorage between tests
let LOCAL_STORAGE_MEMORY = {};
Cypress.Commands.add('saveLocalStorage', () => {
  Object.keys(localStorage).forEach(key => {
    LOCAL_STORAGE_MEMORY[key] = localStorage[key];
  });
});

Cypress.Commands.add('restoreLocalStorage', () => {
  Object.keys(LOCAL_STORAGE_MEMORY).forEach(key => {
    localStorage.setItem(key, LOCAL_STORAGE_MEMORY[key]);
  });
});

// -- Visit multiple domains in one test
Cypress.Commands.add('forceVisit', url => {
  cy.window().then(win => win.open(url, '_self'));
});
```



<br/><br/>

### (2) Performance as a Non-functional Requirement and the Kano model

We can start building our understanding of performance requirements with the [Kano model](https://en.wikipedia.org/wiki/Kano_model).

> *"The Kano model is a theory for product development and customer satisfaction developed in the 1980s by Professor Noriaki Kano, which classifies customer preferences into five categories."*

At a high-level, the Kano model summarizes that performance features are standard requirements that are expected of any competitive product. This overlaps with our usage of Lighthouse; with it we ensure tha we satisfy customer preferences and that we do not regress from it.

![Kano model](../../assets/images/perf-testing/KANO_model.jpg)

At this point, we have fulfilled explicitly stated performance requirements. However, in complex applications, we need to be aware of non-functional requirements (NFRs) as well. But, what are NFRs? Below is a high-level view of them at a glance - from the double standard [ISO/IEC 25010 Product Quality Model](https://www.iso.org/standard/35733.html).

![ISO/IEC standard](../../assets/images/perf-testing/ISO_IEC_25010.jpg)

In the next section, let's focus on how NFRs can help us approach non-function performance testing.

<br/><br/>

### (3) Types of Performance Testing

For practical purposes, we can reduce non-functional performance testing into 3 categories

* Load
* Spike
* Endurance

This graph summarizes their context:

![ISO/IEC standard](../../assets/images/perf-testing/performanceTesting.jpg)

***Side note about Benchmarking and Stress Testing**: Essentially, benchmarking boils down to the step-wise approach as we get a feel for our system which becomes a part of the initial work-flow with automated tools; *"Does my system break yet? No? Let me increase it"*. Stress testing on the other hand is, in short, overdoing it.*

What is the distinction of **Scalability Testing**? It is related; the distinction is an evaluation of when exactly the system starts not responding in a satisfactory fashion. Usually, the approach with an automated tool is close enough and can be realized while analyzing graphs in a load test.

Here is a high-level picture of the intent with Scalability Testing:

![ISO/IEC standard](../../assets/images/perf-testing/scalabilityTesting.jpg)


<br/><br/>

### (4) Practical applications of Performance Testing with k6-loadImpact

There are two qualities that set [k6-loadImpact](https://docs.k6.io/docs) apart for web developers.

  * Uses JS (ES6)
  * Is built for CI

Side bonus: if you hooked on Postman, you can convert those tests to k6 easily.
K6 *can* do DOM testing, however, we believe Lighthouse takes care of that. The true power of k6 comes out when testing APIs.

You can find [quickstart examples with k6 here](https://github.com/muratkeremozcan/k6-loadImpact).
The examples start very simple and are meant to build up the understanding quickly. They are ready to be run out of the box and tinkered with. We will not duplicate that knowledge here.

Instead, in this section, we will cover the overview of a k6 test, and later show a code sample on how k6 can be configured to accommodate different types of performance testing.


```javascript
// k6 lifecycle overview:

// 1. init code -> runs once
// this is where we configure the type of performance testing (there are also
// additional options we do not cover here)
export let options = {
  // there will be 1 virtual user
  vus: 1,

  // default function() will execute 1 time. This simple config
  // is best when trying to get things to work
  iterations: 1,
}

// 2. (optional) setup code -> runs once
export function setup() {
  // for example getting a token so you can run API tests in the default
  // function that comes in (3) virtual user code

  // what gets returned from this function is passed as an argument to the next
  // function. For example: `token`
  return getTokenForUser();
}

// 3. virtual user code -> runs once or many times based on
// `export let options = { ... } `
export default function(token) {
  // http.get is a k6 function that hits a URL with optional test parameters
  // note that  we do not need a token for this url
  http.get("http://test.loadimpact.com");
}

// 4. (optional) teardown code -> runs once
export function teardown(data) {
  // this is in case you need to clean up, for instance if failed test may
  // leave residue an impact state
}
```

Endurance test configuration:
```javascript
export let options = {
  // endurance test for 30 seconds with 50 virtual users. Adds users immediately
  vus: 50,
  duration: "30s",

  // alternative to duration, you can  specify the exact number of iterations
  // the test will run
  // iterations: 500,
}
```

Load test configuration:
```javascript
export let options = {
  // for 15 seconds ramps up 10 users, adds users gradually
  // adds a total of 40 users in the next 15 seconds, and up to 50 in the next
  // 30 seconds..
  // lowers down the users to 10 and 5 in the next 15 second iterations
  stages: [
    { duration: "15s", target: 10 },
    { duration: "15s", target: 40 },
    { duration: "30s", target: 50 },
    { duration: "15s", target: 10 },
    { duration: "15s", target: 5 },
  ]
}
```

Spike test configuration:
```javascript
export let options = {
  // starts slow and builds up the load rapidly, and then drops the load
  stages: [
    { duration: "5s", target: 1 },
    { duration: "5s", target: 5 },
    { duration: "5s", target: 25 },
    { duration: "3s", target: 200 },
    { duration: "3s", target: 20 },
    { duration: "3s", target: 10 },
    { duration: "3s", target: 5 },
    { duration: "3s", target: 1 },
  ]
}
```
As you can see, the `stages` are the utility to configure your performance test type.

#### How do we analyze the results?

K6 provides a simple [CLI output](https://docs.k6.io/docs/results-output). We believe the most important 2 high-level values here are `http_req_duration` which details response duration and `http_req` which shows the number of requests sent. If these are looking at acceptable values, CLI fulfills its purpose.

![k6 CLI](../../assets/images/perf-testing/k6-CLI.PNG)

In case of a need for further diagnosis, the graphical [insights](https://docs.k6.io/docs/load-impact-insights) is valuable. The key in a graph like this is for *Response time* and *Request rate* to follow the trend of *Virtual Users*. Any variances in the trend may signal to underlying issues.

![k6 insights](../../assets/images/perf-testing/insights.PNG)

<br/><br/>

### (5) Using performance testing to prevent ambiguous issues leaking into production

Refer to [Test Flake > Step (3): Identifying sporadic system issues - system flake](./test-flake.md)

<br/><br/><br/><br/>

## References & Further reading

[Lighthouse documentation](https://developers.google.com/web/tools/lighthouse)

[Lighthouse repo](https://github.com/GoogleChrome/lighthouse)

[Kano model](https://en.wikipedia.org/wiki/Kano_model)

[ISO/IEC 25010 Product Quality Model](https://www.iso.org/standard/35733.html)

[k6-loadImpact documentation](https://docs.k6.io/docs)

[Quick start examples with k6](https://github.com/muratkeremozcan/k6-loadImpact)



================================================
FILE: sections/advanced/performance-testing.zh.md
================================================
# 性能测试

<br/><br/>

## 一段简要说明

虽然性能测试是一个庞大的话题，但作为 Web 开发者，我们可以迅速从其核心原则中获益，以提升用户体验、满足功能和非功能需求（NFRs），并检测可能泄漏到生产环境中的不明确系统问题。

<br/><br/>

## (1) 通过 Lighthouse 确保用户体验

作为 Web 开发者，我们最关心的是用户对性能的感知。谢天谢地，Google 已经让这变得简单，并为我们提供了一个第三方权威评估我们 Web 应用程序的工具 - [Lighthouse](https://developers.google.com/web/tools/lighthouse)。

> *"Lighthouse 是一个用于提高网页质量的开源自动化工具。你可以对任何网页运行它，无论是公开的还是需要身份验证的。它可以进行性能、可访问性、渐进式 Web 应用、SEO 等方面的审计。"*

在这个话题中，我们只关注性能，但你也应该考虑从 Lighthouse 的审计中获得关于**渐进式 Web 应用**、**可访问性**、**搜索引擎优化**和**最佳实践**的评估。

入门很简单：Chrome > 开发者工具 > 审计 > Lighthouse。然后，生成报告。它会显示如下，并为你提供有关如何改善用户体验的详细指南。

![Lighthouse 报告](../../assets/images/perf-testing/lighthouse.png)

一旦进行了改进并达成了基线评级，您可以通过将 Lighthouse 纳入您的 CI 来防止回归。

* 将 Lighthouse 添加为 node_module；`npm i -D lighthouse` 或 `yarn add --dev lighthouse`。
* 参考 [Lighthouse Git 存储库](https://github.com/GoogleChrome/lighthouse/blob/master/docs/readme.md#using-programmatically) 上的工作流示例。
* 防止性能评级（和/或其他评级）在开发人员提交代码时出现回归！

### 使用 Cypress 集成 Lighthouse

如果你是 Cypress 用户，通过 [cypress-audit](https://github.com/mfrachet/cypress-audit) 插件，你可以在 Cypress 测试中执行 Lighthouse 审计，以及 [Pa11y](https://www.npmjs.com/package/pa11y) 进行自动化的可访问性测试。

> 除了[通常的插件设置](https://github.com/mfrachet/cypress-audit#preparation)之外，你可能需要解决你的应用程序的[跨域问题](https://github.com/cypress-io/cypress/issues/944#issuecomment-788373384)，直到 Cypress 官方支持它。

以下是一个带有内联说明的示例测试。

```typescript

// Pass in optional configuration parameters for the Cypress test:
// you may need to increase default timeout for the overall task, if you have a slow app. Mind that Lighthouse is only for Chromium based browsers
describe('Lighthouse audit ', { taskTimeout: 90000, browser: 'chrome' }, () => {
  before(() => {
    // if you are using programmatic login, you might not need to use the cy.forceVisit('/') workaround for cross-origin (linked above)
    cy.login(Cypress.env('USERNAME'), Cypress.env('PASSWORD'));
  });

  // thresholds is the first argument to cy.lighthouse(), most of the performance configuration is done here.
  // a complete list of Lighthouse parameters to use as thresholds can be found at https://github.com/mfrachet/cypress-audit/blob/master/docs/lighthouse.md
  // for an explanation of the parameters, refer to https://web.dev/lighthouse-performance/
  const thresholds = {
    'first-contentful-paint': 20000,
    'largest-contentful-paint': 35000,
    'first-meaningful-paint': 20000,
    'speed-index': 25000,
    interactive: 40000,
    performance: 5,
    accessibility: 50,
    'best-practices': 50,
    seo: 50,
    pwa: 20
  };

  // the 2nd, and optional argument to cy.lighthouse() replicates Lighthouse CLI commands https://github.com/GoogleChrome/lighthouse#cli-options
  const desktopConfig = {
    formFactor: 'desktop',
    screenEmulation: { disabled: true }
  };

  // your app may need this beforeEach and afterEach workaround for cross-origin (linked above)
  beforeEach(() => {
    cy.restoreLocalStorage();
    // Preserve Cookies between tests
    Cypress.Cookies.defaults({
      preserve: /[\s\S]*/
    });
  });

  afterEach(() => {
    cy.saveLocalStorage();
  });

  it('should pass audit for main page ', () => {
    cy.lighthouse(thresholds, desktopConfig);
  });

  it('should pass audit for another page', () => {
    cy.forceVisit('anotherUrl');
    cy.lighthouse(thresholds, desktopConfig);
  });
});

// Commands for working around cross origin, if needed

// -- Save localStorage between tests
let LOCAL_STORAGE_MEMORY = {};
Cypress.Commands.add('saveLocalStorage', () => {
  Object.keys(localStorage).forEach(key => {
    LOCAL_STORAGE_MEMORY[key] = localStorage[key];
  });
});

Cypress.Commands.add('restoreLocalStorage', () => {
  Object.keys(LOCAL_STORAGE_MEMORY).forEach(key => {
    localStorage.setItem(key, LOCAL_STORAGE_MEMORY[key]);
  });
});

// -- Visit multiple domains in one test
Cypress.Commands.add('forceVisit', url => {
  cy.window().then(win => win.open(url, '_self'));
});
```

<br/><br/>

## (2) 性能作为一种非功能性需求和 Kano 模型

我们可以通过[Kano 模型](https://en.wikipedia.org/wiki/Kano_model)开始建立对性能需求的理解。

> *"Kano 模型是在 1980 年代由日本学者狩野纪明教授开发的产品开发和客户满意度理论，将客户偏好分为五类。"*

从高层次上看，卡诺模型总结了性能特性是标准要求，是任何竞争性产品所期望的。这与我们使用 Lighthouse 的方式重叠；通过它，我们确保满足客户偏好，并确保我们不会回退。

![Kano 模型](../../assets/images/perf-testing/KANO_model.jpg)

在这一点上，我们已经满足了明确说明的性能要求。然而，在复杂的应用程序中，我们还需要注意非功能性需求（NFRs）。但是，什么是 NFRs 呢？下面是它们在一瞥之下的高层次视图 - 来自双重标准的[ISO/IEC 25010 产品质量模型](https://www.iso.org/standard/35733.html)。

![ISO/IEC标准](../../assets/images/perf-testing/ISO_IEC_25010.jpg)

在下一节中，让我们专注于 NFRs 如何帮助我们进行非功能性能测试的方法。

<br/><br/>

## (3) 性能测试的类型

为了实际应用，我们可以将非功能性能测试分为 3 个类别

* Load 负载测试
* Spike 尖峰测试
* Endurance 耐久测试

这张图总结了它们的上下文：

![ISO/IEC标准](../../assets/images/perf-testing/performanceTesting.jpg)

***关于基准测试和压力测试的额外说明**: 本质上，基准测试归结为逐步的步骤，因为我们逐渐了解我们的系统，这成为了初始工作流程的一部分，其中使用自动化工具；*"我的系统已经崩溃了吗？没有？那我再增加一点"。*而压力测试，简而言之，就是做得过火了。*

那么**可扩展性测试**的区别是什么？它是相关的；区别在于系统何时开始以不令人满意的方式不响应的评估。通常情况下，使用自动化工具的方法足够接近，并且可以在负载测试中分析图表时实现。

这是可扩展性测试意图的高层次图：

![ISO/IEC标准](../../assets/images/perf-testing/scalabilityTesting.jpg)

<br/><br/>

### (4) 使用 k6-loadImpact 进行性能测试的实际应用

[k6-loadImpact](https://docs.k6.io/docs)在 Web 开发领域有两个显著的特点。

* 使用 JS（ES6）
* 专为 CI 构建

额外的好处：如果你习惯使用 Postman，你可以轻松地将这些测试转换为 k6。
K6 *可以* 进行 DOM 测试，但我们认为 Lighthouse 已经处理了这方面的问题。K6 真正强大的地方在于测试 API 时。

你可以在[这里找到使用 k6 的快速入门示例](https://github.com/muratkeremozcan/k6-loadImpact)。
这些示例从非常简单的开始，旨在快速建立理解。它们已经准备好直接运行和调整。我们将不会在这里重复这些知识。

相反，在本节中，我们将概述 k6 测试的概览，并稍后展示一个代码示例，演示如何配置 k6 以适应不同类型的性能测试。

```javascript
// k6 lifecycle overview:

// 1. init code -> runs once
// this is where we configure the type of performance testing (there are also
// additional options we do not cover here)
export let options = {
  // there will be 1 virtual user
  vus: 1,

  // default function() will execute 1 time. This simple config
  // is best when trying to get things to work
  iterations: 1,
}

// 2. (optional) setup code -> runs once
export function setup() {
  // for example getting a token so you can run API tests in the default
  // function that comes in (3) virtual user code

  // what gets returned from this function is passed as an argument to the next
  // function. For example: `token`
  return getTokenForUser();
}

// 3. virtual user code -> runs once or many times based on
// `export let options = { ... } `
export default function(token) {
  // http.get is a k6 function that hits a URL with optional test parameters
  // note that  we do not need a token for this url
  http.get("http://test.loadimpact.com");
}

// 4. (optional) teardown code -> runs once
export function teardown(data) {
  // this is in case you need to clean up, for instance if failed test may
  // leave residue an impact state
}
```

耐久测试配置：

```javascript
export let options = {
  // endurance test for 30 seconds with 50 virtual users. Adds users immediately
  vus: 50,
  duration: "30s",

  // alternative to duration, you can  specify the exact number of iterations
  // the test will run
  // iterations: 500,
}
```

负载测试配置：

```javascript
export let options = {
  // for 15 seconds ramps up 10 users, adds users gradually
  // adds a total of 40 users in the next 15 seconds, and up to 50 in the next
  // 30 seconds..
  // lowers down the users to 10 and 5 in the next 15 second iterations
  stages: [
    { duration: "15s", target: 10 },
    { duration: "15s", target: 40 },
    { duration: "30s", target: 50 },
    { duration: "15s", target: 10 },
    { duration: "15s", target: 5 },
  ]
}
```

尖锋测试配置：

```javascript
export let options = {
  // starts slow and builds up the load rapidly, and then drops the load
  stages: [
    { duration: "5s", target: 1 },
    { duration: "5s", target: 5 },
    { duration: "5s", target: 25 },
    { duration: "3s", target: 200 },
    { duration: "3s", target: 20 },
    { duration: "3s", target: 10 },
    { duration: "3s", target: 5 },
    { duration: "3s", target: 1 },
  ]
}
```

正如你所看到的，`stages` 是配置性能测试类型的实用工具。

### 我们如何分析测试结果？

K6 提供了一个简单的[CLI 输出](https://docs.k6.io/docs/results-output)。我们认为这里最重要的两个高级数值是 `http_req_duration`，它详细说明了响应持续时间，以及 `http_req`，它显示发送的请求数量。如果这些数值在可接受的范围内，CLI 就达到了其目的。

![k6 CLI](../../assets/images/perf-testing/k6-CLI.PNG)

如果需要进行更深入的诊断，图形化的[insights](https://docs.k6.io/docs/load-impact-insights)非常有价值。在这样的图表中，关键是 *响应时间* 和 *请求速率* 跟随 *虚拟用户* 的趋势。任何趋势上的变化都可能提示潜在问题。

<br/><br/>

## (5) 通过性能测试来防止不稳定的问题进入生产环境

可参考章节 [不稳定的测试 > 第三步：识别零星的系统问题 - *不稳定的系统*](./test-flake.zh.md)

<br/><br/><br/><br/>

## 参考资料和延伸阅读

[Lighthouse 文档](https://developers.google.com/web/tools/lighthouse)

[Lighthouse 代码库](https://github.com/GoogleChrome/lighthouse)

[Kano 模型](https://en.wikipedia.org/wiki/Kano_model)

[ISO/IEC 25010 产品质量模型](https://www.iso.org/standard/35733.html)

[k6-loadImpact 文档](https://docs.k6.io/docs)

[使用 K6 的快速启动示例](https://github.com/muratkeremozcan/k6-loadImpact)



================================================
FILE: sections/advanced/test-flake.md
================================================
# Test flake

<br/><br/>

### One Paragraph Explainer

Tests must produce consistent results every time. Repeatable pipeline execution results are the quorum.
If a test cannot produce reliable results, it reduces confidence in the tests and requires maintenance which reduces all value. In these cases, it may be best to manually test the functionality.

And ask yourself these questions:

* How do you address Test Flake and ensure test-confidence through growing pains?
* How do you address false-negatives with the pipeline, infrastructure, shared resources and not having control?
* How do you reveal **Sporadic Defects**?

<br/><br/>


### Step 1: Locally identifying test flake

Headless execution in an OS that replicates pipeline CI machine is preferred; Linux and MacOS will behave more similarly to the pipeline than Windows -with the exception of Windows Docker containers if you are using one. Headless execution will reveal more of the test flake. There are various ways to repeatedly execute a test spec, one example from Cypress is using the Lodash library (already built-in with Cypress) `Cypress._.times( <times to repeat>, () => { <your test spec code> })`. This must be utilized before pushing any code for a merge request.

#### Code Example

```JavaScript
// will repeat the full suite 10 times
Cypress._.times( 10, function {

  describe('..', function () {

    before(function () {
    });

    beforeEach(function () {
    });

      // you can place it anywhere to repeat 1 test, or another describe / context block
      Cypress._.times( 3, function {
        it('..', function () {..});
      }
      it('..', function () {..});
      it('..', function () {..});
      it('..', function () {..});

  });
});

// this will result in 6 tests per run x 10 runs = 60 executions

```
<br/>

### Step 2: Identifying test flake in the pipeline & retries

After initial pipelines pass, things are looking good and the code gets merged, it just so may happen that tests ***sometimes*** fail in the pipeline.

Why do tests still fail if ***there are no reproducible defects*** and ***the test code has been fully optimized***?

Rather than the tests failing at a sporadic rate, getting ignored, or worse ***reducing the team's confidence in them***, retry mechanisms can be utilized:
* To work around an unreliable pipeline infrastructure that the team has no control over
* Growing pains during development and / or dependencies on external services under development
* Most importantly ***to lock-in on sporadic system issues***


#### Code Example

Many frameworks implement retry utilities. Here is an example from [Cypress docs](https://docs.cypress.io/guides/references/migration-guide.html#Tests-retries):

In a test:
```javascript
it('allows user to login', { // can also be in a context or describe block
  retries: {
    runMode: 2, // for CI usage
    openMode: 1  // for local usage
  }
}, () => {
  // ...
})
```

In a configuration file such as `cypress.json`:
```json
{
  "retries": {
    "runMode": 1,
    "openMode": 3
  }
}



```
### Step 3: Identifying sporadic system issues - *system flake*

Given that:

* There are no reproducible defects
* The test code is fully optimized
* Pipeline issues are known and validly worked-around with test retries
* External dependencies, growing pains are known, recognized and worked around with test retries

... How do we detect deeper issues with the system that *may* indicate *system-flake*? Here is a snapshot from a team's [Cypress dashboard](https://www.cypress.io/dashboard/) of such an example:

 >*"It fails at 10% rate over 40 executions on the weekend... We ran the test suite 40 times, and in one of them saw the spec retrying 2 times until it passed..."*
![](../../assets/images/test-retry-pipeline.PNG)

*Pleas note: the camera icon means that there are some test failures because Cypress takes videos and screenshot on failures.*


In these cases, consistency testing with [cron jobs](https://crontab.guru/#0_1-23_*_*_6-7) overnights or the weekends can be utilized as the initial indicator of deeper system issues. These are usually the ambiguous defects that are likely to leak into production, be found on the field and have costly repercussions at a larger scale.


#### Code Example - [cron jobs](https://crontab.guru/#0_1-23_*_*_6-7)

```cron syntax
at minute 0 at midnight and 2 am, every day-of-week from Monday through Friday:

0 0,2 * * 1-5


At minute 0 past hour 2, 6, 8, 10, 12, 14, 16, 18, and 20 on every day-of-week from Saturday through Sunday:

0 2,6,8,10,12,14,16,18,20 * * 6-7
```

Once all other factors are ruled out and the initial indication of *system-flake* realized in automated tests in the pipeline with cron jobs, these issues are perfect candidates for **Performance Testing** because such test methodology can directly indicate shortcomings in the system that may be causing the *system-flake*.

Here is performance testing in a nutshell:

![](../../assets/images/performanceTesting.jpg)


There are many performance testing tools. One that we find approachable due to it being in ES6 and pipeline friendly is [k6-loadImpact](https://docs.k6.io/docs). A simple tutorial with code samples can be found [here](https://github.com/muratkeremozcan/k6-loadImpact).

### References
[Google Testing Blog: Where do our flaky tests come from](https://testing.googleblog.com/2017/04/where-do-our-flaky-tests-come-from.html)



================================================
FILE: sections/advanced/test-flake.zh.md
================================================
# 不稳定的测试

<br/><br/>

## 一段简要说明

每次测试都必须产生一致的结果，而可重复的流水线执行结果则是至关重要的。如果测试无法产生可靠的结果，将降低对测试的信心，还需要进行维护，这将降低所有价值。在这些情况下，最好进行手动功能测试。

并请自问以下几个问题：

- 如何解决测试波动，通过成长的过程确保测试的可信度？
- 如何处理流水线、基础设施、共享资源等方面的假阴性，并在没有控制的情况下解决？
- 如何发现零星缺陷？

<br/><br/>

## 第一步：本地识别不稳定的测试

推荐在模拟流水线 CI 机器的操作系统中进行无头模式执行；Linux 和 MacOS 与流水线的行为更为相似，而 Windows 则是个例外，除非你正在使用 Windows Docker 容器。无头执行将更容易暴露测试波动。有多种方法可以重复执行测试规范，Cypress 提供的一个例子是使用 Lodash 库（Cypress 已经内置了）`Cypress._.times( <重复次数>, () => { <你的测试规范代码> })`。在提交代码合并请求之前，务必使用此方法。

### 第一步的代码示例

```JavaScript
// will repeat the full suite 10 times
Cypress._.times( 10, function {

  describe('..', function () {

    before(function () {
    });

    beforeEach(function () {
    });

      // you can place it anywhere to repeat 1 test, or another describe / context block
      Cypress._.times( 3, function {
        it('..', function () {..});
      }
      it('..', function () {..});
      it('..', function () {..});
      it('..', function () {..});

  });
});

// this will result in 6 tests per run x 10 runs = 60 executions

```

<br/>

## 第二步：在流水线中识别不稳定的测试并进行重试

在初始的流水线顺利通过并合并代码后，**有时**测试会出现失败的情况。

为什么测试在**没有可重现的缺陷**且**测试代码已经完全优化的情况下仍然失败呢**？

为了解决这种零星的失败问题，以及避免测试被忽略或**降低团队对其的信心**，我们可以采用重试机制：

- 用以解决团队无法掌控的不可靠流水线基础设施问题
- 在开发中遇到的问题，或者依赖于正在开发中的外部服务
- 最为重要的是，**用于锁定零星的系统问题**

### 第二步的代码示例

许多框架都提供了重试实用工具。下面是一个例子来自于 [Cypress 文档](https://docs.cypress.io/guides/references/migration-guide.html#Tests-retries):

在一个测试中：

```javascript
it('allows user to login', { // can also be in a context or describe block
  retries: {
    runMode: 2, // for CI usage
    openMode: 1  // for local usage
  }
}, () => {
  // ...
})
```

在配置文件中，例如 `cypress.json`:

```json
{
  "retries": {
    "runMode": 1,
    "openMode": 3
  }
}



```

## 第三步：识别零星的系统问题 - *不稳定的系统*

鉴于以下情况：

- 不存在可重现的缺陷
- 测试代码已经充分优化
- 已知并通过测试重试有效解决了流水线问题
- 已知、认可并通过测试重试解决了外部依赖和成长痛苦

... 我们如何检测系统存在的更深层次问题，这可能表明存在*不稳定的系统*？以下是团队[Cypress 仪表板](https://www.cypress.io/dashboard/)上的一个示例快照：

>*“在周末的 40 次执行中，它以 10% 的错误率失败... 我们运行了测试套件 40 次，在其中的一次执行中看到该规范重试了 2 次，直到通过...”*

![ ](/assets/images/test-retry-pipeline.png)

*请注意：相机图标表示一些测试失败，因为 Cypress 在失败时会拍摄视频和截图。*

在这些情况下，可以通过每晚或周末的 [cron 任务](https://crontab.guru/#0_1-23_*_*_6-7) 进行一致性测试，作为更深层次系统问题的初始指标。这些通常是那些容易泄漏到生产环境中、在实际使用中被发现并具有昂贵后果的模糊缺陷。

### 代码示例 - [cron 任务](https://crontab.guru/#0_1-23_*_*_6-7)

```cron syntax
at minute 0 at midnight and 2 am, every day-of-week from Monday through Friday:

0 0,2 * * 1-5


At minute 0 past hour 2, 6, 8, 10, 12, 14, 16, 18, and 20 on every day-of-week from Saturday through Sunday:

0 2,6,8,10,12,14,16,18,20 * * 6-7
```

一旦排除了所有其他因素，并且在管道中使用 cron 任务自动化测试初步指示了“系统波动”，这些问题就是**性能测试**的理想候选项，因为这种测试方法可以直接指出可能导致“不稳定的系统”的系统缺陷。

性能测试的要点如下：
![ ](../../assets/images/performanceTesting.jpg)

有许多性能测试工具，其中一个我们认为比较易于使用的是 [k6-loadImpact](https://docs.k6.io/docs)，因为它采用了 ES6 语法，并且与流水线兼容。
你可以在 [这里](https://github.com/muratkeremozcan/k6-loadImpact) 找到一个包含代码示例的简单教程。

## 参考资料

[Google 测试博客：我们的测试中哪些是不稳定的，是从哪些方面产生的](https://testing.googleblog.com/2017/04/where-do-our-flaky-tests-come-from.html)



================================================
FILE: sections/advanced/test-states.md
================================================
# Test States

<br/><br/>

### One Paragraph Explainer

Tests should be repeatable, modular and should handle their own state setup. UI Tests should not be repeated in order to achieve state for another test.

We want to have stateless that can scale:

* Tests that independently handle their state.
* Have no side effects outside themselves, or manageable side effects which the test handles itself
* Tests that can be executed by *n* number of entities simultaneously.

<br/><br/>

### Code Example – explanation

**Repeatability**: tests must setup state, perform the test, and leave the environment in a clean state which does not affect the execution of the next test. If a test clutters the system in every execution, leaves it in a state that cannot be reset, this is a manual test candidate. Tests must also not clash with each other: multiple testers and pipelines must be able to execute the same test at the same time. If this is not possible, these groups of tests should be executed once a day in a pipeline [cron job](https://crontab.guru/#0_1-23_*_*_6-7), preferably outside of business hours.

Each test that must change the state of the environment has to be used as a setup-state-test and must ensure that the test environment is  able to be cleaned up before the next test.

It is preferred that UI tests do not repeat themselves as setup tests; API tests, Application Actions or DB seeding should be utilized wherever a UI test has to be used as a setup for another test.

**Setup vs Cleanup**: Setup (before all) is preferred over Cleanup (after all). Wherever possible, the test itself should take responsibility that it starts in a clean environment. However, as emphasized above, tests must not make it so that after their execution the next test cannot clean up the environment.

**Login**: Varieties of UI-login should only be used in their singular test cases. Any other tests that require login should use intrinsic API login and/or have a pre-configured test user.

**Test state setup**: It is encouraged that tests are isolated so that they do not rely on an entire setup before they can be executed. Example: if a group of tests may need a user to be created, a test user can be utilized to use these tests in isolation. On the other hand, the tests that setup the user should be independent and isolated.

**Modularity**: each test should be able to be run by itself, not relying on other tests to set up state for it. If this setup is required, it should be handled in beforeAll or beforeEach sections. A good way to test this is to run the test in isolation: `it.only()` , `fit()`, etc.).

```JavaScript
describe('..', function () {

  // setup (before/beforeEach) is preferred over cleanup (after/afterEach)

  before(function () {
    // login with UI once in an isolated test
    // for login here and all other tests, use a faster login method: use API, App Actions or DB seeding
  });

  beforeEach(function () {
    // setup additional state...
    // have one UI test to ensure this state can be achieved
    // however for the state set up here, utilize API, Application Actions or DB seeding; do not repeat UI tests
  });

    // test each test once with .only to ensure modularity
    it('..', function () {..});
    it('..', function () {..});
    it.only('..', function () {..});
    it('..', function () {..});

});

```

<br/><br/>

### References
[Stop using Page Objects and Start using App Actions](https://www.cypress.io/blog/2019/01/03/stop-using-page-objects-and-start-using-app-actions/)

[Cypress Docs: Organizing Tests, Logging In, Controlling State](https://docs.cypress.io/guides/references/best-practices.html#Organizing-Tests-Logging-In-Controlling-State)



================================================
FILE: sections/advanced/test-states.zh.md
================================================
# 测试状态

<br/><br/>

## 一段简要说明

测试应该是可重复的、模块化的，并且应该自己处理状态设置。为了为其他测试实现状态，不应该重复执行 UI 测试。

我们希望测试是无状态的，具有可扩展性：

- 测试应该独立处理其状态。
- 没有对外部产生不受控制的副作用，或者具有测试自身能够处理的可管理副作用。
- 测试应该能够被 *n* 个实体同时执行。

<br/><br/>

## 代码示例 – 解释说明

**可重复性**: 测试必须能够设置状态、执行测试，并在不影响下一个测试执行的前提下使环境保持干净。如果一个测试在每次执行时都使系统混乱，将其留在无法重置的状态，那么这个测试就适合作为手动测试。测试还不能互相冲突：多个测试者和流水线必须能够同时执行相同的测试。如果这不可行，这些测试组应该每天在流水线中执行一次，最好在非工作时间执行 [cron 作业](https://crontab.guru/#0_1-23_*_*_6-7)。

每个需要更改环境状态的测试都必须被用作设置 - 状态 - 测试，并确保在下一个测试之前能够清理测试环境。

最好是 UI 测试不要重复作为设置测试；在必须将 UI 测试用作另一个测试的设置的情况下，应该使用 API 测试、应用程序操作或数据库初始化。

**设置 vs 清理**: 设置（之前全部）优于清理（之后全部）。在可能的情况下，测试本身应该负责在一个干净的环境中开始。然而，正如上面强调的，测试不能使得在它们执行后下一个测试无法清理环境。

**登录**: UI 登录的各种形式应仅在其各自的测试用例中使用。任何其他需要登录的测试应该使用内部的 API 登录和/或具有预配置的测试用户。

**测试状态设置**: 鼓励测试是隔离的，以便它们在执行之前不依赖于整个设置。例如：如果一组测试可能需要创建用户，可以利用一个测试用户在隔离中使用这些测试。另一方面，设置用户的测试应该是独立的和隔离的。

**模块化**: 每个测试应该能够独立运行，不依赖于其他测试来为其设置状态。如果需要进行这样的设置，应该在 `beforeAll` 或 `beforeEach` 部分进行。测试这一点的一个好方法是在隔离中运行测试：`it.only()`，`fit()`，等等。

```JavaScript
describe('..', function () {

  // setup (before/beforeEach) is preferred over cleanup (after/afterEach)

  before(function () {
    // login with UI once in an isolated test
    // for login here and all other tests, use a faster login method: use API, App Actions or DB seeding
  });

  beforeEach(function () {
    // setup additional state...
    // have one UI test to ensure this state can be achieved
    // however for the state set up here, utilize API, Application Actions or DB seeding; do not repeat UI tests
  });

    // test each test once with .only to ensure modularity
    it('..', function () {..});
    it('..', function () {..});
    it.only('..', function () {..});
    it('..', function () {..});

});

```

<br/><br/>

## 参考资料

[放弃使用页面对象，转而使用应用动作](https://www.cypress.io/blog/2019/01/03/stop-using-page-objects-and-start-using-app-actions/)

[Cypress 文档：测试组织、登录、状态控制](https://docs.cypress.io/guides/references/best-practices.html#Organizing-Tests-Logging-In-Controlling-State)



================================================
FILE: sections/beginners/top-to-bottom-approach.md
================================================
# Approach the testing pyramid from the top!

<br/>

### One Paragraph Explainer

When you are an experienced tester, approaching a test suite is an easy road.
But learning how to test properly, what to test and what to avoid, which kind of
tests choosing etc. is not so easy.

**Testing is expensive at the beginning**. Everything is new, the examples you
try to implement do not work, you do not understand clearly why the tests fail,
how it’s related to your code, etc.

We all know the Testing Pyramid and commonly, we approach it from the bottom

![Bottom to top approach means starting with the Unit Tests.](../../assets/images/top-to-bottom-approach/bottom-to-top-approach.jpg)
_The standard Testing Pyramid approach: bottom to top._

Approaching the pyramid from the bottom makes sense. Starting with the Unit
Tests is easier because they're fast, they do not require complex contexts or
tools, a "unit" (whatever you mean with "unit": a function, a component, etc.)
contains just a few lines of code and usually it has a few dependencies (or not
at all), etc.

What's the biggest **downside of this approach**? Essentially, its
**confidence**.

Testing is all about confidence and the tradeoff between high-confidence, yet
slow, tests and low-confidence, yet fast, tests.

If you're new to the testing field the term "confidence" could not be clear in
your mind, so: how can you be sure that the **application** you're working on
**works if the tests pass**? This is the **testing confidence**.

Why the Unit Tests give so little confidence? Some examples:

- if the `isValidEmail` function passes the tests, are you sure that the
  registration form of your front-end application works?
- if the `Input` React component passes the tests, are you sure that the
  registration form works too?
- if the whole `RegisterForm` component passes the tests, are you sure that the
  user can register?

The answer is No. A whole application is made of a lot of units integrated each
other, without counting some presentational (CSS) problems that could prevent
the user from registering because of an image with a higherz-index that covers
the submit button.

Speaking again about the missing experience of testing newbies (like I was, two
years ago): **everything new requires a big cognitive load** and you cannot face
too much new stuff at the same time. It's hard to face the usual development of
your app, the new Testing topic, the Unit Tests world and the UI tests one (the
latter two require different tools and efforts).

Take a look at this exhaustive image from the
[JavaScript & Node.js testing best practices](https://github.com/goldbergyoni/javascript-testing-best-practices)
project:

![Mental and time capacity is mainly dedicated to the development phase, a few of them can be dedicated to writing tests.](../../assets/images/top-to-bottom-approach/headspace.jpg)
_Courtesy of [Yoni Goldberg](https://goldbergyoni.com/), visit
[testjavascript.com](https://testjavascript.com/) and add a star to the
[JavaScript & Node.js testing best practices](https://github.com/goldbergyoni/javascript-testing-best-practices)
repository._

This is true for experienced developers, and when you first approach the testing
world things are worse.

## Bottom to top approach results

You inevitably put the most of your attention to the base of the pyramid, the
Unit Tests. The bunch of tests you are going to write allow you becoming
familiar with the testing world, but without confidence. You could find yourself
asking

- "What is the advantage of the tests I wrote?"
- "I spent some time fighting with Unit Tests, but the application breaks like
  before, do the tests end with themselves?"
- "Honestly, I've more doubts now than before starting with tests…"

![The Testing Pyramid with every kind of tests highlighted with the attention you dedicate them with a bottom to top approach.](../../assets/images/top-to-bottom-approach/unit-testing-first.jpg)
_The bottom to top approach inevitably makes you concentrate on the Unit Tests._

The problem is not with you but with the wrong kind of tests for a beginner!

What's my suggested solution? **Starting from the top and concentrating on UI
tests firstly!**

First of all, what's a UI Test (also called Functional Test, E2E Test, etc.)?
It's essentially a script that opens a real browser and interacts with the DOM
elements, the same way the real end-user does. Some videos could tell more than
hundreds of words: take a look at [an E2E test running against
Conduit - the RealWorld project](https://www.youtube.com/watch?v=gdly-oU72X0&feature=youtu.be) and [some UI tests of the Conio Backoffice](https://www.youtube.com/watch?v=lNEMKeTYEPI&feature=youtu.be).

In the above videos, you can see a real browser that loads the whole front-end
application and interacts with it. The pros are:

- your application is tested in the same context of the end-user (the browser),
  which means **higher confidence**. Even if you write just one UI Test, it
  gives you more confidence that a hundred Unit Tests
- the path under test (the steps the user does, like "registering", "creating a
  new post", etc.) is the same that the end-user must perform, that means
  **lower cognitive load** (for you) to understand what you are really testing
- honestly, you have more fun automating a browser than automating the terminal
  😁
- **UI Testing best fits** the little-to-medium size of most of **the projects
  you work on a daily basis**. From a landing page to a little CMS: all of them
  require at least some UI tests, yet you could overfly on the Unit Tests based
  on the testing confidence and the deliveries you have to respect. Just a few
  of you work at Facebook, Spotify, Netflix, etc., products that require strict
  testing strategies, code coverage requisites, etc. More in general: if you
  work for medium-to-large product companies, you probably do not need this post
  because Testing is at the core of your company's culture 🎉

There are cons too, but I'm going to list them later. That's the approach I
suggest:

![Starting from the top of the testing pyramid allows you to concentrate on UI tests firstly.](../../assets/images/top-to-bottom-approach/ui-testing-first.jpg)
_A top to bottom approach._

### Does the top to bottom approach enforce testing bad practices?

This post is not about best or bad practices (take a look at the end of the post
for a long list of resources), this post is about engaging new front-end
developers profitably in the testing world. My goal is to provide a more
practical approach, an approach that allows the developer to **enjoy the testing
advantages** and do not leave him with more doubts than before.

### If UI Testing is so magical, why other kinds of tests exist?

That's the point! And please, note that I'm not against Unit Testing! Every kind
of test is important and **different tests provide different feedback**! A
developer that approaches the pyramid from the top is enough happy to love the
whole testing world.

Then, you are going to discover the limitations of the high-level **UI tests**:

- they **are slow**: I know that the above videos give you the idea that they're
  super fast but they are not. They are fast when you have five, ten, twenty of
  them, but when you have hundreds of UI tests and they need minutes, you start
  asking yourself how you can improve the situation
- they give you mostly **high-level feedback**: if the submit button of the form
  does not work, what's the bug? There are a ton of possible causes but the UI
  Test does not allow to exclude some of them
- they render the whole app and it could be cumbersome if you just want to test
  something smaller. Some corner cases that you need to test are not replicable
  at all through the whole app

The solution to all the above problems is: **going down with the Testing
Pyramid**! And if you reach the need for lower tests, well done! It's the goal
of this post!

Consider the result of both approaches:

- bottom to top: **you have doubts** about the usefulness of the unit tests you
  write and you do not understand how these tests could help you improve the
  testing confidence
- top to bottom: you have a **few, confident, tests** and you end up with the
  need to get down the Testing Pyramid. And if you do not need to get it down,
  it means that your project is small and it does not need any more tests

Then, start from the [root of this project](../../README.md) and explore the various best practices to follow to start with UI Testing successfully since the very beginning.



================================================
FILE: sections/beginners/top-to-bottom-approach.zh.md
================================================
[Binary file]


================================================
FILE: sections/generic-best-practices/await-dont-sleep.md
================================================
# Await, don't sleep

<br/><br/>

### One Paragraph Explainer

When testing your UI, you define a sort of key points the app must pass through. Reaching these key
points is an asynchronous process because, almost 100% of the times, your UI does not update
synchronously.

Those key points are called **deterministic events**, as known as something that you know that must happen.

It depends on the events you define and how your UI reaches them but, usually, there are some
"long" waitings, like XHR requests, and some faster ones, like re-render updates.

The solution to the asynchronous updates seems handy: **sleeping/pausing the test** for a bunch of
milliseconds, tenths of a second, or even seconds. It can make your test working because it gives
the app the time to update itself and moving to the next deterministic event to be tested.

Consider that, except for specific and known waitings (like when you use `setInterval` or
`setTimeout`), **it's totally unpredictable** how much the sleeping time should be because it could depend on:

- the network state (for XHR requests)
- the total amount of available machine resources (CPU, RAM, etc.)
  - a CI pipeline can limit them for example
  - other apps can consume them on your local machine too
- the concurrence of other resource-consuming updates (canvas, etc.)
- a bunch of unpredictable game players like Service Workers, cache management etc. that can make
  the UI update process faster or slower

Every fixed delay leads your test to be more brittle and **increasing its duration**. You are going to
find a balance between false negatives—when the test fails because of a too low sleeping
time—and exaggerate test duration.

What about waiting just the right amount of time? The amount of time that makes the test as fast as
possible!

Waitings fall in four main categories

- **[page load waitings](#page-load-waitings)**: the first waiting to manage while testing your app, waiting for an event that
  allows you to understand that the page is interactive
- **[content waitings](#content-waitings)**: waiting for DOM element that matches a selector
- **[XHR request waitings](#xhr-request-waitings)**: waiting for an XHR request start or the corresponding response received

All the following examples are based on Cypress.

<br/><br/>

## Page load waitings

```javascript
// Cypress code
cy.visit('http://localhost:3000')
```

## Content waitings

Take a look at the following examples to see how waiting for a DOM element could be implemented in
the available tools.

### Code Examples

- waiting for an element:

```javascript
// Cypress code

// it waits up to 4 seconds by default
cy.get('#form-feedback')
// the timeout can be customized
cy.get('#form-feedback', { timeout: 5000 })
```

- waiting for an element with specific content

```javascript
// Cypress code

cy.get('#form-feedback').contains('Success')
```

## XHR request waitings

### Code Examples

- waiting for an XHR request/response

```javascript
// Cypress code

cy.intercept('http://dummy.restapiexample.com/api/v1/employees').as('employees')
cy.wait('@employees')
  .its('response.body')
  .then((body) => {
    /* ... */
  })
```

<br /><br />

_Crossposted by [NoriSte](https://github.com/NoriSte) on [dev.to](https://dev.to/noriste/await-do-not-make-your-e2e-tests-sleep-4g1o) and [Medium](https://medium.com/@NoriSte/react-hooks-memorandum-bf1c2758a672)._



================================================
FILE: sections/generic-best-practices/await-dont-sleep.zh.md
================================================
[Binary file]


================================================
FILE: sections/generic-best-practices/name-test-files-wisely.md
================================================
# Name the test files wisely

<br/><br/>

### One Paragraph Explainer

You can write a lot of different UI tests and it's a good habit to have a common way of naming the
test files.

It's useful because often you need to run just a type of tests, the situations could be:
- during the development process, you need to run just some of them
  - you're changing some related components and you need to check that the generated markup does not change
  - you're changing a global CSS rule and you need to run only the visual tests
  - you're changing an app flow and you need to run the whole app integration tests
- your DevOps colleague needs to be sure that everything is up and running and the easiest way to do
  that is launching just the E2E tests
- your building pipeline needs to run just the integration and E2E tests
- your monitoring pipeline needs a script to launch the E2E and monitoring tests

If you name your tests wisely, it will be really easy to launch just some kind of them.

Cypress:
```bash
cypress run --spec \"cypress/integration/**/*.e2e.*\"
```

Jest:
```bash
jest --testPathPattern=e2e\\.*$
```

<br>

A global way to name the test files does not exist, a suggestion could be to name them with:
- the subject you are testing
- the kind of test (`integration`, `e2e`, `monitoring`, `component`, etc.)
- the test suffix of choice (`test`, `spec`, etc.)
- the file extension (`.js`, `.ts`, `.jsx`, `.tsx`, etc.)

all of them separated by a period.

Some examples could be
- `authentication.e2e.test.ts`
- `authentication.integration.test.ts`
- `site.monitoring.test.js`
- `login.component.test.tsx`
etc.



================================================
FILE: sections/generic-best-practices/name-test-files-wisely.zh.md
================================================
# 明智地为测试文件命名

<br/><br/>

## 一段简要说明

编写各种不同的 UI 测试是一种好习惯，而采用一种常见的测试文件命名方式更是有益的。

这很有用，因为通常情况下，你需要仅运行某一类测试，可能的情况包括：

- 在开发过程中，你只需要运行其中一些测试
  - 你正在更改一些相关组件，并需要检查生成的标记是否发生了变化
  - 你正在更改全局 CSS 规则，只需运行视觉测试
  - 你正在更改应用程序流程，需要运行整个应用程序集成测试
- 你的 DevOps 同事需要确保一切正常运行，最简单的方法就是只运行端对端测试
- 你的构建流水线需要运行集成测试和端对端测试
- 你的监控流水线需要一个脚本来运行端对端测试和监控测试

如果你为测试取一个明智的命名，将会非常容易只运行其中的某些类型。

Cypress:

```bash
cypress run --spec \"cypress/integration/**/*.e2e.*\"
```

Jest:

```bash
jest --testPathPattern=e2e\\.*$
```

<br>

没有一种全局的命名测试文件的方式，一个建议是使用以下方式命名：

- 正在测试的主题
- 测试的类型（`integration`、`e2e`、`monitoring`、`component`等）
- 选择的测试后缀（`test`、`spec`等）
- 文件扩展名（`.js`、`.ts`、`.jsx`、`.tsx`等）

它们之间用句点分隔。

以下是一些例子：

- `authentication.e2e.test.ts`
- `authentication.integration.test.ts`
- `site.monitoring.test.js`
- `login.component.test.tsx`
等等。



================================================
FILE: sections/generic-best-practices/reaching-ui-state.md
================================================
# Reaching UI state for tests without using the UI

<br/><br/>

### One Paragraph Explainer

It adds value to cover a UI scenario *once*, and it provides little value to duplicate any parts of it in other tests; tests which may require a relevant state of the system. Suppose in a new test you require a state, and that state -partially or in full- duplicates testing from a UI test. Scenarios like this are excellent for utilizing certain techniques:

* Direct navigation
* Network stub record & play
* Application actions
* Seeding the database

> Disclaimer: applications of the whole package of these techniques are only possible in Cypress (as far as we know), consequently the code samples below are are in Cypress context.

<br/><br/>

### Direct navigation

This is the easiest technique and is applicable in any framework. Suppose the intent of the test is concerned with a certain page in your application. Instead of click navigating, directly visit the URL. Upon landing you can either wait for a UI element (any test framework) or network calls (some test frameworks), or both.

```javascript
// Test A covers click-navigation to a certain page.
// This is Test B, and navigating to that page is the prerequisite step.

// assuming baseUrl is set in cypress.json or config file
// directly navigate to the page.
cy.visit('/endpoint');

// to ensure stability, wait for network (preferred), ui elements, or both

// note: checking the endpoint you are at is entirely optional, only for sanity that you are at the right page
cy.url().should('contain', 'endpoint');
// cy.url().should('match', /endpoint/); // there are many, some more complex, ways of doing it


// network wait: this is in addition to the sanity url check, and it is more important
// because you want the page to "settle" before you start running assertions on it

// usually a GET request. Is aliased so we can wait for it.
cy.intercept('some-xhr-call-that-happens-upon-landing').as('crutcXHR');
// The default Cypress timeout is 4 seconds. 15 seconds here is arbitrary.
// Most pages load faster, but if you need more time then increase the timeout.
// The only caveat to increasing timeout is that the tests will take longer to fail, but still run as fast as possible when things work.
cy.wait('@crutchXHR', {timeout: 15000});

// ui-element wait is straightforward, and may be optional, as well as less stable)
cy.get('element-on-page').should('exist').and('be.visible');

```

#### Pro vs Con

Pro: not having to click-navigate saves time in tests and saves effort in test maintenance.

Con: this technique ignores the user E2E way of clicking through the application. Make sure you have at least one workflow in any other test that covers the same workflow of click-navigation to ensure that click-navigation functionality is regression-proof. Usually click-navigation could be a test of its own; and when setting up state in other tests, you do not repeat the UI-test that is already covered elsewhere. The thought pattern is analogous to login; if you do UI-login in one test, in the others you can implement programmatic login which is both fast and cost effective.

<br/><br/>

### Application actions

Cypress gives you complete control of your application. You can bypass the page object abstraction layer (which is detached from your application), access the UI directly via `cy.get()`, have access to the API, database, and even access the source code.

Application actions are shortcuts that allow you to access internal utilities in order to save time. A simple example could be a `cy.signup()` custom command that goes to the registration form and invokes the callback of the registration form instead of filling the form and clicking the registration button.

Here is a quick example of how you would allow source code access to Cypress in an Angular application.
```javascript
// Angular Component file example
/* setup:
 1. Identify the component in the DOM;
  inspect and find the corresponding <app.. tag,

 2. Right in the constructor of your component, insert conditional */
constructor(
  /* ... */
) {
  /* if running inside Cypress tests, set the component
  may need // @ts-ignore initially */
  if (window.Cypress) {
    window.yourComponent = this;
  }
}

// at ../../support/app-actions.ts helper file:

/** yields  window.yourComponent */
export const yourComponent = () =>
  cy.window().should('have.property', 'yourComponent');

/** yields the data property on your component */
export const getSomeListData = () =>
 yourComponent().should('have.property', 'data');
```
After this at DevTools see what that component allows for properties, or in the component code see what functions you can .invoke()

Check out [the presentation slide](https://cypress.slides.com/cypress-io/siemens-case-study#/12/3/4) for a code sample utilizing app actions with visual testing.

#### Another example on app actions utilizing states, using [Building Operator](https://new.siemens.com/us/en/products/buildingtechnologies/automation/talon/software/building-operator.html?stc=ussi100451&sp_source=ussi100451&&s_kwcid=AL!464!3!435315652461!b!!g!!%2Bbuilding%20%2Boperator&ef_id=CjwKCAjw8df2BRA3EiwAvfZWaAsQmgot5Ph-nGBB8rW1QLLr870q2HW-qzMKhqtQb1QvlPBVJxho5BoCmtMQAvD_BwE:G:s) building control product of Siemens.

In the below state diagram there are 3 states. We begin where both left and right panes exist. If the right pane is deleted (delete point / red flow), only the left pane exists. If the left pane is deleted (delete device - blue flow), both panes go away and the UI is redirected.

![deleting building points and controllers](../../assets/images/ui-state/delete-states.PNG)

Testing the UI, you might chose to delete the right pane (red flow) and then in another test you might choose to delete the left pane (blue flow). This leaves out 1 final path through the state diagram where right pane and then left pane are deleted one at a time.

We already covered deleting the right pane in a UI test (red path). Why not avoid repeating this test and utilize app actions, getting access to the delete function in the source code and using `cy.invoke()` to call it?

```javascript
it('Component test: delete right pane and then left', () => {
  /* tests a SEQUENCE not covered with UI tests
   * tests a COMBINATION of components */
  appAction.deleteRightPane();
  cy.window().should('not.have.property', 'rightPaneComponent');
  cy.window().should('have.property', 'leftPaneComponent');

  appAction.deleteLeftPane();
  cy.window().should('not.have.property', 'leftPaneComponent');
  cy.window().should('not.have.property', 'rightPaneComponent');
  cy.url().should('match', redirectRoute);
});
```

#### Pro vs Con

Using applications actions / having component access is fast! The tests are less prone to changes. Generally this is the benefit of testing at lower level. Alas, it can get addictive to engineers and testing the user interface starts getting neglected; the pro can become a con.

There are a few counter arguments against application it. Developers may be opinionated that Cypress' access to the source code isn't ideal. There is a not a counter argument to this until Cypress has official component testing support.

The real power of application actions comes out when combining application actions with other techniques; not duplicating the UI workflow to setup a state, combining component testing with visual testing, combining component testing with network manipulation are where this approach shines.


<br/><br/>


### Network stub record & play
This is an advanced technique that strongly relates to UI-integration tests. Recall UI-integration references [1](../testing-strategy/component-vs-integration-vs-e2e-testing.md), [2](../real-life-examples/test-front-end-with-integration-back-end-with-e2e.md).

Cypress allows you to stub all network traffic. We can record the network data from an endpoint, and stub that response every time the UI makes a call to an arbitrary server.

Start by copying the network data from devTools to a json file. Place it in `cypress/fixtures` folder. This folder is made for this purpose, and any reference to it will default to the root of the folder.

![devtools > network tab](../../assets/images/ui-state/devtools-network.PNG)

```javascript
// prerequisite: the data has been copied to a file `cypress/fixtures/agents.json`

// this is a shorthand for cy.fixture(). More at https://docs.cypress.io/api/commands/fixture.html#Accessing-Fixture-Data
cy.intercept('some-xhr-call-that-happens-upon-landing', { fixture: 'agents.json'} ).as('crutcXHR');
// all calls to the network route will be stubbed by the data in agents.json file
```

#### What if there are so many network requests happening?
Where do we get all our mocks for fixtures? We do not want to manually copy and save them. We want to record them as the test runs against a real API

There are at least 2 Cypress plugins you can utilize for this [1](https://github.com/Nanciee/cypress-autorecord) & [2](https://github.com/scottschafer/cypressautomocker).

If these do not work for you, you can easily create record and playback utilities yourself with these 3 functions.

```javascript
function stubRecorder(pathToJson) {
  const xhrData = []; // an empty array to hold the data
  cy.server({ // if recording, save the response data in the array
    onResponse: (response) => {
      const url = response.url;
      const method = response.method;
      const data = response.response.body;
      // We push a new entry into the xhrData array
      xhrData.push({ url, method, data });
    }
  });

  // cy.intercept() specification below is used as a selector for the data you want to record.
  // In this example, all GET requests from any url will be selected
  // You can specify the methods and routes that are recorded
  cy.log('recording!');
  cy.intercept({
    method: 'GET',
    url: '*',
  });

  // if recording, after the test runs, create a fixture file with the recorded data
  after(function () {
    cy.writeFile(`./cypress/fixtures/${pathToJson}.json`, xhrData);
    cy.log(`Wrote ${xhrData.length} XHR responses to local file ${pathToJson}.json`);
  });
}

/** Plays recorded fixture with all required network data as json*/
function playStubbedFixture(stateFixture) {
  cy.log(`playing fixture from ${stateFixture}`);
  cy.fixture(stateFixture, { timeout: 15000 }) // the fixture file may be large and take time in CI
    .each(({method, url, data}) => {
      cy.intercept(method, url, data);
    }).as(`stateFixture_stub`);
}

/** Visits the stubbed state */
function visitStubbedState(stubFile, url, wait: boolean = true) {
  playStubbedFixture(stubFile);
  cy.visit(url);
  if (wait) { // sometimes you do not want to wait for network, this gives you the option
    cy.wait('@stateFixture_stub', { timeout: 15000 });
  }
}

//////////
// usage

// recording network
it('should run your test', function () {
  stubrecorder('jsonfileNameForNetworkData');

  // your original test

  cy.wait(5000); // one-time wait so that the after() step records all the network without missing anything

  // the rest of your original test
});

// playing the stubbed network
it('should run your test', function () {
  // every time we visit this endpoint, all network will be stubbed
  // double check this by observing (XHR stubbed) network responses in the test runner
  visitStubbedState('jsonfileNameForNetworkData', '/endpoint');

  // the rest of your original test
});
```

#### Pro vs Con

UI integration tests are the bread and butter of UI testing. They run the whole app in a real browser without hitting a real server. They are blazing fast and less exposed to random failures in the network or false negatives.

The engineers have to realize that the strength can be a curse if misused. The UI application is isolated, but network failures, if there are any, are ignored. It is great for feature branch testing, but in further deployments one should ensure that the back-end is also operational. Refer to [test-front-end-with-integration-back-end-with-e2e](../real-life-examples/test-front-end-with-integration-back-end-with-e2e.md) for when to use which technique.

<br/><br/>


### Seeding the database

Cypress [`cy.task()`](https://docs.cypress.io/api/commands/task.html#Requirements) is very powerful. Effectively, it allows you to use NodeJs within the context of Cypress. This can be anything from NodeJs code, to using an npm package to manipulating the database. If you use Node.js for your app, you can re-use your app code to help set up and manipulate data for your tests.

There is a [Cypress recipe](https://github.com/cypress-io/cypress-example-recipes/tree/master/examples/server-communication__seeding-database-in-node) on this topic and we will end with that reference.


## Related chapters

- 🔗 [From unreadable React Component Tests to simple, stupid ones](/sections/real-life-examples/from-unreadable-react-component-tests-to-simple-ones.md)



================================================
FILE: sections/generic-best-practices/reaching-ui-state.zh.md
================================================
# 在测试中达到 UI 状态而无需使用 UI

<br/><br/>

## 一段简要说明

在 UI 场景中覆盖一次是有价值的，而在其他测试中复制其中任何部分提供的价值很小；这些测试可能需要系统的相关状态。假设在一个新测试中，你需要一种状态，而那种状态 - 部分或全部 - 与 UI 测试中的某些部分重复。在这种情况下，可以考虑以下几种技术：

* 直接导航
* 网络存根记录和播放
* 应用程序动作
* 数据库种子

> 免责声明：整个技术包的应用仅在 Cypress 中可能（据我们所知），因此以下代码示例是在 Cypress 上下文中。

<br/><br/>

## 直接导航

这是最简单的技术，适用于任何框架。假设测试的意图与你的应用程序中的某个页面有关。与其进行点击导航，直接访问 URL。一旦到达，你可以等待 UI 元素（任何测试框架）或网络调用（一些测试框架），或两者兼而有之。

```javascript
// Test A covers click-navigation to a certain page.
// This is Test B, and navigating to that page is the prerequisite step.

// assuming baseUrl is set in cypress.json or config file
// directly navigate to the page.
cy.visit('/endpoint');

// to ensure stability, wait for network (preferred), ui elements, or both

// note: checking the endpoint you are at is entirely optional, only for sanity that you are at the right page
cy.url().should('contain', 'endpoint');
// cy.url().should('match', /endpoint/); // there are many, some more complex, ways of doing it


// network wait: this is in addition to the sanity url check, and it is more important
// because you want the page to "settle" before you start running assertions on it

// usually a GET request. Is aliased so we can wait for it.
cy.intercept('some-xhr-call-that-happens-upon-landing').as('crutcXHR');
// The default Cypress timeout is 4 seconds. 15 seconds here is arbitrary.
// Most pages load faster, but if you need more time then increase the timeout.
// The only caveat to increasing timeout is that the tests will take longer to fail, but still run as fast as possible when things work.
cy.wait('@crutchXHR', {timeout: 15000});

// ui-element wait is straightforward, and may be optional, as well as less stable)
cy.get('element-on-page').should('exist').and('be.visible');

```

### 直接导航的优缺点

优点：不进行点击导航可以节省测试时间，并减少测试维护的工作量。

缺点：这种技术忽略了用户通过应用程序的端到端点击方式。确保在其他测试中至少有一个工作流程覆盖与点击导航相同的工作流程，以确保点击导航功能不会出现回归问题。通常，点击导航可以成为一个独立的测试；在设置其他测试的状态时，不要重复已经在其他地方覆盖的 UI 测试。思考模式类似于登录；如果在一个测试中进行 UI 登录，在其他测试中可以实现程序化登录，这既快速又经济。

<br/><br/>

## 应用程序操作

Cypress 为你提供了对应用程序的完全控制权。你可以绕过页面对象的抽象层（与你的应用程序分离），通过 `cy.get()` 直接访问 UI，还可以访问 API、数据库，甚至可以访问源代码。

应用程序操作是一种快捷方式，允许你访问内部工具以节省时间。一个简单的例子可以是一个 `cy.signup()` 自定义命令，该命令进入注册表单并调用注册表单的回调，而不是填写表单并点击注册按钮。

以下是一个快速示例，演示了在 Angular 应用程序中如何允许 Cypress 访问源代码。

```javascript
// Angular Component file example
/* setup:
 1. Identify the component in the DOM;
  inspect and find the corresponding <app.. tag,

 2. Right in the constructor of your component, insert conditional */
constructor(
  /* ... */
) {
  /* if running inside Cypress tests, set the component
  may need // @ts-ignore initially */
  if (window.Cypress) {
    window.yourComponent = this;
  }
}

// at ../../support/app-actions.ts helper file:

/** yields  window.yourComponent */
export const yourComponent = () =>
  cy.window().should('have.property', 'yourComponent');

/** yields the data property on your component */
export const getSomeListData = () =>
 yourComponent().should('have.property', 'data');
```

在这之后，在 DevTools 中查看该组件允许的属性，或者在组件代码中查看你可以使用 `.invoke()` 进行的函数。

可以查看 [演示幻灯片](https://cypress.slides.com/cypress-io/siemens-case-study#/12/3/4) 获取一个使用应用程序操作进行视觉测试的代码示例。

### 另一个应用程序操作的示例，利用状态，使用 Siemens 的 [Building Operator](https://new.siemens.com/us/en/products/buildingtechnologies/automation/talon/software/building-operator.html?stc=ussi100451&sp_source=ussi100451&&s_kwcid=AL!464!3!435315652461!b!!g!!%2Bbuilding%20%2Boperator&ef_id=CjwKCAjw8df2BRA3EiwAvfZWaAsQmgot5Ph-nGBB8rW1QLLr870q2HW-qzMKhqtQb1QvlPBVJxho5BoCmtMQAvD_BwE:G:s) Siemens 的建筑控制产品

在下面的状态图中有 3 个状态。我们从左右两个窗格都存在的地方开始。如果删除右窗格（删除点/红色流），则只剩下左窗格。如果删除左窗格（删除设备 - 蓝色流），两个窗格都消失，并且 UI 被重定向。

![删除建筑点和控制器](../../assets/images/ui-state/delete-states.PNG)

在测试 UI 时，你可能选择删除右窗格（红色流），然后在另一个测试中，你可能选择删除左窗格（蓝色流）。这遗漏了通过状态图的最后一条路径，其中右窗格和左窗格被逐一删除。

我们已经在一个 UI 测试中涵盖了删除右窗格（红色路径）。为什么不避免重复进行此测试，利用应用程序操作，获取源代码中的删除函数，并使用 `cy.invoke()` 调用它呢？

```javascript
it('Component test: delete right pane and then left', () => {
  /* tests a SEQUENCE not covered with UI tests
   * tests a COMBINATION of components */
  appAction.deleteRightPane();
  cy.window().should('not.have.property', 'rightPaneComponent');
  cy.window().should('have.property', 'leftPaneComponent');

  appAction.deleteLeftPane();
  cy.window().should('not.have.property', 'leftPaneComponent');
  cy.window().should('not.have.property', 'rightPaneComponent');
  cy.url().should('match', redirectRoute);
});
```

### 应用程序操作的优缺点

使用应用程序操作/拥有组件访问速度很快！测试不太容易受到变化的影响。一般来说，这是在较低级别进行测试的好处。然而，对于工程师而言，这可能会变得让人上瘾，开始忽视对用户界面的测试；优势可能变成劣势。

有一些反对应用程序的论点。开发人员可能认为 Cypress 对源代码的访问不理想。在 Cypress 具有官方组件测试支持之前，这没有反驳的理由。

应用程序操作的真正威力在于将应用程序操作与其他技术结合使用时显现出来；不重复 UI 工作流程来设置状态，将组件测试与视觉测试结合使用，将组件测试与网络操作结合使用，这些都是这种方法的亮点所在。

<br/><br/>

## 网络存根记录和回放

这是一种与 UI 集成测试密切相关的高级技术。回顾 UI 集成参考 [1](../testing-strategy/component-vs-integration-vs-e2e-testing.zh.md), [2](../real-life-examples/test-front-end-with-integration-back-end-with-e2e.zh.md)。

Cypress 允许你对所有网络流量进行存根。我们可以记录来自一个端点的网络数据，并在 UI 每次调用任意服务器时存根该响应。

首先，从开发者工具复制网络数据到一个 json 文件中。将其放置在 `cypress/fixtures` 文件夹中。这个文件夹专为此目的而创建，对它的任何引用都将默认指向文件夹的根目录。

![开发者工具 > 网络选项卡](../../assets/images/ui-state/devtools-network.PNG)

```javascript
// prerequisite: the data has been copied to a file `cypress/fixtures/agents.json`

// this is a shorthand for cy.fixture(). More at https://docs.cypress.io/api/commands/fixture.html#Accessing-Fixture-Data
cy.intercept('some-xhr-call-that-happens-upon-landing', { fixture: 'agents.json'} ).as('crutcXHR');
// all calls to the network route will be stubbed by the data in agents.json file
```

### 如果有很多网络请求发生怎么办？

我们从哪里获取所有的模拟数据？我们不想手动复制和保存它们。我们希望在测试运行时记录它们，以便与真实的 API 进行比对。

至少有两个 Cypress 插件可以用于这个目的 [1](https://github.com/Nanciee/cypress-autorecord) 和 [2](https://github.com/scottschafer/cypressautomocker)。

如果这些插件不适用于你，你可以轻松使用以下三个函数创建自己的记录和回放工具。

```javascript
function stubRecorder(pathToJson) {
  const xhrData = []; // an empty array to hold the data
  cy.server({ // if recording, save the response data in the array
    onResponse: (response) => {
      const url = response.url;
      const method = response.method;
      const data = response.response.body;
      // We push a new entry into the xhrData array
      xhrData.push({ url, method, data });
    }
  });

  // cy.intercept() specification below is used as a selector for the data you want to record.
  // In this example, all GET requests from any url will be selected
  // You can specify the methods and routes that are recorded
  cy.log('recording!');
  cy.intercept({
    method: 'GET',
    url: '*',
  });

  // if recording, after the test runs, create a fixture file with the recorded data
  after(function () {
    cy.writeFile(`./cypress/fixtures/${pathToJson}.json`, xhrData);
    cy.log(`Wrote ${xhrData.length} XHR responses to local file ${pathToJson}.json`);
  });
}

/** Plays recorded fixture with all required network data as json*/
function playStubbedFixture(stateFixture) {
  cy.log(`playing fixture from ${stateFixture}`);
  cy.fixture(stateFixture, { timeout: 15000 }) // the fixture file may be large and take time in CI
    .each(({method, url, data}) => {
      cy.intercept(method, url, data);
    }).as(`stateFixture_stub`);
}

/** Visits the stubbed state */
function visitStubbedState(stubFile, url, wait: boolean = true) {
  playStubbedFixture(stubFile);
  cy.visit(url);
  if (wait) { // sometimes you do not want to wait for network, this gives you the option
    cy.wait('@stateFixture_stub', { timeout: 15000 });
  }
}

//////////
// usage

// recording network
it('should run your test', function () {
  stubrecorder('jsonfileNameForNetworkData');

  // your original test

  cy.wait(5000); // one-time wait so that the after() step records all the network without missing anything

  // the rest of your original test
});

// playing the stubbed network
it('should run your test', function () {
  // every time we visit this endpoint, all network will be stubbed
  // double check this by observing (XHR stubbed) network responses in the test runner
  visitStubbedState('jsonfileNameForNetworkData', '/endpoint');

  // the rest of your original test
});
```

### 网络存根记录和回放的优缺点

UI 集成测试是 UI 测试的核心。它们在真实浏览器中运行整个应用程序，而不连接真实服务器。它们运行速度极快，对网络中的随机故障或错误负面影响较小。

工程师们必须认识到，这种优势如果被滥用可能成为一种诅咒。UI 应用程序是隔离的，但如果有网络故障，它们会被忽略。这对于功能分支测试非常有用，但在进一步的部署中，应确保后端也正常运行。请参阅 [使用集成测试前端，同时使用 E2E 测试后端](../real-life-examples/test-front-end-with-integration-back-end-with-e2e.zh.md) 了解何时使用哪种技术。

<br/><br/>

## 填充数据库

Cypress [`cy.task()`](https://docs.cypress.io/api/commands/task.html#Requirements) 功能非常强大。实际上，它允许你在 Cypress 上下文中使用 Node.js。这可以是任何内容，从 Node.js 代码到使用 npm 包来操纵数据库。如果你的应用程序使用 Node.js，你可以重用应用程序代码来帮助设置和操纵测试数据。

关于这个主题有一个 [Cypress 示例](https://github.com/cypress-io/cypress-example-recipes/tree/master/examples/server-communication__seeding-database-in-node)，我们将以此作为参考结束。

## 相关章节

- 🔗 [从难以理解的 React 组件测试到简单愚蠢的测试](/sections/real-life-examples/from-unreadable-react-component-tests-to-simple-ones.zh.md)



================================================
FILE: sections/generic-best-practices/test-code-with-debugging-in-mind.md
================================================
# Keep abstraction low to ease debugging the tests

<br/><br/>

### One Paragraph Explainer

UI tests are made up of a lot of steps and should accomplish three main things, but two of them are somewhat underestimated:

1.  To test a feature _(the obvious one)_
2.  To help the reader to understand what the code does _(usually underestimate)_
3.  To ease debuggability _(underestimate, and also requires experience)_

Let's go through some simple yet effective tips to keep in mind when writing UI tests.

<br/><br/>

## Readability

One arguable topic (Page-Object Model's fans will get hurt) is my view about abstraction in tests.

Let's look at a real-life example of a test I had to fix.

```ts
// spec.ts file
it('Create Query Action', createQueryAction);

// test.ts file (simplified version)
export const createMutationAction = () => {
  // ...
  clearActionDef();
  typeIntoActionDef(statements.createMutationActionText);
  clearActionTypes();
  // ...
};

// test.ts file contains the clearActionDef, typeIntoActionDef, etc.
const clearActionDef = () => {
  cy.get('textarea').first().type('{selectall}', { force: true });
  cy.get('textarea').first().trigger('keydown', {
    keyCode: 46,
    which: 46,
    force: true,
  });
};

// test.ts file contains also the statements
const statements = {
  createMutationActionText: `type Mutation {
    login (username: String!, password: String!): LoginResponse
  }`,
  createMutationCustomType: `type LoginResponse {
    accessToken: String!
  }
  `,
  createMutationHandler: 'https://hasura-actions-demo.glitch.me/login',
  // ...
}
```

The rationale behind the short functions is creating small, reusable pieces of code to help other tests that must do similar things on the page.

I think it is not good: because **it is hard to build a mental model of what the test does**! All the test parts are split into small functions and utilities, while the test's code must be as straightforward as possible.

Can you recall the two underrated points at the top of the chapter? The idea is that the test should accomplish three main things:

- To help the reader to understand what code does
- To allow debugging itself with ease

The former requires the test's code to be as dumb as possible, and there is no advantage in having abstraction in the test's code because it leads to spending more time debugging and maintaining the tests instead of the application.

The latter relates to the wrong part of tests: debugging/fixing them. Debugging a UI test is hard because you work with

- You front-end application
- The browser
- A tool that controls the browser
- The instructions you provide to the tool that controls the browser

Each of the above elements can fail, and even the more experienced developers can struggle with understanding the source of a failing test.

Hence, E2E testing is complicated. Cypress improves the developers' life (find more in [Some UI testing problems and the Cypress way](../tools/ui-testing-problems-cypress.md) chapter), but a straightforward code dramatically helps.

### No abstraction at all

I recommend having no abstraction at all (later, I will talk about the exceptions and which abstraction it's good)! I rewrote the above example to something like

```ts
it('Test the feature', () => {
  cy.get('textarea').eq(0).as('actionDefinitionTextarea');
  cy.get('textarea').eq(1).as('typeConfigurationTextarea');

  cy.get('@actionDefinitionTextarea').clearConsoleTextarea().type(
    `type Mutation {
        login (username: String!, password: String!): LoginResponse
      }`,
    { force: true, delay: 0 }
  );

  cy.get('@typeConfigurationTextarea').clearConsoleTextarea().type(
    `type LoginResponse {
      accessToken: String!
    }
    `,
    { force: true, delay: 0 }
  );

  // ...
})
```

The rewritten test does the same as the original one, but when you jump on the test's code, the overhead of jumping back and forth to connect the dots mentally is not needed.

- Do you want to know that is typed in the textarea? No hassle, it's there!
- Do you want to know what is the textareas used by the text? No hassle, it's there!

### When is abstraction good in tests?

In my opinion:

- When I want to hide some test oddities that could distract the readers for no value
- When they are soft, almost parameters-free, only one-level deep
- When there is a considerable amount of duplication (the precise amount is subjective, though)

An example of a test oddity is the following

```ts
/**
 * Clear a Console's textarea.
 * Work around cy.clear sometimes not working in the Console's textareas.
 */
Cypress.Commands.add('clearConsoleTextarea', { prevSubject: 'element' }, el => {
  cy.wrap(el).type('{selectall}', { force: true }).trigger('keydown', {
    keyCode: 46,
    which: 46,
    force: true,
  });
});
```

I created the central `cy.clearConsoleTextarea` because

1.  It's a workaround 😊
2.  For a newcomer, it is odds reading `trigger('keydown')` instead of using the more idiomatic `cy.clear`, and I do not want to leave a comment explaining it everywhere.
3.  The command is made up of 5 lines of code that would get the test's code too long for no reason.

An example of a soft abstraction is the following

```ts
function expectSuccessNotification = (title: string) {
  cy.get('.notification-success')
    .should('be.visible')
    .should('contain', title)
}
```

I like it because

1.  It does not use other abstracted code: if my tests fails at `expectSuccessNotification('Table created!')` I do not have to go crazy down the rabbit-hole to understand what happens behind `expectSuccessNotification`.
2.  It accepts only one variable, not a lot of options; neither includes conditions that would get hard in the way of understanding what the code finally does.
3.  **It's vertical for a specific use case**. It does not try to cover all the notification types, contents, etc., at once. Other vertical functions will do.
4.  If you refactor the notification system, you have a central point to refactor to adapt the tests to the new notification system.

At the opposite, this is what I do not want to have (while speaking about notification utilities)

```ts
export const expectNotification = (
  {
    type,
    title,
    message,
  }: {
    type: 'success' | 'error';
    title: string;
    message?: string;
  },

  timeout = 10000
) => {
  const el = cy.get(
    type === 'success' ? '.notification-success' : '.notification-error',
    { timeout }
  );

  el.should('be.visible');
  el.should('contain', title);

  if (message) el.should('contain', message);
};
```

I'm not too fond of the above example because

1.  It tries to cover too many use cases at a time.
2.  If it fails, you have to deal with conditions that make the whole experience a nightmare.

You can find more best practices we follow internally in the [Hasura Console UI coding patterns: Testing](https://dev.to/noriste/hasura-console-ui-coding-patterns-testing-281d) article.

### Matching the test's code and test runner's commands


![The test code side by side with the Cypress panel with some red arrows to match the code and the Cypress logs](../../assets/images/test-code-with-debugging-in-mind/no-match-between-code-and-runner.jpg)




The Cypress Test Runner helps understand what is happening in the application and which commands are executed, but when you debug a test, it is hard to have an immediate correlation between the Test Runner and the code. More, the logs do not help in understanding what the test is doing in feature terms (ex., the logs say "types in the textarea" but do not say "Type in the Type Configuration textarea"). So, detecting the root of a failure is hard. Cypress records videos for the failing tests, but it is useless if the reader/debugger does not have an immediate correlation between the logs and what the test is doing in plain English.

#### Look at something like this


![The code and the Cypress panel side by side, with a lot of custom logs that allow directly connecting what happens in Cypress to a precise point in the code](../../assets/images/test-code-with-debugging-in-mind/match-between-code-and-runner.jpg)



I add a log reporting what the test is doing, allowing a direct correlation between the test's code and the Test Runner (`cy.log('**--- Type in the Webhook Handler field**');`).

Please note that you can pass more arguments to 'cy.log', and they are logged right in the devtools' console when you click on the logged command.


![The Cypress Test Runner showing the value of a logged object](../../assets/images/test-code-with-debugging-in-mind/cy-log-console.jpg)



Storybook and Playwright already have the concept of `step` utilities that allow explaining in English what is happening in the test. Cypress does not have the same option, so the `cy.log` I propose is valuable, in my opinion.

Side note here: do not chain `cy.log` because it is not a query command; does not retry the chain.

`cy.log` doesn’t retry at function level, as of Cypress V12.

Ex:
```js
cy.log('foo').get('bar').should('baz') // does not retry
cy.get('bar').should('baz') // retries the whole chain until the assertion passes (you have 10 sec timeout set)
```

It's worth mentioning that even if Cypress does not have `step`, [Filip Hric](https://github.com/filiphric)'s [cypress-plugin-steps](https://github.com/NoriSte/ui-testing-best-practices/issues/43) is a valid alternative.

### Use clear selectors

Look at this code

```ts
cy.get('textarea')
  .eq(0)
  .type(`{enter}{uparrow}${statements.createMutationGQLQuery}`, {
    force: true,
  });
```

What is `cy.get('textarea').eq(0)`? In the absence of better selectors, I suggest hiding them under Cypress aliases, such as

```ts
// Assign an alias to the most unclear selectors for future references
cy.get('textarea').eq(0).as('actionDefinitionTextarea');
cy.get('textarea').eq(1).as('typeConfigurationTextarea');
```

and then referring to them this way

```ts
cy.get('@actionDefinitionTextarea').clearConsoleTextarea().type(/* ... */);
```

to improve the readers' life.

### Reducing data-testid attributes

I do not want to speak about the value for the tests themselves and for their confidence, but only about the effect of data-testid attributes over the debugging phase.

If an element with a data-tesid cannot be retrieved from the page, the possible problems are

1.  The element is not there.
2.  The element is there, but it does not have the attribute.
3.  The element is there, and it has the attribute but not the expected value.

All the above problems **cause the developer to re-launch the tests, inspect the elements**, look for the test-related attributes, etc. Instead, if the tests are based on the textual contents, a screenshot is enough to understand if the text searched by the test is not there or if it is wrong.

Also, some more cons for the engineers that have to deal with data-testid's

1.  Test-related attributes must be maintained during refactors, but it is not easy when you have hundreds of them.
2.  Test-related attributes are helpful if they are unique on the page. Another thing that is not easy to guarantee when you have hundreds of them

My suggestion is to use data-testid attributes only for:

-  Sections, not elements (ex. the Header, the Footer, , etc.) that allows reducing the scope of text-based searches. Here is an example

```ts
cy.get('[data-test="Actions list"]').within(() => { // <-- reduce the scope
  cy.contains('login') // <-- the "login" text could exist more times in the page
})
```

-  Non-text-based elements: icons, images, etc.

Last but not least: I suggest valuing them with user-like values, not programmer-like ones (ex. "Actions List", not "actionsList"), especially when the section shows that exact text. This allows a direct connection between the code of the test, the Cypress' Test Runner, and the page's text content.

### Grouping related actions

Reading a flat list of interactions generally does not help comprehend the page's structure the test is running against.

For instance

- get 1 and click
- get 2 and click
- get 3 and click
- get 4 and click
- get 5 and click
- get 6 and click
- get 7 and click
- get 8 and click

Instead, un-flattening the list could help the readers to create a mental model of where the involved parts reside

- within block 1
  - get 1 and click
  - get 2 and click
  - get 3 and click
- within block 2
  - get 4 and click
  - get 5 and click
  - get 6 and click
- get 7 and click
- get 8 and click


![The Cypress UI showing cy.within](../../assets/images/test-code-with-debugging-in-mind/cy-within.png)



Again: Storybook and Playwright already have the concept of `step` utilities that allow grouping actions, the above suggestion is handy with Cypress.


## Related chapters

- 🔗 [From unreadable React Component Tests to simple, stupid ones](/sections//real-life-examples/from-unreadable-react-component-tests-to-simple-ones.md)

<br/><br/>


*Crossposted by [NoriSte](https://github.com/NoriSte) on [dev.to](https://dev.to/noriste/improving-ui-testss-code-to-ease-debugging-them-later-2478j).*



================================================
FILE: sections/generic-best-practices/test-code-with-debugging-in-mind.zh.md
================================================
# 保持低抽象度以便于调试测试

<br/><br/>

## 一段简要说明

UI 测试涉及许多步骤，主要有三个关键目标，但其中两个往往被低估：

1. **测试一个功能**（显而易见）
2. **帮助读者理解代码的作用**（通常被低估）
3. **简化调试**（被低估，同时需要经验）

下面让我们一起了解编写 UI 测试时要记住的一些简单但有效的技巧。

<br/><br/>

## 可读性

关于测试中抽象的问题是一个有争议的话题（Page-Object Model 的粉丝可能会对此有异议）。

让我们看一个我不得不修复的真实测试的例子。

```ts
// spec.ts file
it('Create Query Action', createQueryAction);

// test.ts file (simplified version)
export const createMutationAction = () => {
  // ...
  clearActionDef();
  typeIntoActionDef(statements.createMutationActionText);
  clearActionTypes();
  // ...
};

// test.ts file contains the clearActionDef, typeIntoActionDef, etc.
const clearActionDef = () => {
  cy.get('textarea').first().type('{selectall}', { force: true });
  cy.get('textarea').first().trigger('keydown', {
    keyCode: 46,
    which: 46,
    force: true,
  });
};

// test.ts file contains also the statements
const statements = {
  createMutationActionText: `type Mutation {
    login (username: String!, password: String!): LoginResponse
  }`,
  createMutationCustomType: `type LoginResponse {
    accessToken: String!
  }
  `,
  createMutationHandler: 'https://hasura-actions-demo.glitch.me/login',
  // ...
}
```

短函数的背后思路是创建小而可重复使用的代码片段，以帮助其他需要在页面上执行类似操作的测试。

我认为这不太好，因为**很难建立对测试的执行过程的心智模型**！所有测试部分都被分割成小函数和实用程序，而测试的代码必须尽可能地直截了当。

你还记得章节开头提到的两个被低估的点吗？这个想法是测试应该实现三个主要目标：

- 帮助读者理解代码的作用
- 以便轻松进行调试

前者要求测试的代码尽可能简单，而在测试的代码中使用抽象并没有好处，因为这会导致花费更多时间调试和维护测试，而不是应用程序。

后者与测试的错误部分有关：调试/修复它们。调试 UI 测试很困难，因为你需要处理以下元素：

- 你的前端应用程序
- 浏览器
- 控制浏览器的工具
- 你提供给控制浏览器的工具的指令

上述每个元素都可能出现问题，即使是经验丰富的开发人员也可能在理解测试失败的原因时感到困扰。

因此，端到端测试是复杂的。Cypress 提高了开发人员的生活质量（在 [一些 UI 测试问题和 Cypress 方法](../tools/ui-testing-problems-cypress.zh.md) 章节中了解更多），但直截了当的代码会极大地帮助。

## 不使用任何抽象

我建议根本不使用抽象（稍后，我将讨论一些例外情况以及哪种抽象是好的）！我将上述例子改写为如下形式：

```ts
it('Test the feature', () => {
  cy.get('textarea').eq(0).as('actionDefinitionTextarea');
  cy.get('textarea').eq(1).as('typeConfigurationTextarea');

  cy.get('@actionDefinitionTextarea').clearConsoleTextarea().type(
    `type Mutation {
        login (username: String!, password: String!): LoginResponse
      }`,
    { force: true, delay: 0 }
  );

  cy.get('@typeConfigurationTextarea').clearConsoleTextarea().type(
    `type LoginResponse {
      accessToken: String!
    }
    `,
    { force: true, delay: 0 }
  );

  // ...
})
```

重写后的测试与原始测试执行相同的操作，但当你查看测试代码时，无需来回跳转来在脑中建立连接。

- 想知道在文本区域中输入了什么吗？毫不费力，就在那里！
- 想知道文本使用的是哪个文本区域吗？毫不费力，就在那里！

## 在测试中什么时候使用抽象化是好的呢？

在我看来：

- 当我想隐藏一些可能没有价值但可能分散读者注意力的测试怪癖时
- 当它们是软的，几乎不带参数，只有一层深度
- 当存在相当数量的重复（确切的数量是主观的）

一个测试怪癖的例子是下面这个

```ts
/**
 * Clear a Console's textarea.
 * Work around cy.clear sometimes not working in the Console's textareas.
 */
Cypress.Commands.add('clearConsoleTextarea', { prevSubject: 'element' }, el => {
  cy.wrap(el).type('{selectall}', { force: true }).trigger('keydown', {
    keyCode: 46,
    which: 46,
    force: true,
  });
});
```

我创建了中心的 `cy.clearConsoleTextarea`，原因如下：

1. 这是一种权宜之计 😊
2. 对于新手来说，阅读 `trigger('keydown')` 而不是使用更符合习惯的 `cy.clear` 是有点奇怪的，我不想在每个地方都留下解释的注释。
3. 该命令由 5 行代码组成，将使测试代码变得过长而毫无必要。 

以下内容是软抽象的一个例子：

```ts
function expectSuccessNotification = (title: string) {
  cy.get('.notification-success')
    .should('be.visible')
    .should('contain', title)
}
```

我喜欢它的原因是

1. 它不依赖其他抽象代码：如果我的测试在 `expectSuccessNotification('Table created!')` 失败，我不必陷入深奥的代码中，理解 `expectSuccessNotification` 背后发生了什么。
2. 它只接受一个变量，而不是很多选项；也没有包含那些在理解代码最终执行内容时变得复杂的条件。
3. **它专注于特定用例**。它不试图一次性涵盖所有通知类型、内容等。其他专注于特定用例的函数会处理。
4. 如果你重构通知系统，你有一个中心点进行重构，以适应新的通知系统。

相反，这是我不希望拥有的（在谈论通知工具时）。

```ts
export const expectNotification = (
  {
    type,
    title,
    message,
  }: {
    type: 'success' | 'error';
    title: string;
    message?: string;
  },

  timeout = 10000
) => {
  const el = cy.get(
    type === 'success' ? '.notification-success' : '.notification-error',
    { timeout }
  );

  el.should('be.visible');
  el.should('contain', title);

  if (message) el.should('contain', message);
};
```

我对上面的例子不太喜欢，原因有两点：

1. 它试图一次性涵盖太多用例。
2. 如果测试失败，你必须处理让整个体验变成噩梦的各种条件。

在[Hasura 控制台 UI 编码模式：测试](https://dev.to/noriste/hasura-console-ui-coding-patterns-testing-281d)文章中，你可以找到我们在内部遵循的更多最佳实践。

## 匹配测试代码和测试运行器命令

![测试代码与 Cypress 面板并排显示，带有一些红色箭头来匹配代码和 Cypress 日志](../../assets/images/test-code-with-debugging-in-mind/no-match-between-code-and-runner.jpg)

Cypress 测试运行器有助于理解应用程序中发生了什么以及执行了哪些命令，但在调试测试时，很难立即在测试运行器和代码之间建立关联。而且，日志无法帮助理解测试从功能角度正在做什么（例如，日志说“在文本区域中键入”，但没有说明“在类型配置文本区域中键入”）。因此，查找失败的根本原因是困难的。Cypress 会为失败的测试记录视频，但如果阅读者/调试者不能在日志和测试在普通英语中所做的事情之间建立直接关联，则视频就毫无用处。

### 请看下面的内容

![代码和 Cypress 面板并排显示，有许多自定义日志，可以直接将 Cypress 中发生的情况与代码中的特定点连接起来。](../../assets/images/test-code-with-debugging-in-mind/match-between-code-and-runner.jpg)

我添加了一个日志，报告测试正在进行的操作，使测试代码与测试运行程序之间能够直接对应。 (`cy.log('**--- Type in the Webhook Handler field**');`).

请注意，你可以向 'cy.log' 传递更多参数，这些参数将在单击记录的命令时直接显示在开发工具的控制台中。

![Cypress 测试运行器展示了已记录对象的值。](../../assets/images/test-code-with-debugging-in-mind/cy-log-console.jpg)

Storybook 和 Playwright 已经引入了`step`实用工具的概念，可以用英语解释测试中的步骤。Cypress 没有相同的选项，因此我认为我提出的`cy.log`是很有价值的。

这里需要注意：不要将`cy.log`链在一起，因为它不是一个查询命令，不会对链进行重试。

截至 Cypress V12 版本，`cy.log`在函数级别不进行重试。

例如：

```js
cy.log('foo').get('bar').should('baz') // does not retry
cy.get('bar').should('baz') // retries the whole chain until the assertion passes (you have 10 sec timeout set)
```

值得注意的是，即使 Cypress 没有 `step`，[Filip Hric](https://github.com/filiphric) 的 [cypress-plugin-steps](https://github.com/NoriSte/ui-testing-best-practices/issues/43) 也是一个有效的替代选择。

## 使用清晰的选择器

看一下这段代码

```ts
cy.get('textarea')
  .eq(0)
  .type(`{enter}{uparrow}${statements.createMutationGQLQuery}`, {
    force: true,
  });
```

`cy.get('textarea').eq(0)` 是什么？在没有更好的选择器的情况下，我建议将它们放在 Cypress 的别名下，比如

```ts
// Assign an alias to the most unclear selectors for future references
cy.get('textarea').eq(0).as('actionDefinitionTextarea');
cy.get('textarea').eq(1).as('typeConfigurationTextarea');
```

然后通过这种方式来引用它们

```ts
cy.get('@actionDefinitionTextarea').clearConsoleTextarea().type(/* ... */);
```

以提高读者的体验。

## 减少 data-testid 属性

我不想讨论测试本身及其对测试结果可信度的价值，只想谈谈 data-testid 属性在调试阶段的影响。

如果无法从页面中检索带有 data-testid 属性的元素，可能的问题有：

1. 元素不存在。
2. 元素存在，但它没有该属性。
3. 元素存在，具有该属性，但值不符合预期。

上述所有问题都会**导致开发人员重新启动测试、检查元素、查找与测试相关的属性等**。相反，如果测试基于文本内容，仅通过截图就足以了解测试搜索的文本是否不存在或错误。

此外，对于那些必须处理 data-testid 的工程师来说，还有一些不足之处：

1. 在重构期间必须维护与测试相关的属性，但在有数百个属性时并不容易。
2. 如果测试相关的属性在页面上是唯一的，那么它们会很有帮助。然而，当你有数百个这样的属性时，很难保证它们是唯一的。

我的建议是仅在以下情况使用 data-testid 属性：

- 用于节，而不是元素（例如 Header、Footer 等），以减小基于文本搜索的范围。以下是一个示例：

```ts
cy.get('[data-test="Actions list"]').within(() => { // <-- reduce the scope
  cy.contains('login') // <-- the "login" text could exist more times in the page
})
```

- 非文本元素，如图标、图片等。

最后但同样重要的是：我建议为它们赋予用户友好的值，而不是采用程序员的命名风格（例如，“操作列表”而不是“actionsList”），尤其是当该部分显示相同文本时。这样可以直接关联测试代码、Cypress 的测试运行器和页面的文本内容。

## 将相关操作分组

通常来说，阅读一系列平面的交互并不能帮助理解测试运行的页面结构。

例如：

- 获取 1 并点击
- 获取 2 并点击
- 获取 3 并点击
- 获取 4 并点击
- 获取 5 并点击
- 获取 6 并点击
- 获取 7 并点击
- 获取 8 并点击

然而，将列表展开可以帮助读者构建一个有关所涉及部分位置的心理模型

- 在块 1 内
  - 获取 1 并点击
  - 获取 2 并点击
  - 获取 3 并点击
- 在块 2 内
  - 获取 4 并点击
  - 获取 5 并点击
  - 获取 6 并点击
- 获取 7 并点击
- 获取 8 并点击

![Cypress 界面展示 cy.within](../../assets/images/test-code-with-debugging-in-mind/cy-within.png)

再强调一下：Storybook 和 Playwright 已经引入了“步骤（step）”实用程序的概念，该实用程序可以将操作进行分组，而上述建议在 Cypress 中非常实用。

## 相关章节

- 🔗 [从晦涩难懂的 React 组件测试到简单、易读的版本](/sections//real-life-examples/from-unreadable-react-component-tests-to-simple-ones.zh.md)

<br/><br/>

*由 [NoriSte](https://github.com/NoriSte) 在 [dev.to](https://dev.to/noriste/improving-ui-testss-code-to-ease-debugging-them-later-2478j)进行发表.*



================================================
FILE: sections/generic-best-practices/ui-tests-debugging-best-practices.md
================================================
# UI Tests Debugging Best Practices

Before moving to Cypress, I was used to writing UI tests with Puppeteer. Understanding what was happening in the browser, which test was running, and debugging the tests were not easy tasks, hence I started applying a series of solutions that helped me through the whole process.

Tools like [Cypress](https://www.cypress.io/) and [TestCafé](https://devexpress.github.io/testcafe/) get the following list of best practices almost useless but you do not realize how much a made-on-purpose tool simplifies your life unless you have previous testing experience with tools like [Selenium](https://www.selenium.dev/) or [Puppeteer](https://pptr.dev/).

The zero-step is to launch the browser in non-headless mode, then...

### Console.log/show the description of the test

Since you do not have visual feedback about which test is running inside the browser, remember to log the name of the test inside the browser console. It is quite useless in case of fast tests (less than 1 second) but helpful in case of longer tests or to have a double-check about the test that you are running while playing with test.skip and test.only.

In Puppeteer this could be accomplished with:
```js
test('Test description', async () => {
  await page.evaluate(() => console.log('Test description'));

  // ... the test code...
})
```
If you need more intrusive feedback, you could consider even adding a fixed div at the top-left corner of the page that every test populates with its own description...

### Forward browser console.log to Node.js

With Puppeteer, a simple
```js
page.on('console', msg => console.log('BROWSER LOG:', msg.text()));
```
allows you to read both the test logs and the browser one in the same terminal window. Simple and effective.

### Launch the browser with the devtools already opened

Like in classic front-end development, opening the devtools after the page loading has already started could make you miss important stuff, especially in the network tab. While debugging your tests, launching the browser with the devtools already opened could save you precious time and info.
```js
const browser = await puppeteer.launch({
  headless: false,
  devtools: true
});
```
### Slow down the simulated user actions

A browser automation tool is fast as hell, this allows us to run a lot of tests in a bunch of seconds. While debugging, this could be a disadvantage, because you need to follow with your eyes what’s happening on the page. Slowing down **every action** could be counterproductive—because the whole test becomes slow— but usually, it is the easiest way to perform some rapid checks. In Puppeteer, there is a global setting to do that.
```js
const browser = await puppeteer.launch({
  headless: false,
  slowMo: 250, // slow down every action by 250ms
});
```
Some actions, like typing, allows you to add a more specific delay (that occurs on top of the global slowMo setting)
```js
await page.type('.username', 'admin', {delay: 10});
```
### Pause the test with a debugger statement

Again, like in standard web development, you could add a debugger statement to the code running on your page to “pause” the JavaScript execution. Please note: the statement is effective only if the devtools are opened in the controlled browser.
```js
await page.evaluate(() => {debugger;});
```
By clicking “Resume scripts execution” or bypressing F8 (debugger is a “flying” breakpoint) will resume the test execution.

### Increase the test timeout

Test runners like Jest, Jasmine, etc. have test timeouts. Timeouts are useful to terminate a test if something goes wrong and the tests never end. In UI testing, this behavior is cumbersome because you open the browser when the test starts and you close it when the test ends. In the normal test's lifecycle, a high timeout does not work because it results in a huge loss of time in case of failure, while a low one could “truncate” the test before it is finished.

Instead, you need long timeouts because you do not want the end of the test make close the browser while you are inspecting it. That’s why a 10-minutes timeout could be helpful while debugging the controlled browser.

Otherwise, you could...

### Avoid closing the browser when the test ends

When the tests start, you open the browser, then you close it when the tests end. Avoid closing it gives you the freedom of inspecting the front-end app without the fear of the test timeout. This is valid only when running the tests locally and the auto-close must be restored before running the tests on CI pipelines to avoid memory shortage due to the left open browser instances.

### Take screenshots

This is particularly helpful while running the tests in headless mode, in the phase when the tests are expected to be stable and to fail only in case of regressions. If a test fails, a lot of times a screenshot makes you to understand how the feature you are working on affected a previously working one. The most effective solution is to take a screenshot when the tests fail, otherwise, you could identify some checkpoints in your UI test and taking a screenshot at these steps.

### Assert frequently

A rule of thumb: if a test fails, it must drive you directly to understand what went wrong without re-launching the test and debugging it manually. Try to manually introduce bugs in your codebase (changing requests payload, removing elements, etc.) and check what the test reports. Is the error correlated to the bug you introduced? Who reads the failure could understand what needs to be fixed?

You need to add a lot of assertions to your test and it is totally fine! Unit tests take generally one single step and one or two assertions but UI tests are different, they have a lot of steps and hence you need a lot of assertions. Think of them as a series of uni tests where the previous test is necessary to create the ground for the second test, and so on.

### Use test.skip and test.only

It is one of the basics of every test runner but you never know: if you are not accustomed to using skip and only, start now! Otherwise, you are going to waste a lot of time, even if your test files are made by just two or three tests. Always run the least number of tests you are working on or you need to debug!

### Run the tests serially

If you are using Puppeteer in combination with Jest remember that Jest has a dedicated runInBand option that prevents it from spreading the execution of the tests over your CPU cores. Parallelizing the tests is perfect to fasten the execution but it is annoying when you need to follow the test actions with your eyes. runInBand runs the tests serially. Using it in combination with test.skip, test.only, and [jest-watch-typeahead](https://github.com/jest-community/jest-watch-typeahead) saves you a lot of debugging headaches.

### Keep your test code simple

Prefer duplication over abstraction. Strive to keep your tests code simple and easy to read. The more you debug UI tests, the more you realize how hard it could be. Your super-abstracted, completely DRYed, testing code becomes a pain as soon as you need to understand what is happening under the hood and which step is not working as expected.

More in general, tests are little scripts that must be two levels of magnitude simpler than the code they test, get them an ally, and not some more complex programs.

You can dig more about this topic in [Keep abstraction low to ease debugging the tests](/sections/generic-best-practices/test-code-with-debugging-in-mind.md), and [From unreadable React Component Tests to simple, stupid ones](/sections/real-life-examples/from-unreadable-react-component-tests-to-simple-ones.md).




<br /><br />

_Crossposted by [NoriSte](https://github.com/NoriSte) on [dev.to](https://dev.to/noriste/ui-tests-debugging-best-practices-1eg3) and [Medium](https://medium.com/@NoriSte/ui-tests-debugging-best-practices-789c4ed4daf6?sk=c6056f124f40b15e09669e5839e9f814)._



================================================
FILE: sections/generic-best-practices/ui-tests-debugging-best-practices.zh.md
================================================
[Binary file]


================================================
FILE: sections/generic-best-practices/use-your-testing-tool-as-your-primary-development-tool.md
================================================
# Use your testing tool as your primary development tool

<br/><br/>

### One Paragraph Explainer


An example speaks itself. Let's say you're developing an authentication form, probably, you:
- code the username input field
- **try it manually** in the browser
- code the password input field
- **try it manually** in the browser
- code the submit button
- code the XHR request management

then, you can't go ahead because, without changing the source code, you need that a stubbed/mocked server responds to the app XHR requests. **Then you start writing an integration test** that:
- fill the username input field
- fill the password input field
- click the submit button
- check the XHR request
- stub the XHR response
- check the feedbacks
- re-do it for every error flow
- code the error flow management
- re-check the tests

Take a look at the first test steps, they are **the same we made manually** while coding the authentication form. Then, we stub the
server responses and check the final behavior of the form (with success/failure responses).

This working flow could be easily improved if we write the test alongside the form itself (TDD
developers are already trained to do that):
- **code the username input field** *
- **write the test to fill** the username input field *
- code the password input field
- update the test to fill the password input field
- code the submit button
- update the test to click the submit button
- stub the XHR response into the test
- code the XHR request management
- check the feedbacks
- code the error flow management
- update the test to check the error flow
- re-do the above steps for every single error flow

\* please note that the first and the second step could be inverted if you want to apply a strict TDD approach

What are the most important advantages of doing that?
- you **avoid (almost) completely manually testing** your app
- you leverage the speed of your testing tool, it fills the form at a blazing speed and let you **save
  a lot of time**
- you don't have to write the test after you coded the form (again, TDD developers already avoid it)
  that, only at the first approaches, could seem an annoying task
- you completely **avoid putting some temporary states into your source code** (input field default
  values, fake XHR responses)
- you test your app directly with a real network response (remember that your app does not know that
  the network request is stubbed by the testing tool)
- the test is relaunched every time you save the test file
- you can leverage both the Chrome DevTools and the framework-specific devtools

How to leverage the **existing Development Tools**?<br>
Well, you can do that in
almost every testing tool but Cypress stands out for this kind of goal. Cypress has a dedicated
Chrome user that's persisted across all your tests and all your projects. Doing so, Cypress allows
you to have a real testing-dedicated browser with your favorite extensions, even if you use the
same Chrome version you use to browse.<br>
Mix it with a great UI and you are ready to start developing all your app directly with Cypress.

Below you can find some screenshot of the Cypress UI to show you how much easy is using it as a
primary development tool.

<br>

**Browser Selection**
![Cypress browser
selection](../../assets/images/use-your-testing-tool-as-your-primary-development-tool/browser-selection.png
"Cypress browser selection")

**The Cypress-controlled browser DevTools**
![Cypress browser
devtools](../../assets/images/use-your-testing-tool-as-your-primary-development-tool/devtools.jpg
"Cypress browser devtools")

**Cypress [Skip and Only UI plugin](https://github.com/bahmutov/cypress-skip-and-only-ui)** that allows you to add some `.only` or `.skip` to the tests directly from the Cypress UI.
![Cypress Skip and Only
UI](../../assets/images/use-your-testing-tool-as-your-primary-development-tool/skip-and-only.gif
"Cypress Skip and Only UI")

**Cypress [Watch and Reload plugin](https://github.com/bahmutov/cypress-watch-and-reload)** that allows you to re-run the cypress tests on every source code compilation.


If you want to see the React/Redux devtools in action with the Cypress controlled browser you can use the [cypress-react-devtools](https://github.com/NoriSte/cypress-react-devtools) repository.

## Related chapters

- 🔗 [Found a bug? Write the test, then fix it](/sections/testing-strategy/write-test-then-fix-bug.md)

<br /><br />

*Crossposted by [NoriSte](https://github.com/NoriSte) on [dev.to](https://dev.to/noriste/front-end-productivity-boost-cypress-as-your-main-development-browser-5cdk) and [Medium](https://medium.com/@NoriSte/front-end-productivity-boost-cypress-as-your-main-development-browser-f08721123498).*



================================================
FILE: sections/generic-best-practices/use-your-testing-tool-as-your-primary-development-tool.zh.md
================================================
[Binary file]


================================================
FILE: sections/real-life-examples/from-unreadable-react-component-tests-to-simple-ones.md
================================================
# From unreadable React Component Tests to simple, stupid ones

<br/><br/>

### One Paragraph Explainer

The test's code must be as straightforward as possible. The benefit is to save a lot of time to understand, update, refactor, fix it when needed. At the opposite, a terrible scenario happens when you are not able to read some tests, even if you are the author!

<br/><br/>

Here are the rationales, the mental process, and the patterns at the base of the refactor of some old React Component Tests of mine.


## The problem

One year after adding at the ["Testing a Virtual List component with Cypress and Storybook"](../../sections/tools/cypress-and-storybook-exposing-component-from-story.md) chapter, and the ["Unit Testing React components with Cypress"](../../sections/tools/cypress-react-component-test.md) one, I felt terrible while realizing that my tests were almost unreadable. Many abstractions prevented me from carefully understanding what the test did in a while, resulting in a long time reading them. This is unacceptable friction.


## How to improve tests readability?

Kent Beck, the father of TDD, said

> Test code is NOT production code. It must be 1000x times simpler and smaller.

but how? What adds such friction to my tests? What worsens readability?

I will to analyze a bunch of my tests, reasoning about them, and propose a more straightforward approach. The component under test is a VirtualList mentioned in the previous articles.

## Test 1, low complexity

The next test is the simplest one: checking that the VirtualList renders nothing when nothing is passed. Following is the original test

```tsx
it('When there are no items, then nothing is showed', () => {
  const itemsAmount = 0
  const itemHeight = 30
  const listHeight = 300
  const items = getStoryItems({ amount: itemsAmount })

  mount(
    <VirtualList
      items={items}
      getItemHeights={() => itemHeight}
      RenderItem={createRenderItem({ height: itemHeight })}
      listHeight={listHeight}
    />,
  )

  cy.findByTestId('VirtualList')
    .then($el => $el.text())
    .should('be.empty')
})
```

Considering the simplicity of the test, is speaking about readability here bikeshedding? No, I've already some questions about it, such as:
- What does `getStoryItems` do?
- What does `createRenderItem` do?

I don't report `getStoryItems`'s code here, but it's just a function that generates an array containing X items in the form of `[{ id: 1, name: 'Item 1' }, { id: 2, name: 'Item 2' }, /* etc. */]`. Its purpose is to generate thousands of items easily, but I wrote it to ease writing Storybook's stories without tests in mind! Then, I reused it for the tests, but stories and tests have completely different needs and purposes!

At the same time, `createRenderItem` is a factory that generates the list items (some React components). Again, I made it such dynamic for Storybook, and tests weren't originally in my mind.

Both the functions are easy to read, but why am I forcing the reader to follow these abstractions? Are they needed? The answer is no.

Following is the simplified code of the test, following the differences.

```tsx
it('When there are no items, then nothing is showed', () => {
  // ------------------------------------------
  // Arrange
  const items = [];

  mount(
    <VirtualList
      items={items}
      listHeight={90}
      getItemHeights={() => 30}
      RenderItem={RenderItem}
    />
  );

  // ------------------------------------------
  // Assert
  cy.findByTestId('VirtualList')
    .then(($el) => $el.text())
    .should('be.empty');
});
```
```diff
-const itemsAmount = 0
-const itemHeight = 30
-const listHeight = 300
-const items = getStoryItems({ amount: itemsAmount })
+const items = [];

mount(
  <VirtualList
    items={items}
    listHeight={listHeight}
-   getItemHeights={() => itemHeight}
+   getItemHeights={() => 30}
-   RenderItem={createRenderItem({ height: itemHeight })}
+   RenderItem={RenderItem}
  />,
)
```

In the simplified test, the most significant changes are:
1. I made `items` explicit instead of generating them through `getStoryItems`. The goal is immediately to clarify to the reader which are the items the VirtualList renders.
2. I removed the "unnecessary" constants. How tall are the items and the list don't make a difference if no items are rendered.
3. I removed the need for the `createRenderItem` factory. Generating components with height pre-set is useless here.

## Test 2, medium complexity

The next test is not complex. But the way I implemented it adds complexity when not needed. The goal is testing the base functionality of a VirtualList: rendering the visible items and not rendering the invisible ones.

```tsx
it('When the list receives 10000 items, then only the minimum number of them are rendered', () => {
  const itemsAmount = 10000
  const itemHeight = 30
  const listHeight = 300
  const items = getStoryItems({ amount: itemsAmount })
  const visibleItemsAmount = listHeight / itemHeight

  mount(
    <VirtualList
      items={items}
      getItemHeights={() => itemHeight}
      RenderItem={createRenderItem({ height: itemHeight })}
      listHeight={listHeight}
    />,
  )

  const visibleItems = items.slice(0, visibleItemsAmount - 1)
  itemsShouldBeVisible(visibleItems)

  // first not-rendered item check
  cy.findByText(getItemText(items[visibleItemsAmount])).should('not.exist')
})
```

Here things are getting weirder. Again, there are some simple abstractions, but the reader must:
- Comprehend the value of `visibleItemsAmount`.
- Comprehend what `visibleItems` contains, by reading `items.slice`. Again, one more complexity layer.
- Guess about what `itemsShouldBeVisible` does, or reading its code.
- Guess what `items[visibleItemsAmount]` contains.

Yeah, there are some comments. Yeah, I tried to create meaningful names. But I could simplify it a lot.

One more thing. Imagine this situation: the test is failing. It doesn't matter what you have done. This test is failing. You start debugging it, but you know that debugging a highly dynamic test (you don't know what `items`, `visibleItemsAmount`, `visibleItems`, `items[visibleItemsAmount]` contains upfront) is hard. You need to `console.log`/`cy.log`/`debugger`/breakpoint the test code to have an overall idea of the contents managed by the test, and then you can start debugging the VirtualList. Could I avoid future debugger these problems? Do I need the test to render 10.000 items?

Following is how I improved the test.

```tsx
it('When the list is longer than the available space, then only the minimum number of items are rendered', () => {
  // ------------------------------------------
  // Arrange

  // creating the data
  const items = [
    // visible ones
    { id: 1, name: 'Item 1' },
    { id: 2, name: 'Item 2' },
    { id: 3, name: 'Item 3' },
    // invisible one
    { id: 3, name: 'Item 4' },
  ];

  // only 3 items are visible
  const itemHeight = 30;
  const listHeight = 90;

  // mounting the component
  mount(
    <VirtualList
      items={items}
      getItemHeights={() => itemHeight}
      RenderItem={RenderItem}
      listHeight={listHeight}
    />
  );

  // ------------------------------------------
  // Act

  // ------------------------------------------
  // Assert
  cy.findByText('Item 1').should('be.visible');
  cy.findByText('Item 2').should('be.visible');
  cy.findByText('Item 3').should('be.visible');
  cy.findByText('Item 4').should('not.exist');
});
```

Also, here, the sole and relevant change is easing the future reader/debugger. You don't have to guess/calculate/log the value of the constants, nor what the abstractions do. The code is under your eyes, following the KISS principle (Keep It Simple, Stupid).

```diff
-const itemsAmount = 10000
-const itemHeight = 30
-const listHeight = 300
-const items = getStoryItems({ amount: itemsAmount })
-const visibleItemsAmount = listHeight / itemHeight
+// creating the data
+const items = [
+ // visible ones
+ { id: 1, name: 'Item 1' },
+ { id: 2, name: 'Item 2' },
+ { id: 3, name: 'Item 3' },
+ // invisible one
+ { id: 3, name: 'Item 4' },
+];

+// only 3 items are visible
+const itemHeight = 30;
+const listHeight = 90;

/* ... */

-const visibleItems = items.slice(0, visibleItemsAmount - 1)
-itemsShouldBeVisible(visibleItems)
-cy.findByText(getItemText(items[visibleItemsAmount])).should('not.exist')
+cy.findByText('Item 1').should('be.visible');
+cy.findByText('Item 2').should('be.visible');
+cy.findByText('Item 3').should('be.visible');
+cy.findByText('Item 4').should('not.exist');
```

## Test 3, medium complexity

In the next test, the purpose is to test the VirtualList's `buffer` property that allows rendering some items even if they aren't visible yet.

```tsx
it('When some items buffered, then they exist in the page', () => {
  const itemsAmount = 1000
  const itemHeight = 30
  const listHeight = 300
  const items = getStoryItems({ amount: itemsAmount })
  const visibleItemsAmount = listHeight / itemHeight
  const bufferedItemsAmount = 5

  mount(
    <VirtualList
      items={items}
      getItemHeights={() => itemHeight}
      RenderItem={createRenderItem({ height: itemHeight })}
      listHeight={listHeight}
      buffer={bufferedItemsAmount}
    />,
  )

  fastScrollVirtualList().then(() => {
    const firstRenderedItemIndex = getFirstRenderedItemIndex(items, getItemText)
    const firstVisibleItemIndex = firstRenderedItemIndex + bufferedItemsAmount
    const lastVisibleItemIndex = firstVisibleItemIndex + visibleItemsAmount + 1
    const lastRenderedItemIndex = lastVisibleItemIndex + bufferedItemsAmount

    items.slice(firstRenderedItemIndex, firstVisibleItemIndex).forEach(item => {
      cy.findByText(getItemText(item)).should('not.be.visible')
    })

    items.slice(firstVisibleItemIndex, lastVisibleItemIndex).forEach(item => {
      cy.findByText(getItemText(item)).should('be.visible')
    })

    items.slice(lastVisibleItemIndex, lastRenderedItemIndex).forEach(item => {
      cy.findByText(getItemText(item)).should('not.be.visible')
    })
  })
})
```

The complexity comes from
1. Scrolling the list to test that the buffer acts on both sides.
2. When scrolling stops, I don't know in advance which items are visible and which not, that's why the content of `fastScrollVirtualList().then(() => { /* ... */ })` is dynamic.

I return on #2 later, but for this test, I cut the snake's head by removing #1: why do I need to test the entire `buffer` behavior here through a Cypress Component Test? I have a lot of unit tests that check that the internal VirtualList functions do their job. I don't need to re-test the same behavior again. Once `buffer` works, it works on both sides. The test benefit from this choice; now it's way simpler, containing a lot of comments that help the reader!

```tsx
it('Should render only the visible items and the buffered ones when an item is partially visible', () => {
  // ------------------------------------------
  // Arrange

  // creating the data
  const items = [
    // visible ones
    { id: 1, name: 'Item 1' },
    { id: 2, name: 'Item 2' },
    { id: 3, name: 'Item 3' },
    // visible ones
    { id: 4, name: 'Item 4' },
    // buffered ones
    { id: 5, name: 'Item 5' },
    { id: 6, name: 'Item 6' },
    // non-rendered one
    { id: 7, name: 'Item 7' },
  ];

  const itemHeight = 30;
  // 3 items are fully visible, 1 is partially visible
  const listHeight = 100;
  // 2 items are buffered
  const buffer = 2;

  // mounting the component
  mount(
    <VirtualList
      items={items}
      getItemHeights={() => itemHeight}
      RenderItem={RenderItem}
      listHeight={listHeight}
      buffer={buffer}
    />
  );

  // ------------------------------------------
  // Act

  // ------------------------------------------
  // Assert
  cy.findByText('Item 1').should('be.visible');
  cy.findByText('Item 2').should('be.visible');
  cy.findByText('Item 3').should('be.visible');
  cy.findByText('Item 4').should('be.visible');
  cy.findByText('Item 5').should('not.be.visible');
  cy.findByText('Item 6').should('not.be.visible');
  cy.findByText('Item 7').should('not.exist');
});
```

## Test 4, high complexity

Testing the selection is the hardest part of the VirtualList, because:
1. The VirtualList manages keyboard modifiers, allowing simple, additive, subtractive, and range selection.
2. The VirtualList is stateless: we need to wrap it with a stateful wrapper that stores the previous selection to test the additive, subtractive, and range selection.

My old test is very hard or read, because:
1. The stateful wrapper is declared in the body of the test itself, using the test's scope.
2. All the selections are checked out in a single long flow.

Step by step, let's simplify it.

### Moving the abstraction away

The first part of the old test is the following

```tsx
it('When the items are clicked, then they are selected', () => {
  const itemHeight = 30
  const listHeight = 300
  let testItems

  const WithSelectionManagement: React.FC<{
    testHandleSelect: (newSelectedIds: ItemId[]) => {}
  }> = props => {
    const { testHandleSelect } = props
    const items = getStoryItems({ amount: 10000 })

    const [selectedItems, setSelectedItems] = React.useState<(string | number)[]>([])

    const handleSelect = React.useCallback<(params: OnSelectCallbackParams<StoryItem>) => void>(
      ({ newSelectedIds }) => {
        setSelectedItems(newSelectedIds)
        testHandleSelect(newSelectedIds)
      },
      [setSelectedItems, testHandleSelect],
    )

    React.useEffect(() => {
      testItems = items
    }, [items])

    return (
      <VirtualList
        items={items}
        getItemHeights={() => itemHeight}
        RenderItem={createSelectableRenderItem({ height: itemHeight })}
        listHeight={listHeight}
        updateScrollModeOnDataChange={{
          addedAtTop: true,
          removedFromTop: true,
          addedAtBottom: true,
          removedFromBottom: true,
        }}
        selectedItemIds={selectedItems}
        onSelect={handleSelect}
      />
    )
  }
  WithSelectionManagement.displayName = 'WithSelectionManagement'

  mount(<WithSelectionManagement testHandleSelect={cy.stub().as('handleSelect')} />)

  /* ... rest of the test ... */
})
```

It's pretty hard reading a test that starts with such a boilerplate. You get lost in a while, losing the critical parts of the test itself. Let's move it away from the test.

```tsx
// wrap the VirtualList to internally manage the selection, passing outside only the new selection
function SelectableList(props) {
  const { onSelect, ...virtualListProps } = props;

  // store the selection in an internal state
  const [selectedItems, setSelectedItems] = React.useState([]);
  const handleSelect = React.useCallback(
    ({ newSelectedIds }) => {
      setSelectedItems(newSelectedIds);
      // call the passed spy to notify the test about the new selected ids
      onSelect({ newSelectedIds });
    },
    [setSelectedItems, onSelect]
  );

  // Transparently renders the VirtualList, apart from:
  // - storing the selection
  // - passing the new selection back to the test
  return (
    <VirtualList
      selectedItemIds={selectedItems}
      onSelect={handleSelect}
      // VirtualList props passed from the test
      {...virtualListProps}
    />
  );
}

it('When two items are clicked pressing the meta button, then they are both selected', () => {
    // ------------------------------------------
    // Arrange

    // creating the data
    const itemHeight = 30;
    const listHeight = 90;
    const items = [
      { id: 1, name: 'Item 1' },
      { id: 2, name: 'Item 2' },
      { id: 3, name: 'Item 3' },
    ];

    // mounting the component
    mount(
      <SelectableList
        // test-specific props
        onSelect={cy.spy().as('onSelect')}
        // VirtualList props
        items={items}
        getItemHeights={() => itemHeight}
        RenderItem={RenderItem}
        listHeight={listHeight}
      />
    );

  /* ... rest of the test ... */
})
```

The background noise is still high, but you don't encounter it when you read the test. Then, do you notice that consuming the wrapper moved from
```tsx
mount(<WithSelectionManagement testHandleSelect={cy.stub().as('handleSelect')} />)
```
to
```tsx
mount(
  <SelectableList
    // test-specific props
    onSelect={cy.spy().as('onSelect')}
    // VirtualList props
    items={items}
    getItemHeights={() => itemHeight}
    RenderItem={RenderItem}
    listHeight={listHeight}
  />
);
```
? The purpose is getting the code similar as much as possible to the previous, simpler tests. `SelectableList` is now more transparent, and its code is simpler because it does just one thing: storing the previous selection.

### Splitting the long test

Fasten the seatbelt: apart from the wrapper, the old test is the following

```tsx
it('When the items are clicked, then they are selected', () => {
  /* ... the code of the wrapper ... */

  cy.then(() => expect(testItems).to.have.length.greaterThan(0))
  cy.wrap(testItems).then(() => {
    cy.findByText(getItemText(testItems[0])).click()
    cy.get('@handleSelect').should(stub => {
      expect(stub).to.have.been.calledOnce
      expect(stub).to.have.been.calledWith([testItems[0].id])
    })

    cy.findByText(getItemText(testItems[1])).click().window()
    cy.get('@handleSelect').should(stub => {
      expect(stub).to.have.been.calledTwice
      expect(stub).to.have.been.calledWith([testItems[1].id])
    })

    cy.get('body')
      .type('{meta}', { release: false })
      .findByText(getItemText(testItems[2]))
      .click()
      .get('@handleSelect')
      .should(stub => {
        expect(stub).to.have.been.calledThrice
        expect(stub).to.have.been.calledWith([testItems[1].id, testItems[2].id])
      })
      .get('body')
      .type('{meta}', { release: true })

    cy.get('body')
      .type('{shift}', { release: false })
      .findByText(getItemText(testItems[0]))
      .click()
      .get('@handleSelect')
      .should(stub => {
        expect(stub).to.have.been.callCount(4)
        expect(stub).to.have.been.calledWith([testItems[2].id, testItems[1].id, testItems[0].id])
      })
      .get('body')
      .type('{shift}', { release: true })

    cy.get('body')
      .type('{alt}', { release: false })
      .findByText(getItemText(testItems[1]))
      .click()
      .get('@handleSelect')
      .should(stub => {
        expect(stub).to.have.been.callCount(5)
        expect(stub).to.have.been.calledWith([testItems[2].id, testItems[0].id])
      })
      .get('body')
      .type('{alt}', { release: true })

    fastScrollVirtualList().then(() => {
      const firstRenderedItemIndex = getFirstRenderedItemIndex(testItems, getItemText)
      const firstRenderedItem = testItems[firstRenderedItemIndex]
      const expectedSelectedItemIds = testItems
        .slice(0, firstRenderedItemIndex + 1)
        .map(item => item.id)

      cy.get('body')
        .type('{shift}', { release: false })
        .findByText(getItemText(firstRenderedItem))
        .click()
        .get('@handleSelect')
        .should(stub => {
          expect(stub).to.have.been.callCount(6)
          expect(stub).to.have.been.calledWith(expectedSelectedItemIds)
        })
        .get('body')
        .type('{shift}', { release: true })
    })
  })
})
```

Looking at it now, the weird things are:
- `cy.then(() => expect(testItems).to.have.length.greaterThan(0))` since the items were generated dynamically, I bailed out in case of problems with the  external function.
- `cy.findByText(getItemText(testItems[0])).click()` is too much dynamic, what `testItems[0]` contains?
- The `fastScrollVirtualList().then(() => { /* ... */ }` content 😩
- The length of the test itself.
- It's not clear where testing a type of selection ends and where testing the next one begins.

Let's start by removing the need for such an extended test splitting a four-selection test into four ones.

#### Single selection

Guess what? Testing the simple selection doesn't need the wrapper at all 😊

```tsx
it('When an item is clicked, then it is selected', () => {
  // ------------------------------------------
  // Arrange

  // creating the spy
  // a spy is needed to intercept the call the VirtualList does
  const onSelectSpy = cy.spy().as('onSelect');

  // creating the data
  const items = [
    { id: 1, name: 'Item 1' },
    { id: 2, name: 'Item 2' },
    { id: 3, name: 'Item 3' },
  ];

  // mounting the component
  mount(
    <VirtualList
      items={items}
      getItemHeights={() => 30}
      RenderItem={RenderItem}
      listHeight={90}
      onSelect={onSelectSpy}
    />
  );

  // ------------------------------------------
  // Act
  cy.findByText('Item 1').click();

  // ------------------------------------------
  // Assert
  cy.get('@onSelect').should((spy) => {
    expect(spy).to.have.been.calledOnce;

    // Sinon matchers allow to assert about partials of the params
    // see
    // https://sinonjs.org/releases/latest/assertions/
    // https://sinonjs.org/releases/latest/matchers/
    expect(spy).to.have.been.calledWith(
      Cypress.sinon.match({ newSelectedIds: [1] })
    );
    expect(spy).to.have.been.calledWith(
      Cypress.sinon.match({ item: { id: 1, name: 'Item 1' } })
    );
  });
});
```

The most relevant changes, compared to the first part of the old test:
- No need for the wrapper.
- No more dynamic values.
- More expressive assertions.
- It's a single-purpose test.

#### Additive and subtractive selection

Here we need to leverage the wrapper.

```tsx
it('When two items are clicked pressing the meta button, then they are both selected', () => {
    // ------------------------------------------
    // Arrange

    // creating the data
    const itemHeight = 30;
    const listHeight = 90;
    const items = [
      { id: 1, name: 'Item 1' },
      { id: 2, name: 'Item 2' },
      { id: 3, name: 'Item 3' },
    ];

    // mounting the component
    mount(
      // mount `SelectableList`instead of `VirtualList`
      <SelectableList
        // test-specific props
        onSelect={cy.spy().as('onSelect')}
        // VirtualList props
        items={items}
        getItemHeights={() => itemHeight}
        RenderItem={RenderItem}
        listHeight={listHeight}
      />
    );

    // ------------------------------------------
    // click on the first item
    // Act
    cy.findByText('Item 1')
      .click()
      // Assert
      .get('@onSelect')
      .should((spy) => {
        expect(spy).to.have.been.calledOnce;
        expect(spy).to.have.been.calledWith({ newSelectedIds: [1] });
      });

    // ------------------------------------------
    // click on the second item
    // Act
    // keep the meta button  pressed
    cy.get('body').type('{meta}', { release: false });

    cy.findByText('Item 2')
      .click()
      // Assert
      .get('@onSelect')
      .should((spy) => {
        expect(spy).to.have.been.calledTwice;
        expect(spy).to.have.been.calledWith({ newSelectedIds: [1, 2] });
      });
  });
```

The huge difference here is avoiding scrolling because it doesn't affect the additive selection. Again explicit values, clarity, and brevity allow having a more straightforward and more expressive test.

Testing the subtractive selection follows the same pattern. I don't report it here.

#### Range selection

Compared to the previous selections, I think that the range selection **could be** affected by scrolling the list because some items that will be selected aren't rendered anymore. How could I make something that's dynamic by definition—scrolling the list—more static? Through manual tests and some comments.

```tsx
it('When the list is scrolled amd some items are clicked pressing the shift button, then the range selection works', () => {
  // ------------------------------------------
  // Arrange

  // creating the data
  const items = [
    { id: 1, name: 'Item 1' },
    { id: 2, name: 'Item 2' },
    { id: 3, name: 'Item 3' },
    { id: 4, name: 'Item 4' },
    { id: 5, name: 'Item 5' },
    { id: 6, name: 'Item 6' },
    { id: 7, name: 'Item 7' },
    { id: 8, name: 'Item 8' },
    { id: 9, name: 'Item 9' },
    { id: 10, name: 'Item 10' },
    { id: 11, name: 'Item 11' },
    { id: 12, name: 'Item 12' },
    { id: 13, name: 'Item 13' },
    { id: 14, name: 'Item 14' },
    { id: 15, name: 'Item 15' },
    { id: 16, name: 'Item 16' },
    { id: 17, name: 'Item 17' },
    { id: 18, name: 'Item 18' },
    { id: 19, name: 'Item 19' },
    { id: 20, name: 'Item 20' },
  ];
  // only 3 items are visible
  const itemHeight = 30;
  const listHeight = 90;

  // mounting the component
  mount(
    <SelectableList
      // test-specific props
      onSelect={cy.spy().as('onSelect')}
      // VirtualList props
      items={items}
      getItemHeights={() => itemHeight}
      RenderItem={RenderItem}
      listHeight={listHeight}
    />
  );

  // Act

  // click on the first item
  cy.findByText('Item 1').click();

  // scroll the list
  cy.findAllByTestId('VirtualList').first().trigger('wheel', {
    deltaX: 0,
    deltaY: 200,
  });

  cy.get('body').type('{shift}', { release: false });

  // Item 7, 8, 9, and 10 are going to be visible after the scroll
  // click on the 10th item. It's going to be clicked as soon as it's in the DOM and clickable
  cy.findByText('Item 10')
    .click()
    // Assert
    .get('@onSelect')
    .should((spy) => {
      expect(spy).to.have.been.calledTwice;
      expect(spy).to.have.been.calledWith({ newSelectedIds: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10] });
    });
});
```

The worst thing that could happen here is that the scrolling logics of the VirtualList scroll less or more when triggering the `wheel` event
```tsx
cy.findAllByTestId('VirtualList').first().trigger('wheel', {
  deltaX: 0,
  deltaY: 200,
});
```

but if it happens, the reader has a clear idea of what went wrong because of the comments 😊


## Related chapters

- 🔗 [Keep abstraction low to ease debugging the tests](/sections/generic-best-practices/test-code-with-debugging-in-mind.md)

<br/><br/>

*Crossposted by [NoriSte](https://github.com/NoriSte) on [dev.to](https://dev.to/noriste/from-unreadable-react-component-tests-to-simple-stupid-ones-3ge6).*



================================================
FILE: sections/real-life-examples/from-unreadable-react-component-tests-to-simple-ones.zh.md
================================================
[Binary file]


================================================
FILE: sections/real-life-examples/test-front-end-with-integration-back-end-with-e2e.md
================================================
# Real life example: *Test the front-end with the integration tests, the back-end with the E2E ones* - in reference to  [Component vs Integration vs E2e Testing](..//testing-strategy/component-vs-integration-vs-e2e-testing.md):

<br/><br/>

### One Paragraph Explainer

UI tests with a stubbed server are [highly reliable and faster](../testing-strategy/component-vs-integration-vs-e2e-testing.md#ui-integration-tests)<!--TODO: check that the deeplinkl works--> in comparison to full E2E tests.

Full E2E tests still provide the highest possible confidence, but at a high cost: being brittle, potentially unreliable, and slow.

We can still achieve high confidence for the front-end by using lower-cost UI integration tests and saving higher cost E2E tests for the back-end.


<br/><br/>

### Sample Test Architecture Diagram

A high-level architectural view from a real-world [Building Controls Cloud application](https://new.siemens.com/global/en/products/buildings/digitalization/building-operator.html).

* Angular front-end
* Node-Express API (back-end)
* Services (Go lambdas) (back-end)
* Hardware (back-end)

> Depending on needs, UI-E2E tests can be supplemented with pure API tests. Some popular tools for API testing are [Postman](https://www.getpostman.com/), [Rest Client for VS COde](https://marketplace.visualstudio.com/items?itemName=humao.rest-client), as well as Cypress.

![](./../../assets/images/test-architecture-example.png)

<br/>

*Please note: all the following examples are for Cypress, it has the best XHR testing support at the moment. [Full XHR request waiting and inspection is not so common](../generic-best-practices/await-dont-sleep.md#xhr-request-waitings) in the existing testing tools, Cypress provides the most complete inspection support at the moment.*

<br/>

### Code Example: Login testing

The following example has 2 tests for covering Login functionality. The first test covers the front-end application with a UI integration trest, the second test covers the back-end with an E2E test.

```javascript
/** function to fill username, password and Login*/
const fillFormAndClick = ({ username, password }) => { .. };

// This is an UI integration test with server stubbing.
// Remember to write a few E2E tests and a lot of integration ones
// @see https://github.com/NoriSte/ui-testing-best-practices/blob/master/sections/testing-strategy/component-vs-integration-vs-e2e-testing.md#ui-integration-tests
it("Login: front-end integration tests", () => {

  // A route that intercepts / sniffs every POST request that goes to the authentication URL.
  // Stubs the response with authentication-success.json fixture. This is called server stubbing
  cy.intercept({
    method: "POST",
    fixture: "authentication/authentication-success.json", // Stubs the response
    url: `**${AUTHENTICATE_API_URL}`
  }).as("auth-xhr");

  fillFormAndClick(USERNAME_PLACEHOLDER, PASSWORD_PLACEHOLDER);

  // wait for the POST XHR
  cy.wait("@auth-xhr").then(interception => {
    // assert the payload body that the front end is sending to the back-end
    expect(interception.request.body).to.have.property("username", username);
    expect(interception.request.body).to.have.property("password", password);
    // assert the request headers in the payload
    expect(interception.request.headers).to.have.property('Content-Type', 'application/json;charset=utf-8');
  });

  // finally, the user must see the feedback
  cy.getByText(SUCCESS_FEEDBACK).should("be.visible");
});

// this is a copy of the integration test but without server stubbing.
it("Login: back-end E2E tests", () => {

  // A route that intercepts / sniffs every POST request that goes to the authentication URL.
  // Distinction: this is NOT stubbed!
  cy.intercept({
    method: "POST",
    url: `**${AUTHENTICATE_API_URL}`
  }).as("auth-xhr");

  fillFormAndClick(USERNAME_PLACEHOLDER, PASSWORD_PLACEHOLDER);

  cy.wait("@auth-xhr").then(interception => {
    // since the integration tests already tested the front-end app, we use E2E tests to check the
    // back-end app. It needs to ensure that the back-end app works and gets the correct response data

    // response body assertions and status should be in the E2E tests since they rely on the server
    expect(interception.status).to.equal(200);
    expect(interception.response.body).to.have.property("token");
  });

  // finally, the user must see the feedback
  cy.getByText(SUCCESS_FEEDBACK).should("be.visible");
});
```

<br/><br/>

### Code Example 2: switching UI integration tests to UI-E2E tests

Sometimes, you may want to switch UI integration tests to E2E tests.

At lower-level test layers - for example when isolating tests to only the UI code - you may prefer to use cost-effective UI integration tests.

At higher level test layers - for example, when you integrate with intermediate level services - you may need higher confidence and target the tests to the back-end.

You can switch focus between UI integration and E2E tests by using a conditional stub.

```javascript
// stub-services.js : a file that only includes a function to stub the back-end services
export default function() {
  // all routes to the specified endpoint will respond with pre-packaged Json data
  cy.intercept('/api/../me', {fixture:'services/me.json'});
  cy.intercept('/api/../permissions', {fixture:'services/permissions.json'});
  // Lots of other fixtures ...
}

// spec file:
import stubServices from '../../support/stub-services';

/** isLocalhost is a function that checks the configuration environment*/
const isLocalHost = () => Cypress.env('ENVIRONMENT') === "localhost";

// ... in your tests, or in before / beforeEach blocks,
// stub the services if you are testing front-end (UI integration tests)
// do not stub if you are testing the back-end (UI-E2E tests)
if (isLocalHost()) {
  stubServices();
}

```


### References

[Mastering UI Testing - conference video](https://www.youtube.com/watch?v=RwWz4hllDtg)
<!-- TODO: in the end, decide if you want to move all the resources to a common chapter too -->



================================================
FILE: sections/real-life-examples/test-front-end-with-integration-back-end-with-e2e.zh.md
================================================
[Binary file]


================================================
FILE: sections/server-communication-testing/monitoring-tests.md
================================================
# Monitoring tests

<br/><br/>

### One Paragraph Explainer

The more the front-end expectations grow, the more the server and services complexity grows. Front-end applications need to be faster every day: code splitting, lazy loading, brotli compression and a lot of other performance-oriented solutions became a standard during the last years. Not to cite some amazing solutions like code splitting and resources preloading based on machine learning and analytics data. More: JAMstack site generators are useful to avoid manually managing a lot of performance optimizations but their configuration and their build processes could break an **already tested feature**.

There are a lot of features that we take for granted once tested that are not regression-free and that could lead to disasters. Some examples could be:
- `sitemap.xml` and `robots.txt` crawling configurations (usually different for every environment)
- Brotli/gzip served assets: a wrong content-encoding could break all the site functionalities
- cache management with different configurations for static or dynamic assets

They could seem obvious things but they are more subtle then what you think. If you care about the good user experience you should keep it monitored because it's usually too late when you discover that something did not work. You could not monitor everything, I know, but the more you test your applications, the more you leverage tests as your first quality checker.

Monitoring tests could also be integrated with E2E ones (after all, they are super-simple E2E tests) but keeping them separated helps you running them-only if you need. Most of the above-cited things are DevOps-related and having super-fast monitoring tests allows you to have immediate and focused feedbacks.

<br/><br/>

## Cypress examples

Cache monitoring tests

```javascript
const urls = {
  staging: "https://staging.example.com",
  production: "https://example.com",
}

const shouldNotBeCached = (xhr) => cy.wrap(xhr).its("headers.cache-control").should("equal", "public,max-age=0,must-revalidate")
const shouldBeCached = (xhr) => cy.wrap(xhr).its("headers.cache-control").should("equal", "public,max-age=31536000,immutable")
// extract the main JS file from the source code of the page
const getMainJsUrl = pageSource => "/app-56a3f6cb9e6156c82be6.js"

context('Site monitoring', () => {
  context('The HTML should not be cached', () => {
    const test = url =>
      cy.request(url)
        .then(shouldNotBeCached)

    it("staging", () => test(urls.staging))
    it("production", () => test(urls.production))
  })

  context('The static assets should be cached', () => {
    const test = url =>
      cy.request(url)
        .its("body")
        .then(getMainJsUrl)
        .then(appUrl => url+appUrl)
        .then(cy.request)
        .then(shouldBeCached)

    it('staging', () => test(urls.staging))
    it('production', () => test(urls.production))
  })
})
```

Content encoding monitoring tests

```javascript
context('The Brotli-compressed assets should be served with the correct content encoding', () => {
  const test = url => {
    cy.request(url)
    .its("body")
    .then(getMainJsUrl)
    .then(appUrl => cy.request({url: url + appUrl, headers: {"Accept-Encoding": "br"}})
      .its("headers.content-encoding")
      .should("equal", "br"))
  }

  it('staging', () => test(urls.staging))
  it('production', () => test(urls.production))
})
```

Crawling monitoring tests
```javascript
context('The robots.txt file should disallow the crawling of the staging site and allow the production one', () => {
  const test = (url, content) =>
    cy.request(`${url}/robots.txt`)
      .its("body")
      .should("contain", content)

  it('staging', () => test(urls.staging, "Disallow: /"))
  it('production', () => test(urls.production, "Allow: /"))
})
```

<br /><br />

*Crossposted by [NoriSte](https://github.com/NoriSte) on [dev.to](https://dev.to/noriste/the-concept-of-monitoring-tests-4l5j) and [Medium](https://medium.com/@NoriSte/the-concept-of-monitoring-tests-d7cb5af514e5).*



================================================
FILE: sections/server-communication-testing/monitoring-tests.zh.md
================================================
[Binary file]


================================================
FILE: sections/server-communication-testing/test-request-and-response-payload.md
================================================
# Test the request and response payloads

<br/><br/>

### One Paragraph Explainer

How many times the front-end application stops working because of a misaligned communication with the back-end?

The front-end application and the back-end one have a contract, and you always need to test contract compliance. Every communication between the two apps is defined by:

- its URL
- the HTTP verb used (GET, POST, etc.)
- the request payload and headers: the data that the front-end application sends to the back-end one
- the response payload, headers, and status: the data that the back-end application sends back to the front-end one

You need to test all of them and, more in general, you need to wait for every relevant AJAX request, why?

- a relevant XHR request is part of the application flow that you're testing
- if an XHR request is not part of the flow that you're testing, it could be relevant to reach the desired UI state
- waiting for XHR requests make your test more robust, see the [Await, don't sleep](/sections/generic-best-practices/await-dont-sleep.md) chapter and its [XHR request waitings](/sections/generic-best-practices/await-dont-sleep.md#xhr-request-waitings) section

Full XHR request waiting and inspection is not so common in the existing testing tools, Cypress provides the most complete inspection support at the moment.

<br/><br/>

*Please note: all the following examples are for Cypress, it has the best XHR testing support at the moment.*

## Asserting about an XHR request, a complete example

```javascript
// ask Cypress to intercept every XHR request made to a URL ending with `/authentication`
cy.intercept("POST", "**/authentication").as("authentication-xhr");

// ... your test actions...

cy.wait("@authentication-xhr").then(interception => {
  // request headers assertion
  expect(interception.request.headers).to.have.property("Content-Type", "application/json");
  // request payload assertions
  expect(interception.request.body).to.have.property("username", "admin");
  expect(interception.request.body).to.have.property("password", "asupersecretpassword");
  // status assertion
  expect(interception.response.statusCode).to.equal(200);
  // response headers assertions
  expect(interception.response.body).to.have.property("access-control-allow-origin", "*");
  // response payload assertions
  expect(interception.response.body).to.have.property("token");
});
```

In the next sections, we are going to split the different characteristics of an XHR request.





<details><summary>Asserting about the XHR request URL</summary>

With Cypress, the URL used for the request is defined with the `cy.intercept` call. You could need to inspect the query string of the URL.

```javascript
// ask Cypress to intercept every XHR request made to a URL ending with `/authentication`
cy.intercept("**/authentication**").as("authentication-xhr");

// ... your test actions...

cy.wait("@authentication-xhr").then(interception => {
  // query string assertion
  expect(interception.request.url).to.contain("username=admin");
  expect(interception.request.url).to.contain("password=asupersecretpassword");
});
```

Please note that the `then => expect` syntax of Cypress is helpful when you need to assert about multiple subjects (ex. both the URL and the status). If you need to assert about a single subject you could use more expressive `should` syntax

```javascript
cy.wait("@authentication-xhr")
  .its("url")
  .should("contain", "username=admin")
  .and("contain", "password=asupersecretpassword");
```
</details>





<details><summary>The XHR request method</summary>

With Cypress, the method used for the request is defined calling the `cy.intercept` function. You specify it to define what kind of request you want to intercept.

```javascript
// the most compact `cy.intercept` call, the GET method is implied
cy.intercept("**/authentication").as("authentication-xhr");

// method can be explicitly defined
cy.intercept("POST", "**/authentication").as("authentication-xhr");

// the extended `cy.intercept` call is available too
cy.intercept({
  method: "POST",
  url: "**/authentication"
}).as("authentication-xhr");
```
</details>





<details><summary>Asserting about the XHR request payload and headers</summary>

Asserting about the request payload and headers allows you to have immediate and detailed feedback about the reason for a bad XHR request. They must be checked on every single XHR request to be sure that everything represents correctly the UI actions the test makes.

```javascript
// ask Cypress to intercept every XHR request made to a URL ending with `/authentication`
cy.intercept("POST", "**/authentication").as("authentication-xhr");

// ... your test actions...

cy.wait("@authentication-xhr").then(interception => {
  // request headers assertion
  expect(interception.request.headers).to.have.property("Content-Type", "application/json");
  // request payload assertions
  expect(interception.request.body).to.have.property("username", "admin");
  expect(interception.request.body).to.have.property("password", "asupersecretpassword");
});
```
</details>




<details><summary>Asserting about the XHR response payload, headers, and status</summary>

The response must adhere 100% to what the front-end application expects, otherwise, an unexpected state could be shown to the user. Response assertions are useful for full E2E tests, while they're useless in UI integration tests (TODO: link the integration test page).

```javascript
// ask Cypress to intercept every XHR request made to a URL ending with `/authentication`
cy.intercept("POST", "**/authentication").as("authentication-xhr");

// ... your test actions...

cy.wait("@authentication-xhr").then(intercept => {
  // status assertions
  expect(intercept.response.statusCode).to.equal(200);
  // response headers assertions
  expect(intercept.response.body).to.have.property("access-control-allow-origin", "*");
  // response payload assertions
  expect(intercept.response.body).to.have.property("token");
});
```
</details>



================================================
FILE: sections/server-communication-testing/test-request-and-response-payload.zh.md
================================================
# 检验请求和响应负载

<br/><br/>

## 一段简要说明

前端应用因与后端通信不协调而导致停止工作的频率有多高？

前端应用和后端应用之间存在一份合同，你始终需要测试合同是否得到遵守。每一次前后端应用之间的通信都由以下几个方面定义：

- 请求的 URL
- 所使用的 HTTP 动词（GET、POST 等）
- 请求的有效负载和标头：前端应用发送给后端应用的数据
- 响应的有效负载、标头和状态：后端应用发送回前端应用的数据

你需要对所有这些方面进行测试，更广义地说，你需要等待每个相关的 AJAX 请求，为什么呢？

- 相关的 XHR 请求是你正在测试的应用程序流程的一部分
- 即使 XHR 请求不是你正在测试的流程的一部分，它对达到期望的 UI 状态也可能是相关的
- 等待 XHR 请求可以使你的测试更为健壮，参见[等待，不要休眠](/sections/generic-best-practices/await-dont-sleep.zh.md)章节及其[XHR 请求等待](/sections/generic-best-practices/await-dont-sleep.zh.md#XHR-请求等待)部分

在现有的测试工具中，完全等待和检查 XHR 请求并不那么常见，目前 Cypress 提供了最全面的检查支持。

<br/><br/>

*请注意：以下所有示例均基于 Cypress，它目前提供了最佳的 XHR 测试支持。*

## 对 XHR 请求进行断言的完整示例

```javascript
// ask Cypress to intercept every XHR request made to a URL ending with `/authentication`
cy.intercept("POST", "**/authentication").as("authentication-xhr");

// ... your test actions...

cy.wait("@authentication-xhr").then(interception => {
  // request headers assertion
  expect(interception.request.headers).to.have.property("Content-Type", "application/json");
  // request payload assertions
  expect(interception.request.body).to.have.property("username", "admin");
  expect(interception.request.body).to.have.property("password", "asupersecretpassword");
  // status assertion
  expect(interception.response.statusCode).to.equal(200);
  // response headers assertions
  expect(interception.response.body).to.have.property("access-control-allow-origin", "*");
  // response payload assertions
  expect(interception.response.body).to.have.property("token");
});
```

在下面的章节中，我们将详细讨论 XHR 请求的不同特征。

<details><summary>验证 XHR 请求的 URL</summary>

在 Cypress 中，用于请求的 URL 是通过`cy.intercept`调用定义的。你可能需要检查 URL 的查询字符串。

```javascript
// ask Cypress to intercept every XHR request made to a URL ending with `/authentication`
cy.intercept("**/authentication**").as("authentication-xhr");

// ... your test actions...

cy.wait("@authentication-xhr").then(interception => {
  // query string assertion
  expect(interception.request.url).to.contain("username=admin");
  expect(interception.request.url).to.contain("password=asupersecretpassword");
});
```

请注意，当你需要对多个主题进行断言时，Cypress 的`then => expect`语法非常有帮助（例如，URL 和状态）。如果你只需要对单个主题进行断言，可以使用更具表现力的`should`语法。

```javascript
cy.wait("@authentication-xhr")
  .its("url")
  .should("contain", "username=admin")
  .and("contain", "password=asupersecretpassword");
```

</details>

<details><summary>XHR 请求的方法</summary>

在 Cypress 中，请求使用`cy.intercept`函数定义。你可以通过指定它来定义要拦截的请求类型。

```javascript
// the most compact `cy.intercept` call, the GET method is implied
cy.intercept("**/authentication").as("authentication-xhr");

// method can be explicitly defined
cy.intercept("POST", "**/authentication").as("authentication-xhr");

// the extended `cy.intercept` call is available too
cy.intercept({
  method: "POST",
  url: "**/authentication"
}).as("authentication-xhr");
```

</details>

<details><summary>验证 XHR 请求的 payload 和 headers</summary>

对 XHR 请求的 payload 和 headers 进行断言允许你立即获得有关糟糕的 XHR 请求原因的详细反馈。必须在每个 XHR 请求上进行检查，以确保一切都正确地表示了测试执行的 UI 操作。

```javascript
// ask Cypress to intercept every XHR request made to a URL ending with `/authentication`
cy.intercept("POST", "**/authentication").as("authentication-xhr");

// ... your test actions...

cy.wait("@authentication-xhr").then(interception => {
  // request headers assertion
  expect(interception.request.headers).to.have.property("Content-Type", "application/json");
  // request payload assertions
  expect(interception.request.body).to.have.property("username", "admin");
  expect(interception.request.body).to.have.property("password", "asupersecretpassword");
});
```

</details>

<details><summary>验证 XHR 请求响应的 payload, headers 和 status</summary>

响应必须百分之百符合前端应用的预期，否则可能向用户展示意料之外的状态。响应断言在完整的端到端测试中很有用，但在 UI 集成测试中则无关紧要（TODO：链接到集成测试页面）。

```javascript
// ask Cypress to intercept every XHR request made to a URL ending with `/authentication`
cy.intercept("POST", "**/authentication").as("authentication-xhr");

// ... your test actions...

cy.wait("@authentication-xhr").then(intercept => {
  // status assertions
  expect(intercept.response.statusCode).to.equal(200);
  // response headers assertions
  expect(intercept.response.body).to.have.property("access-control-allow-origin", "*");
  // response payload assertions
  expect(intercept.response.body).to.have.property("token");
});
```

</details>



================================================
FILE: sections/testing-perks/tests-as-documentation.md
================================================
# Software tests as a documentation tool

<br/><br/>

### One Paragraph Explainer

Documenting is generally hard, it requires precise and meticulous work and it requires that all the members of the team understand and value writing good documentation. Documenting is selfless and it is **helpful for both other developers and the future you**.

Testing methodologies are a great way not only to be sure that we code what the project needs, not only to grant we do not introduce regressions but to document the code and the user flows too.

The perks that come from using the tests as a documentation tool are:

- **the documentation is coupled** with what the code has been created for: all the UI tests should be written from the user perspective and their descriptions either. Watching what the user is able to do with the project is a really effective way to know the project from a functional point of view.<br>Every codebase is composed of thousands of small pieces of code and sometimes **it could be hard to connect all the dots**. The tests could allow a general understanding of the project and even a lot of technical details.

  <!-- TODO: add a link to the blackbox testing chapter -->

- you do **not rely on the historical memory** of some employees: a lot of times you end up asking to some employees that know the project and remember some particular edge cases. A good test suite can reduce a lot the needed for this kind of knowledge and avoid every fresh developer to add regressions with a few lines of code.

- at the same time, the **handover and onboarding** phases become quite easy.

Bonus point: if you leverage the [Gherkin](https://cucumber.io/docs/gherkin/reference/) syntax, the documentation effectiveness is increased even for some less-technical people like a QA team.

Please, keep in mind that:

- test descriptions must be clear even for developers that do not know the project context the same way as you.

- the re-used test functions, fixtures, etc. must have meaningful names. A `registration-success.json` fixture used for both the sign-up and the login tests could mislead the future reader and make historical knowledge needed. Remember that relying on historical knowledge is always negative for a codebase that must survive the developers' turnover.

- in general, UI Testing plays a fundamental role in a front-end application, they are the only ones that document the real goals the user is expected to be able to accomplish.

- the code of the tests must as simple as possible. Simple to be read, condition-free, with a low-abstraction level, with a good level of logging, etc. Always remember that **the tests must reduce the cognitive load of reading and understanding the code**, hence their complexity should be an order of magnitude lower compared to the code to be understood. This improves the deepening process that a developer must go through just after have watched the tests in the automated browser.

  <!-- TODO: add a link to the chapter that speaks about why the test code must be simple -->

- "connect" the code with the tests: if a user flow is quite long, it could be useful to share some "steps" (with some comments) between the source code and the code of the tests. Something like `/** #1 \*/`, `/** #2 \*/`, etc.

- UI tests are not the only ones: having more low-level tests for parts of the code that could be hard to be understood is a great way to describe the code expected behaviors.

- comments in the test could help a lot the reader, look at the ["Matching the test's code and test runner's commands" section of the "Keep abstraction low to ease debugging the tests" chapter](../generic-best-practices/test-code-with-debugging-in-mind.md#matching-the-tests-code-and-test-runners-commands).

## Related chapters

- 🔗 [Found a bug? Write the test, then fix it](/sections/testing-strategy/write-test-then-fix-bug.md)
- 🔗 [Name the test files wisely](/sections/generic-best-practices/name-test-files-wisely.md)
- 🔗 [Use your testing tool as your primary development tool](/sections/generic-best-practices/use-your-testing-tool-as-your-primary-development-tool.md)
- 🔗 [Keep abstraction low to ease debugging the tests](/sections/generic-best-practices/test-code-with-debugging-in-mind.md)
- 🔗 [Test the request and response payloads](/sections/server-communication-testing/test-request-and-response-payload.md)



================================================
FILE: sections/testing-perks/tests-as-documentation.zh.md
================================================
[Binary file]


================================================
FILE: sections/testing-strategy/avoid-perfectionism.md
================================================
# In the beginning, avoid perfectionism

<br/>

### One Paragraph Explainer

Testing really changes the way you work but, like everything, it requires a bit of experience to get the best of it. In the beginning, avoid perfectionism at all. Why?

- tests are little programs after all. Perfectionism could drive you to write **extremely complex tests** before knowing how to manage the different testing contexts.

  Tests complexity is a big enemy because debugging a failing test is harder than debugging a failing application. And complex tests make you lose the advantage of testing practices themselves, make you lose a lot of time, and inevitably make you exclude them sooner or later. **If it happens to you don't give up**, it's the same for a lot of testing beginners (it was the same for me, that's why I started writing this repo 😊) and do not be afraid of asking your colleagues or publicly to other developers.

- false negatives: perfectionism-driven tests lead to a lot of false negatives. A false negative is a situation where your application works as expected but the test fails.

  **False negatives are really de-motivating** at the beginning because you started writing tests to have an ally in checking the application status... But you ended up with another application to maintain with no help from the tests. If you realize you are fighting with false negatives, stop yourself, restart studying and ask for help!

- tests utility: successful tests drive you directly to the problem when they fail. The right assertions and [deterministic events](/sections/generic-best-practices/await-dont-sleep.md) make your tests robust and, super important, useful if they fail. At the opposite, too much assertions/checks could make your tests brittle because of their uselessness

What do you mean for perfectionism? I mean checking every front-end detail. Your working experience allows you to write complex user interactions but, in the beginning, your limited testing experience do not allow you to test all of the interactions profitably. Start testing the easiest things like
- is my page loading correctly?
- do the menu buttons works?
- can the user fill the form and reach the thank you page?

and forget, in the beginning, to test things like
- conditional data loading
- complex form rules
- uncontrolled (third party) integrations
- element selectors

<br />

A beginning todo list to avoid falling into the perfectionism trap could be:

1. choose the simplest thing to test (something that's useful for the users)
2. think about it from the users perspective. Remember that the **users care about contents and functionalities**, not about selectors and internal application states
3. write your test
4. run it more than once to be sure that it's stable
5. when it succeeds, insert a bug into the front-end app that breaks it and checks that the test fails. Then, remove your made-on-purpose bug
6. run the test both in headless and non-headless mode
7. think about, based on your experience (ask your colleagues too), what are the reasons that could break the front-end application from the perspective of what you're testing
8. simulate the different front-end failures (kill the server, insert other bugs) and check if the test gives you enough feedback to understand what failed
9. do that for just two or three kinds of failures, remember that your limited experience could drive you to test the wrong things
10. then, move to another thing to test and repeat all the previous steps

Software testing is an amazing journey and the goal of this repo is helping you avoid the most common pitfalls.

The suggested flow is just one of the possible approaches. I know that everything is subjective and please, open a PR for every suggestion!

## Related chapters

- 🔗 [From unreadable React Component Tests to simple, stupid ones](/sections/real-life-examples/from-unreadable-react-component-tests-to-simple-ones.md)
- 🔗 [Use your testing tool as your primary development tool](/sections/generic-best-practices/use-your-testing-tool-as-your-primary-development-tool.md)



================================================
FILE: sections/testing-strategy/avoid-perfectionism.zh.md
================================================
[Binary file]


================================================
FILE: sections/testing-strategy/choose-a-reference-browser.md
================================================
# Choose a reference browser

<br/>

### One Paragraph Explainer

Everyone cares about cross-browser testing. We are used to manually testing everything on every browser because, we know, there are a lot of browser differences. Obviously, we'd like to have the same cross-browser support from the tool we use to test our front-end application... But the reality is that cross-browser support is very limited.

Don't take for granted that testing everything on every browser is always the best solution. Try to think about what you need to test before choosing a testing tool. Think that:

- **Selenium, and Puppeteer are generic automation tools**. They can be used as testing tools (there are a lot of plugins and modules that help you do that) but they are not created with testing in mind so they miss some integrated utilities that could simplify your life as a test writer.

- consider only **Cypress, Playwright, and TestCafé** because they are both tools created to **simplify the UI testing process**. Half of the best practices you should care in your tests are automatically managed by Cypress/Playwright/TestCafé out of the box. Choosing the right testing tool is all about finding the right trade-off. UI testing is hard by definition so, spend some time experimenting with the mentioned tools.

- think about what you need to test. Choose [TestCafé](https://testcafe.devexpress.com) if you need to test a particular mobile capability, but if you need to test that the forms and the buttons work you are less limited with your choice.

- take a look at the [Cypress Test Runner](https://docs.cypress.io/guides/core-concepts/test-runner.html#Command-Log), it's what makes Cypress outstanding and it's a precious ally during test development.

- take a look at what [Playwright offers in terms of debugging](https://playwright.dev/docs/trace-viewer-intro). Playwright is very fast and stable, and its DX improved a lot recently.

- cross-browser testing is usually related to visual testing (CSS browser differences) but this is not related to functional testing. Visual testing is made easy by a lot of dedicated plugins and tools. Take a look at [the dedicated chapter](../tools/visual-regression-testing.md) [Applitools](https://applitools.com) where we talk about some dedicated products that can be integrated with almost all the testing tools and work by uploading a snapshot of the page under test into their servers and render them.

You can also take a sneak peek at some differences between the various testing tools into the [Await, don't sleep](/sections/generic-best-practices/await-dont-sleep.md) chapter.

## Related chapters

- 🔗 [Combinatorial Testing](/sections/advanced/combinatorial-testing.md)



================================================
FILE: sections/testing-strategy/choose-a-reference-browser.zh.md
================================================
# 选择一个参考浏览器

<br/>

## 一段简要说明

每个人都关心跨浏览器测试。我们通常习惯在每个浏览器上手动测试所有内容，因为我们知道，不同浏览器之间存在许多差异。当我们开始评估合适的测试工具时，跨浏览器测试是一个重要的话题，也是你在考虑时可能首先想到的。但是不要担心：首先从功能测试和视觉测试分离开始，这是正确评估跨浏览器支持需求（也是选择正确测试工具的第一步）。视觉测试可以集成到每个测试工具中，感谢诸如 Applitools 和 Percy 这样的服务。

换句话说，不要仅仅基于跨浏览器支持来选择测试工具。以下是一些建议：

- **Selenium 和 Puppeteer 是通用的自动化工具**。它们可以用作测试工具（有许多插件和模块可帮助你实现），但它们并非专为测试而设计，因此它们缺少一些集成实用工具，这可能使测试编写更加简便。

- 只考虑 **Cypress、Playwright 和 TestCafé**，因为它们是专为**简化 UI 测试过程**而创建的工具。这些工具自动处理一半的最佳实践，而在测试中的一些方面，它们可能更符合你的需求。在 UI 测试方面，由于其

困难性，花些时间试验这些工具是值得的。

- 仔细思考你需要测试什么。如果你需要测试特定的移动能力，请选择 [TestCafé](https://testcafe.devexpress.com)，但如果你只需要测试表单和按钮是否正常工作，你在选择上就更加灵活。

- 查看 [Cypress Test Runner](https://docs.cypress.io/guides/core-concepts/test-runner.html#Command-Log)，这是使 Cypress 异于常人的工具，对于测试开发过程中非常有帮助。

- 研究 [Playwright 在调试方面的优势](https://playwright.dev/docs/trace-viewer-intro)。Playwright 非常快速稳定，最近其开发体验有了很大改进。

- 跨浏览器测试通常涉及到视觉测试（CSS 浏览器差异），但这与功能测试不同。视觉测试得益于许多专用插件和工具的支持。详细了解 [视觉测试对应的章节](../tools/visual-regression-testing.zh.md) [Applitools](https://applitools.com)，其中我们讨论了一些专用产品，这些产品可以与几乎所有测试工具集成，通过将被测试页面的快照上传到其服务器并进行呈现来进行工作。

你还可以在 [等待，不是休眠](/sections/generic-best-practices/await-dont-sleep.zh.md) 章节中了解各种测试工具之间的一些差异。

## 相关章节

- 🔗 [组合测试](/sections/advanced/combinatorial-testing.zh.md)



================================================
FILE: sections/testing-strategy/component-vs-integration-vs-e2e-testing.md
================================================
# Component vs (UI) Integration vs E2E tests

<br/>

### One Paragraph Explainer

Speaking about UI Testing (remember that we are speaking about the UI only, not the underlying JavaScript code), there are three main test types:
- **Component tests**: the unit tests of a UI, they test every single component in an isolated environment.

  Developing components in isolation is important because it allows you to isolate them from the corresponding container/use. A component exists to isolate a single behavior/content (the [Single responsibility principle](https://www.wikiwand.com/en/Single_responsibility_principle)) and therefore, coding it in isolation is profitable.

  There are many ways and tools to develop components in isolation but [Storybook](https://storybook.js.org) became the standard choice because of its effectiveness and its ecosystem. The latest Storybook versions wrap the excellent [Vitest Browser Mode](https://vitest.dev/guide/browser/), which is the fastest way to test UI components in isolation.

  Components have three types of contracts: the exposed data (**HTML**), their visual aspect (**CSS**), and the external APIs (**props and callbacks**). Testing every aspect could be cumbersome, that's where [Storybook](https://storybook.js.org/) comes in handy. It allows you to automate:
  - **the a11y (accessibility) tests**: HTML serves different purposes, SEO and a11y for example, and testing the accessibility of the HTML is the most thorough way to ensure HTML is semantically correct and maintain a high-level of compatibility with screen readers. As a result, SEO benefits too.
  - **the visual regression tests**: the visual aspect of the component compared **pixel by pixel** with the previous one, again, you are prompted to choose if you accept the changes or not.
  - **the interaction tests**: some interactions with a component expect correct state management. This kind of test must be written from the consumer point of view, not from the inner one (ex. the value of the input field when the user fills it, not the inner component state). An interaction/state test should assert the input field value after the keyboard events triggered. If the callbacks accepted by the component are correctly called is testable through this type of tests.


- <strong id="ui-integration-tests">UI integration tests</strong>: they run the whole app in a real browser **without hitting a real server**. These tests are the ace in the hole of every front-end developer. They are blazing fast and less exposed to random failures or false negatives.

  The front-end application does not know that there is not a real server: every AJAX call is resolved in no time by the testing tool. Static JSON responses (called "fixtures") are used to simulate the server responses. Fixtures allow us to test the front-end state simulating every possible back-end state.

  Another interesting effect: Fixtures **allow you to work without a working back-end** application. You can think about UI integration tests as "front-end-only tests".

  At the core of the most successful test suites, there is a lot of UI integration tests, considering the best type of test for your front-end app.

- **End-to-end (E2E) tests**: they run the whole app interacting with the real server. From the user interactions (one of the "end") to the business data (the other "end"): everything must work as designed. E2E tests are typically slow because
  - they need a **working back-end** application, typically launched alongside the front-end application. You can't launch them without a server, so you depend on the back-end developers to work
  - they need **reliable data**, seeding and cleaning it before every test

  That's why E2E tests are not feasible to be used as the only/main test type. They are pretty important because they are testing everything (front-end + back-end) but they must be used carefully to avoid brittle and hour-long test suites.

  In a complete suite with a lot of UI integration tests, you can think about E2E tests as "back-end tests". What flows should you test through them?
  - the Happy Path flows: you need to be sure that, at least, the users are able to complete the basic operations
  - everything valuable for your business: happy path or not, test whatever your business cares about (prioritizing them, obviously)
  - everything that breaks often: weak areas of the system must be monitored too

Identifying/defining the type of test is useful to group them, to [name the test files](/sections/generic-best-practices/name-test-files-wisely.md), to limit their scope, and to choose where to run them or not though the whole application and deployment pipelines.

<br /><br />

*Crossposted by [NoriSte](https://github.com/NoriSte) on [dev.to](https://dev.to/noriste/component-vs-ui-integration-vs-e2e-tests-3i0d) and [Medium](https://medium.com/@NoriSte/component-vs-ui-integration-vs-e2e-tests-f02b575339dc).*



================================================
FILE: sections/testing-strategy/component-vs-integration-vs-e2e-testing.zh.md
================================================
[Binary file]


================================================
FILE: sections/testing-strategy/small-tests-or-long-ones.md
================================================

# One long E2E test or small, independent ones?

<br/><br/>

### One Paragraph Explainer


While speaking about testing a CRUD app, how should we organize the "create", "modify", and "delete" E2E tests?

The complete list of options are:

1. To have **three small E2E tests dependent on the execution order** (test B takes for granted that test A run) - The only bad solution, I'm going to explain why.
2. To have **three small E2E tests independent from the execution order** (test B works regardless from whether test A was launched or not) - Theoretically, the best solution. Still, it requires a lot of boilerplates also to be fast.
3. To have **one extended E2E test** that does everything - A good tradeoff for the case presented in this article.

It depends, and most of the problems I present are related to the implicit issues of the E2E tests, a strong signal that we should write only a few of them. As a Front-end Engineer, I strongly prefer to invest my time in server-free tests, not E2E ones. Go ahead, and you will understand why.

Please note: this results from working on Hasura's Console E2E tests.

<br/><br/>



## 1 - To have three small E2E tests dependent on the execution order (test B takes for granted that test A run)

The test flow would be something like this:

1. START (*the application state is empty*)
2. Test 1: create the entity
3. Test 2: modify the entity
4. Test 3: delete the entity
5. END (*the application state is empty*)

In this case, the tests are not independent but based on execution order. To test a CRUD flow, the three primary tests are "create an entity", "modify an entity", "delete the entity". The second test ("modify the entity") takes for granted that when it starts, the application state is okay because it runs after the "create the entity" one. "delete the entity" must run after the "modify the entity" too, etc.

Coupling multiple tests together is an anti-pattern because of:

- **False negatives**: The tests will fail in a row once one fails.
- **Hard to debug**: understanding the root of a failure is more complicated because of higher ambiguity. Did the test fail because of its code? Or because the state of the previous test changed? Then, you have to debug two tests when one fails.
- **Hard to debug** (again): the developers waste a lot of time because they can not run a single test nor use `skip` and `only` to launch a portion of them.
- **Hard to refactor**: The tests cannot be moved elsewhere. If the code of the tests becomes too long, too complex, etc., you cannot move it to a dedicated file/directory because it depends on the previous one.
- **Hard to read**: The readers cannot know what a test does because they must also know the previous tests. You have to read two tests instead of one, which is not good.

I do not recommend writing tests coupled this way, but I want to include them to be sure you realize why.

## 2 - To have three small E2E tests independent from the execution order

To get every test independent, every test should create the application state that it needs to run, then clear it after completion. The flow presented in the previous chapter should become something like (in *italic* the new steps compared to the original create->modify->delete three tests in a row)

1. START (*the application state is empty*)
2. Test 1: create the entity
    1. ***BEFORE****: Load the page (the application state is empty)*
    2. create the entity
    3. ***AFTER****: Delete the *entity* (the application state is empty)*
3. Test 2: modify the entity
    1. ***BEFORE****: create the *entity* (through APIs)*
    2. ***BEFORE****: Load the page (the application state is empty)*
    3. modify the entity
    4. ***AFTER****: Delete the *entity* (through APIs, the application state is empty)*
4. Test 3: delete the entity
    1. ***BEFORE****: create the *entity* (through APIs)*
    2. ***BEFORE****: Load the page (the application state is empty)*
    3. delete the entity
    4. ***AFTER****: Delete the action (the application state is empty)*
5. END (*the application state is empty*)

By doing so, every test is independent. Please note that the before and after actions are done directly by calling the server APIs. Doing them through the UI would be too slow.

Anyway, the presented approach's problem is that **tests become slower** because every test creates the entity, and every test visits the page. When the application takes 10 seconds to load (it was initially the case of Hasura's Console), reloading the app is a problem.

To get the best of both worlds (independent but fast tests), we should evolve the above flow to

- Exploit the previous test's application state.
- But also create the needed application state if no tests have run.

Something like (in *italic* the new steps compared to the flow presented in the previous chapter)

1. START (*the application state is empty*)
2. Test 1: create the entity
    1. ***BEFORE****: Does the *entity* exist?*
        1. *NO: it's ok!*
        2. *YES: delete the entity (through APIs)*

    2. **BEFORE**: Load the page (the application state is empty)
    3. create the entity
3. Test 2: modify the entity
    1. ***BEFORE****: Does the *entity* exist?*
        1. *YES: it's ok!*
        2. *NO: create the entity (through APIs)*
    2. ***BEFORE****: Does the *entity* already includes the change the test is going to make?*
        1. *YES: it's ok!*
        2. *NO: modify the entity (through APIs)*
    3. ***BEFORE****: Are we already on the correct page?*
        1. *YES: it's ok!*
        2. *NO: load the page*
    4. modify the entity
4. Test 3: delete the entity
    1. ***BEFORE****: Does the entity exist?*
        1. *YES: it's ok!*
        2. *NO: create the entity (through APIs)*
    2. ***BEFORE****: Are we already on the correct page?*
        1. *YES: it's ok!*
        2. *NO: load the page*

5. delete the entity
6. END

Now, if you run all the tests in a row, each of them leverages the existing application state. If you run just the "modify the entity" for instance, it creates whatever it needs, then runs the test itself.

Now we have both test independence and test performance! Cool!

Well... Did you notice the amount of code we need to write? The [cypress-data-session](https://github.com/bahmutov/cypress-data-session) plugin comes in handy but

1. You have a lot of cypress-data-session related boilerplate
2. You have to maintain, in the E2E tests, a lot of API calls that could go out of sync with the ones used in the main application in a while

Here is an example of the cypress-data-session related boilerplate (coming from the Hasura Console codebase)

```ts
import { readMetadata } from '../services/readMetadata';
import { deleteHakunaMatataPermission } from '../services/deleteHakunaMatataPermission';

/**
 * Ensure the Action does not have the Permission.
 *
 * ATTENTION: if you get the "setup function changed for session..." error, simply close the
 * Cypress-controlled browser and re-launch the test file.
 */
export function hakunaMatataPermissionMustNotExist(
  settingUpApplicationState = true
) {
  cy.dataSession({
    name: 'hakunaMatataPermissionMustNotExist',

    // Without it, cy.dataSession run the setup function also the very first time, trying to
    // delete a Permission that does not exist
    init: () => true,

    // Check if the Permission exists
    validate: () => {
      Cypress.log({ message: '**--- Action check: start**' });

      return readMetadata().then(response => {
        const loginAction = response.body.actions?.find(
          action => action.name === 'login'
        );

        if (!loginAction || !loginAction.permissions) return true;

        const permission = loginAction.permissions.find(
          permission => permission.role === 'hakuna_matata'
        );

        // Returns true if the permission does not exist
        return !permission;
      });
    },

    preSetup: () =>
      Cypress.log({ message: '**--- The permission must be deleted**' }),

    // Delete the Permission
    setup: () => {
      deleteHakunaMatataPermission();

      if (settingUpApplicationState) {
        // Ensure the UI read the latest data if it were previously loaded
        cy.reload();
      }
    },
  });
}

```

and here is an example of the API call to create the entity (coming from the Hasura Console codebase)

```ts
/**
 * Create the Action straight on the server.
 */
export function createLoginAction() {
  Cypress.log({ message: '**--- Action creation: start**' });

  cy.request('POST', 'http://localhost:8080/v1/metadata', {
    type: 'bulk',
    source: 'default',
    args: [
      {
        type: 'set_custom_types',
        args: {
          scalars: [],
          input_objects: [
            {
              name: 'SampleInput',
              fields: [
                { name: 'username', type: 'String!' },
                { name: 'password', type: 'String!' },
              ],
            },
          ],
          objects: [
            {
              name: 'SampleOutput',
              fields: [{ name: 'accessToken', type: 'String!' }],
            },
            {
              name: 'LoginResponse',
              description: null,
              fields: [
                {
                  name: 'accessToken',
                  type: 'String!',
                  description: null,
                },
              ],
            },
            {
              name: 'AddResult',
              fields: [{ name: 'sum', type: 'Int' }],
            },
          ],
          enums: [],
        },
      },
      {
        type: 'create_action',
        args: {
          name: 'login',
          definition: {
            arguments: [
              {
                name: 'username',
                type: 'String!',
                description: null,
              },
              {
                name: 'password',
                type: 'String!',
                description: null,
              },
            ],
            kind: 'synchronous',
            output_type: 'LoginResponse',
            handler: 'https://hasura-actions-demo.glitch.me/login',
            type: 'mutation',
            headers: [],
            timeout: 25,
            request_transform: null,
          },
          comment: null,
        },
      },
    ],
  }).then(() => Cypress.log({ message: '**--- Action creation: end**' }));
}
```

So, having independent tests is essential, but it comes with a cost.

That's why, for this specific problem, I then opted for the last option...

## 3 - To have one extended E2E test that does everything

Pros: a lot of boilerplate files can be removed.

Cons: Working with the tests becomes slower (you cannot launch only the third test anymore)

Compared to the boilerplate we need to write and the code we need to maintain, it is worth unifying them. After all, the specific CRUD flow I was working on took ~20 seconds.

1. START (*the application state is empty*)
2. Test: CRUD
  1. ***BEFORE****: Delete the entity if it exists (the application state is empty)*
  2. ***BEFORE****: Load the page*
  3. create the entity
  4. modify the entity
  5. delete the entity
  6. ***AFTER****: Delete the entity if it exists (the application state is empty)*
3. END (*the application state is empty*)

And at the same time, it makes cypress-data-session useless. Hence one less dependency to keep updated.

## Conclusions

Working with E2E tests is hard. Dealing with real data, real application state to clear, etc., has a cost. I know that E2E tests are the only ones that give complete confidence, but as a Front-end Engineer (remember, I'm not a QA Engineer), I strongly prefer to work with server-free tests.


## Related chapters


- 🔗 [Component vs (UI) Integration vs E2E tests](/sections/testing-strategy/component-vs-integration-vs-e2e-testing.md)
- 🔗 [Approach the testing pyramid from the top!](/sections/beginners/top-to-bottom-approach.md)
- 🔗 [Use your testing tool as your primary development tool](/sections/generic-best-practices/use-your-testing-tool-as-your-primary-development-tool.md)
<br/><br/>

*Crossposted by [NoriSte](https://github.com/NoriSte) on [dev.to](https://dev.to/noriste/decouple-the-back-end-and-front-end-test-through-contract-testing-112k).*



================================================
FILE: sections/testing-strategy/small-tests-or-long-ones.zh.md
================================================
[Binary file]


================================================
FILE: sections/testing-strategy/write-test-then-fix-bug.md
================================================
# Found a bug? Write the test, then fix it

<br/>

### One Paragraph Explainer

So, you have found a bug in your front-end application and you have already debugged it. You can reproduce it systematically and you're ready to fix it. A testing-oriented mind must pass through these steps:
1. identify the expected behavior
2. write a test that aims to consume the front-end application the correct way
3. the test must fail, obviously, because the bug does not allow the user to perform his task
4. fix the bug
5. check that the test now passes

What are the advantages of this approach? Why should you write a test? I know that fixing the bug without a test could seem faster but consider that:

- as usual, your testing tool is faster than you to reach the state of the application that shows the bug (see the [Use your testing tool as your primary development tool](/sections/generic-best-practices/use-your-testing-tool-as-your-primary-development-tool.md) chapter)

- sometimes you think that you're able to reproduce the bug systematically, but it's not always true. Writing a test that unearths the bug make you 100% sure that the bug is reproducible **excluding a lot of deviant variables** like existing sessions, caches, service workers, browser extensions, browser version, etc. that could influence your confidence. Sometimes you discover that you did not identify the bug correctly

- at the same time, when the test passes thanks to your fix, you are really sure that your solution works as expected. The same variables that could influence your bug identification process could mine the false sense of the job's effectiveness

- **with a test, the bug is fixed forever!** The test will be run thousands of times and let you sleep well about that forever

- a successful test could be used as a proven track of the work you've done

Last but not least: be sure that the test you write fails at the beginning! And that it fails because of the bug!<br/>
The test is not useful only to reproduce the bug and check it visually, but it must put you in the position of having positive feedback after the bug fixing process. **A bug-related test that does not fail is really dangerous** because you can think that you've made a good job when the reality is that you have not reproduced the bug correctly since the beginning.

As a general rule: **a broken flow must have a broken test**, a successful test must be related to a working app.



================================================
FILE: sections/testing-strategy/write-test-then-fix-bug.zh.md
================================================
[Binary file]


================================================
FILE: sections/tools/cypress-and-storybook-exposing-component-from-story.md
================================================
# [OBSOLETE] Cypress + Storybook. Keeping test scenario, data and component rendering in one place.

*This section is now marked as obsolete because it refers to a very old version of Cypress and Storybook (either of them now fully support component tests).*

---

_Russian version: [Cypress + Storybook. Хранение тестового сценария, данных и рендеринг компонента в одном месте](https://habr.com/ru/post/497544/)._

### One Paragraph Explainer

Many of us have chosen Cypress as a tool to test components hosted via Storybook/Styleguidist/Docz. [@NoriSte's example](./cypress-and-storybook.md) suggests creating some Storybook Stories, put components there and expose important data to the global variable in order to have access to the test. The nice approach actually, but the test becomes broken into the pieces between Storybook and Cypress.

Here I'd like to show how to go a little bit further and get the most out of executing JavaScript in Cypress. To see it in action, you may [download the source code](https://github.com/daedalius/article-exposing-component-from-storybook-to-handle-them-in-cypress) and execute then `npm i` and `npm test` in the console.

- You may expose the component reference from Storybook Story to test it however you wish in Cypress (without breaking testing logic into pieces).
- Cypress turned up so powerful for our team, so we do not have another utility that uses js-dom under the hood to test UI components.

## The task

Imagine that we are writing an adaptor for existing Datepicker component to use it across all company websites. We don't want to accidentally break anything, so we have to cover it by tests.

## Storybook

All we need from Storybook - an empty Story that saves a reference to the testing component in the global variable. In order not to be so useless this Story renders the single DOM node. This node will be our war zone inside the test.

```jsx
import React from 'react'
import Datepicker from './Datepicker.jsx'

export default {
  component: Datepicker,
  title: 'Datepicker',
}

export const emptyStory = () => {
  // Reference to retrieve it in Cypress during the test
  window.Datepicker = Datepicker

  // Just a mount point
  return <div id="component-test-mount-point"></div>
}
```

Okay, we've finished with Storybook. Let's take a look at Cypress.

## Cypress

Personally, I like to get started with test cases enumeration. Seems we have next test structure:

```jsx
/// <reference types="cypress" />

import React from 'react'
import ReactDOM from 'react-dom'

/**
 * <Datepicker />
 * * renders text field.
 * * renders desired placeholder text.
 * * renders chosen date.
 * * opens calendar after clicking on text field.
 */

context('<Datepicker />', () => {
  it('renders text field.', () => {})

  it('renders desired placeholder text.', () => {})

  it('renders chosen date.', () => {})

  it('opens calendar after clicking on text field.', () => {})
})
```

Fine. We have to run this test in any environment. Open the Storybook, go directly to the empty Story by clicking at "Open canvas in new tab" button in the sidebar. Copy that URL and make Cypress visit it:

```jsx
const rootToMountSelector = '#component-test-mount-point'

before(() => {
  cy.visit('http://localhost:12345/iframe.html?id=datepicker--empty-story')
  cy.get(rootToMountSelector)
})
```

As you may guess, in order to test we are going to render all components states in the same `<div>` with `id=component-test-mount-point`. So that the tests do not affect each other, we must unmount any component here before the next test execution. Let's add some cleanup code:

```jsx
afterEach(() => {
  cy.document().then((doc) => {
    ReactDOM.unmountComponentAtNode(doc.querySelector(rootToMountSelector))
  })
})
```

Now we are ready to complete the test. Retrieve the component reference, render the component and make some assertions:

```jsx
const selectors = {
  innerInput: '.react-datepicker__input-container input',
}

it('renders text field.', () => {
  cy.window().then((win) => {
    ReactDOM.render(<win.Datepicker />, win.document.querySelector(rootToMountSelector))
  })

  cy.get(selectors.innerInput).should('be.visible')
})
```

Do you see that? Nothing stops us from passing any props or data to the component directly! It's all in one place - in Cypress!

## Testing in a few steps with wrapper

Sometimes we'd like to test that component behaves predictably according to changing props.
Examine `<Popup />` component with `showed` props. When `showed` is `true`, `<Popup />` is visible. After that, changing `showed` to `false`, `<Popup />` should become hidden. How to test that transition?

Those problems are easy to handle in an imperative way, but in case of declarative React we need to come up with something.
In our team, we use an additional wrapper component with state to handle it. The state here is boolean, it responses to "showed" props.

```jsx
let setPopupTestWrapperState = null
const PopupTestWrapper = ({ showed, win }) => {
  const [isShown, setState] = React.useState(showed)
  setPopupTestWrapperState = setState
  return <win.Popup showed={isShown} />
}
```

Now we are about to finish the test:

```jsx
it('becomes hidden after being shown when showed=false passed.', () => {
  // arrange
  cy.window().then((win) => {
    // initial state - popup is visible
    ReactDOM.render(
      <PopupTestWrapper showed={true} win={win} />,
      win.document.querySelector(rootToMountSelector)
    )
  })

  // act
  cy.then(() => {
    setPopupTestWrapperState(false)
  })

  // assert
  cy.get(selectors.popupWindow).should('not.be.visible')
})
```

> Tip: If such hook hasn't worked or you dislike calling the hook outside the component - rewrite the wrapper via simple class.

## Testing component methods

Actually, I've never written such a test. The idea has come up while writing this article. Probably it may be useful to test a component in a unit test style.

However, you may easily do it in Cypress. Just create a ref to the component before rendering. It is worth mentioning that the ref gives access to state and other elements of the component.

I've added the `hide` method to `<Popup \>` which makes it hidden forcibly (example for the sake of example). The following test looks like this:

```jsx
it('closes via method call.', () => {
  // arrange
  let popup = React.createRef()
  cy.window().then((win) => {
    // initial state - popup is visible
    ReactDOM.render(
      <win.Popup showed={true} ref={popup} />,
      win.document.querySelector(rootToMountSelector)
    )
  })

  // act
  cy.then(() => {
    popup.current.hide()
  })

  // assert
  cy.get(selectors.popupWindow).should('not.be.visible')
})
```

## To sum it up: the roles of each participant

Storybook:

- Hosts Storybook Stories that contain bundled react components for test purposes.
- Provides a real non-synthetic environment to run tests.
- Each Story exposes one component in the global variable (to retrieve it in Cypress later).
- Each Story exposes a component mount point (to mount a component in test).
- Able to open each component in isolation in new tab.

> Pro-Tip: Please, run another instance of Storybook for your component library or pages.

Cypress:

- Contains and runs tests and Javascript.
- Visits isolated component Stories, retrieves component references from the global variable.
- Renders component according to testing needs (with any data or test conditions such as mobile resolution).
- Gives you super handy UI so you can see how your tests are going.

## Conclusion

Here I'd like to express my personal opinion and my colleagues' position about possible questions that may appear during the reading. Written below doesn't pretend to be true, may differ from reality and contain nuts.

### My test utils use js-dom under the hood. Do I limit myself?

- Js-dom is a synthetic environment. The separated DOM is not a real browser.
- It doesn't really work out to act with js-dom as it user does. Especially when it comes to simulating input events.
- How much confidence can you get from a written unit test if a component can be broken in CSS due to one incorrect z-index? If the component is tested by Cypress, you will see an error.
- You write unit tests blindly. But why?

### Should I choose the approach suggested?

- If you use tests as a development environment - definitely, Yes!
- If you look at tests as at **live** documentation - Yes.
- If you really write unit-tests to cover things that too close to implementation and React-lifecycle - ... I don't know. I haven't been writing such a test for a long time. Are you sure that the covered logic is component responsibility? Maybe that logic should be extracted and tested accordingly?

### Why not use cypress-react-unit-test then? Why do we need Storybook?

Probably, it is our future to test components. There will be no need to maintain a separate instance of the Storybook, all tests will be entirely under the responsibility of Cypress, the configuration will be simplified, etc.
But now the tool has [some](https://github.com/bahmutov/cypress-react-unit-test/issues/34) [problems](https://github.com/bahmutov/cypress-react-unit-test/issues/52) that make the environment provided incomplete for running tests. Hope that Gleb Bahmutov and the Cypress team will make it worked 🤞

_Crossposted by [daedalius](https://github.com/daedalius) on [Medium](https://itnext.io/cypress-storybook-keeping-test-scenario-data-and-component-rendering-in-one-place-c57b23cc1640) and on [habr.com (in Russian)](https://habr.com/ru/post/497544/)._



================================================
FILE: sections/tools/cypress-and-storybook-exposing-component-from-story.zh.md
================================================
[Binary file]


================================================
FILE: sections/tools/cypress-and-storybook.md
================================================
# [OBSOLETE] Testing a component with Cypress and Storybook

*This section is now marked as obsolete because it refers to a very old version of Cypress and Storybook (either of them now fully support component tests).*

---

_**UPDATE**: After this experimental approach, take a look at the “[Unit Testing React components with Cypress](./cypress-react-component-test.md)” chapter, things got simplified and more effective with Cypress 4.5.0 release!_

_**UPDATE 2**: [Cypress 7 is out with a brand-new Component Test](https://docs.cypress.io/guides/component-testing/introduction#What-is-Component-Testing) support, check it out! And other exciting news is on the way thanks to [Storybook 6.2 release](https://twitter.com/NoriSte/status/1378204109841571840)!_

### Why testing components in isolation?

Components are the building blocks of your app, Storybook allows you to build them in isolation, **checking** that they work properly and that they are aligned with the graphic layouts, sharing with the rest of the team, etc. There are essentially two kinds of component checks performed with Storybook:

- visual tests: run with [Percy](https://percy.io/) or [Applitools](https://applitools.com/), both easily integrable with Storybook to automate this checks

- functional tests: performed manually on the component stories, why do not automate them too? This chapter speaks about that

### The components testing tools

The current front-end testing trends have two winners: **[DOM Testing Library](https://testing-library.com)** and **[Cypress](https://www.cypress.io/)**. They are two completely different tools but **they overlap** in some terms. DOM Testing Library bornt explicitly to test components (through a third-party test runner like [Jest](https://jestjs.io/)) the right and the fast way and it is great for that. Cypress is made to automate the browser in an easy and reliable way.

Why do they overlap? Well because technically, you could test a whole app through DOM Testing Library or you could test a single component with Cypress.

Using **DOM Testing Library** to test an entire app:

- pro: it is blazing **fast**

- con: it renders the HTML but the HTML is not rendered by a real browser so **the CSS part does not work**

- con: reading a giant HTML instead of consuming the result in the browser is cumbersome

- con: third-party components could not fully be fully compatible with the [jsdom](https://github.com/jsdom/jsdom) environment or could not work as expected while rendered by DOM Testing Library

Using **Cypress** to test components:

- pro: it automates a **real browser**, the components are tested in the same environment they will be used

- pro: you can test the component the same way the users are going to see/consume it

- pro: you can check that your **Storybook works well** too. The code of your stories could be bugged, so having some working components does not guarantee you a having a working Storybook. And the rest of the team could count on Storybook as the component library of the team/company.

- con: **it needs a running host**/website that allows you to interact with the components themselves (like Storybook)

- con: it could be slow to test hundreds of components

Please note: for Cypress, there is the [Cypress Testing Library](https://testing-library.com/docs/cypress-testing-library/intro) plugin that allows you to leverage the same _findByText_, _findByPlaceholderText_, _findByTestId_, etc. APIs of DOM Testing Library. I love it and I always use it but they work inside Cypress, not in other test runners

## A real example: a Virtual List

Recently, I developed a VirtualList component and I used it to check how Storybook and Cypress could work together. A VirtualList is a list that renders only the visible items to guarantee the highest possible performance. Take a look at [React Virtualized](https://bvaughn.github.io/react-virtualized/#/components/List) to understand how it works. Apart from virtualizing, my VirtualList manages items clicks and items multi-selection.

Apart from a lot of unit tests, I would like to run some Component Tests but, as said above, third-party libraries (like the one we use: [React Smooth Scrollbar](https://www.npmjs.com/package/react-smooth-scrollbar)) could not work well with [React Testing Library](https://testing-library.com/docs/react-testing-library/intro) (the React version of DOM Testing Library) so Cypress is the only tool of choice.

## Testing challenges

What are the biggest challenges of using Cypress to test a component in Storybook instead of running a standard E2E test? And what are the challenges compared to a standard Component Test with [React Testing Library](https://testing-library.com/docs/react-testing-library/intro) (the React version of DOM Testing Library)?

### Data source control

With Cypress, we are used to loading an entire application, controlling the data through static fixtures (in case of [UI Integration Tests](../testing-strategy/component-vs-integration-vs-e2e-testing.md)) or reading/intercepting the back-end data (in case of [E2E Tests](../testing-strategy/component-vs-integration-vs-e2e-testing.md)) and using this data to assert that the UI is working properly. So we can control, or at least know, the data the UI is going to consume. **Not knowing data would mean no assertions**.
But in a (stateless) component story, the data is passed directly to the component by the component that represents the story and renders the component. In order to know the data and do the proper assertions about the contents shown by the component of the story, **the data needs to be exposed by the story and read by Cypress**.

Please note: if the Cypress tests are in the same repository of the components of the stories, you can import the data from the story file, but the examples shown below come from tests that are not in the same repository of the stories.

### Hidden contents

**A Virtual List removes the invisible components** from the DOM. What does it mean for the tests? That we cannot count on the fact that all the elements exist in the HTML. Neither React Testing Library nor Cypress could be fully leveraged to understand how the Virtual List is working because, as soon as you need to assert about the existence of an item outside the visible area, you cannot leverage the usual _cy.contains_ / _findByText, etc._ utilities: because the items do not exist at all.

The VirtualList is a controlled component so it notifies the parent component about which are the rendered items and which are the selected ones. In a standard [Component Test](../testing-strategy/component-vs-integration-vs-e2e-testing.md) we could assert about the props passed up and down to the VirtualList component, the Story has direct control of these props but, again, Cypress needs to read this data and so the story must expose it.

### Are we testing the story or the component?

The difference could be subtle. Since the VirtualList is a controlled component, the story’ component controls it. The controlling logic inside the story’ component is part of the things to be tested? Are the controlling component and the controlled one separable? Probably not.

A standard test has two actors—the test runner and the controlled component—while using Cypress with Storybook has **three actors—the test runner, the story, and the controlled component**—. So, if a Component Test controls the component and has direct access to the callback data, Cypress needs the story’ component to work properly.

### Scroll and rendered items control

The VirtualList component leverages an inertial scroll and, since the story adds thousands of items to be rendered to fully show the VirtualList potential, has a very little scrollbar handle. Scrolling the VirtualList could result in slightly different rendered items between a test and the next one. So I take for granted that we cannot know in advance which items are going to be rendered once the list is scrolled (ex. from the 100th to the 110th or from the 101st to the 111th).

Why? Because **I hate to have brittle tests based on fragile assumptions**. Tests should not be designed to resist every possible change but they must be enough robust to survive little changes. For the VirtualList tests, it means that once scrolled, the rendered items will be retrieved directly from the HTML ones. We are going to deepen it later.

## Code, please

The first test we are going to write needs to check that if the list received 10000 items, only a bunch of them are rendered. This is the base feature of a Virtual List.

First of all, the RenderItem component, it just alternates the color to visually identify the rows

```js
// every `item` is an { id: string, name: string}
const getItemText = (item) => `id: ${item.id} - ${item.name}`

const RenderItem = ({ item }) => {
  return (
    <div
      style={{
        height: '30px',
        backgroundColor: parseInt(item.id) % 2 ? '#FAFAFA' : '#EEE',
      }}
    >
      {getItemText(item)}
    </div>
  )
}
```

the original story we are going to work on is the following

```js
// `getStoryItems` allows to create a high amount of items, it's used by every story
export const With10000Items = () => {
  return (
    <>
      <h4>The scroll must be fluid</h4>
      <VirtualList
        items={getStoryItems({ amount: 10000 })}
        getItemHeights={() => 30}
        RenderItem={RenderItem}
        listHeight={300}
      />
    </>
  )
}
With10000Items.story = {
  name: 'With 10000 items',
}
```

We need to adapt the story to globally expose:

- the `items` array: the Cypress test needs to know the data used to fill the list

- the `getItemText` function: so the Cypress test avoids caring about how to get the rendered text from an item. Cypress needs the convert an item to text to retrieve the rendered items from their text, avoiding to use `data-test` attributes

- the number of visible items: the Cypress test needs to assert about which items are rendered and which not

Here is the story updated to expose the variables through a global `storyData` variable that will be collected and consumed by the Cypress test:

```js
export const With10000Items = () => {
  const itemHeight = 30
  const listHeight = 300
  const items = React.useMemo(() => getStoryItems({ amount: 10000 }), [])

  // exposing data for Cypress
  React.useEffect(() => {
    // global is `window`
    global.storyData = {
      items,
      visibleItemsAmount: Math.ceil(listHeight / itemHeight),
      getItemText,
    }
  }, [items])

  return (
    <>
      <h4>The scroll must be fluid</h4>
      <VirtualList
        items={items}
        getItemHeights={() => itemHeight}
        RenderItem={RenderItem}
        listHeight={listHeight}
      />
    </>
  )
}
With10000Items.story = {
  name: 'With 10000 items',
}
```

### The Cypress test

The test is going to:

- visit the Storybook page

- collect the exposed data

- check the rendered items

The code for the first two points

```js
it('When the component receives 10000 items, then only the minimum number of items are rendered', () => {
  cy.visit('/iframe.html?id=virtuallist--with-10000-items')

  cy.window()
    .its('storyData')
    .should((storyData) => {
      // the story must expose some variables
      expect(storyData.items).to.be.to.have.length(10000)
      expect(storyData.visibleItemsAmount).to.be.greaterThan(0)
      expect(storyData.getItemText).to.be.a('function')
    })
    .then(() => {
      // the test code
    })
})
```

Why asserting about the exposed `storyData`? Because a wrong `storyData` will make the test fail, and if a test fails it must drive us directly to the problem. If component rendering will fail because of a wrong `storyData`, our test should not run at all. This could be considered **a data-related smoke test**.

Now, the missing part of the test: checking which items are rendered and which are not

```js
it('When the component receives 10000 items, then only the minimum number of items are rendered', () => {
  cy.visit('/iframe.html?id=virtuallist--with-10000-items')

  cy.window()
    .its('storyData')
    .should((storyData) => {
      // the story must expose some variables
      expect(storyData.items).to.be.to.have.length(10000)
      expect(storyData.visibleItemsAmount).to.be.greaterThan(0)
      expect(storyData.getItemText).to.be.a('function')
    })
    .then(({ visibleItemsAmount, getItemText, items }) => {
      // items visibility check
      const visibleItems = items.slice(0, visibleItemsAmount - 1)
      visibleItems.forEach((item) => {
        cy.findByText(getItemText(item)).should('be.visible')
      })

      // first not-rendered item check
      cy.findByText(getItemText(items[visibleItemsAmount])).should('not.exist')
    })
})
```

- We use the exposed `visibleItemsAmount` variable to retrieve just the rendered items

  const visibleItems = items.slice(0, visibleItemsAmount - 1)

- We retrieve every item from the page using the exposed `getItemText` function

  cy.findByText(getItemText(item))

- We assert all the items expected to be visible

  cy.findByText(getItemText(item)).should('be.visible')

- We assert that the next item does not exist in the page

```js
cy.findByText(getItemText(items[visibleItemsAmount])).should('not.exist')
```

Please note that the `cy.findByText` Cypress command comes from… [Cypress Testing Library](https://testing-library.com/docs/cypress-testing-library/intro) 😊 and it is my favorite way to retrieve elements from the page because acts as the user would: reading/retrieving elements from their textual content. I use it instead of `cy.contains` but they do the same thing.

This is the result:

![The Cypress controlled browser, all the assertion results on the left and the Storybook story on the right.](../../assets/images/cypress-storyboook/list-test.png 'The result of the first test: the loaded story and the result of all the assertions.')_The result of the first test: the loaded story and the result of all the assertions._

This test is enough to check that the Virtual List renders only the minimum number of items.

Initially, I tried to check that the browser runs at 60 FPS when the Virtual List was scrolling. Why? Because **a UI Test must check what the user sees, consuming the UI the same UI the user would**. And, from a user perspective, the sole Virtual List goal is that it must run fluidly, regardless of the number of items that are part of the list. But measuring reliably the FPS is hard because the measurement would be impacted by:

- the Cypress commands you use: every Cypress’ action slows down the browser

- the number of resources available to the machine (or Docker image) to run the tests

since having a reliable count is not possible—some initial values would be discarded, etc.—I moved to check the amount of rendered items and nothing more. If I am sure that just 10 of 10000 items are rendered, I am sure that the list runs fluidly. More in general: remember that **a brittle test is worse than a missing one**.

## Second test: scrolling

First of all: the VirtualList component leverages [Smooth Scrollbar](https://idiotwu.github.io/smooth-scrollbar/), Smooth Scrollbar has its own tests so we are going to check how our VirtualList component reacts to the scroll but we take for granted that Smooth Scrollbar works. When consuming **a third-party library**, you do not have to test that the library works. The library **should have its own tests**, if it has not, change the library! Never write tests for third-party libraries.

The scrolling test is going to:

- trigger the scroll

- wait until the scroll ends

- check the rendered items

So, the test code to trigger the scroll is the following

```js
// triggers the wheel event
cy.findByTestId('VirtualList').trigger('wheel', {
  deltaX: 0,
  deltaY: 1000,
})
```

note that the VirtusList component should render a DOM element with a `data-test="VirtualList"` attribute. The rest is managed by Cypress, trigger is a direct mapping for [jQuery trigger API](https://api.jquery.com/trigger/) (Cypress leverages jQuery to shorten as much as possible the test code). Again: the Cypress’ native equivalent ofcy.findByTestId('VirtualList') iscy.get('[data-testid=VirtualList]').

For the “wait until the scroll ends” part, we are going to leverage [Cypress waitUntil](https://github.com/NoriSte/cypress-wait-until) plugin. Why we should use the waitUntil plugin instead of waiting for a fixed amount of time is carefully explained in the [Await, do not make your E2E tests sleep](../generic-best-practices/await-dont-sleep.md) chapter.
The code of the custom waiting is

```js
// waits until the scrollbar handle stops
let scrollbarHandleY = Number.NEGATIVE_INFINITY
cy.get('.scrollbar-thumb-y').waitUntil(
  ($scrollbarHandle) => {
    const [newY, previousY] = [$scrollbarHandle.offset().top, scrollbarHandleY]
    scrollbarHandleY = newY
    return previousY === newY
  },
  {
    customMessage: 'The inertial scroll ends',
  }
)
```

So we are sure that the test waits the right amount of time.

### Checking the rendered items

What does it mean? It means:

- finding the first rendered item

- checking that the first rendered item is not the first one. The Virtual List started rendering the 0 to 10 items. Once scrolled, it must have rendered Xth to Xth+10 items. We do not know the value of X and we do not care about that, otherwise, we are going to tie the test to the exact items rendered. If the first rendered item is the 60th or the 61st one is not important. Checking the exact rendered items is out of the scope of this generic scrolling test. Test stability thanks us.

- Once retrieved the first rendered item, we check that the next ten are all rendered

We are going to go through every single step, the final code of the test is the following

```js
it('When the component is scrolled, then the rendered items are not the first ones', () => {
  cy.visit('/iframe.html?id=virtuallist--with-10000-items')

  cy.window()
    .its('storyData')
    .should((storyData) => {
      // the story must expose some variables
      expect(storyData.items).to.be.to.have.length(10000)
      expect(storyData.visibleItemsAmount).to.be.greaterThan(0)
      expect(storyData.getItemText).to.be.a('function')
    })
    .then(({ visibleItemsAmount, getItemText, items }) => {
      // triggers the wheel event
      cy.findByTestId('VirtualList').trigger('wheel', {
        deltaX: 0,
        deltaY: 1000,
      })

      // waits until the scrollbar handle stops
      let scrollbarHandleY = Number.NEGATIVE_INFINITY
      cy.get('.scrollbar-thumb-y')
        .waitUntil(
          ($scrollbarHandle) => {
            const [newY, previousY] = [$scrollbarHandle.offset().top, scrollbarHandleY]
            scrollbarHandleY = newY
            return previousY === newY
          },
          {
            customMessage: 'The inertial scroll ends',
          }
        )
        // (manually) looks for the first rendered element
        .then(() =>
          items.findIndex((item) => !!Cypress.$(`*:contains("${getItemText(item)}")`).length)
        )
        // checks that the rendered items are not the initially rendered ones
        .should('be.greaterThan', 10)
        // checks the rendered items
        .then((firstVisibleItemIndex) => {
          const visibleItems = items.slice(
            firstVisibleItemIndex,
            firstVisibleItemIndex + visibleItemsAmount - 1
          )
          visibleItems.forEach((item) => cy.findByText(getItemText(item)).should('be.visible'))
        })
    })
})
```

Step by step: the code to retrieve the first rendered item is

```js
items.findIndex((item) => !!Cypress.$(`*:contains("${getItemText(item)}")`).length)
```

Why not leveraging the `cy.findByText` command to retrieve it? Because in Cypress, every `cy.get` command (that is at the core of `cy.findByText` command) has built-in assertions, [check them](https://docs.cypress.io/api/commands/get.html#Assertions) in the official docs. Essentially, if the element does not exist on the page, `cy.get` makes the test fail. But since we need to go through over the non-rendered items until we find the first rendered one, we should go by hand. Cypress.\$ is a global instance of jQuery, a jQuery version of `cy.findByText("XXX")` is `Cypress.$(`\*:contains("XXX")`)` and, the jQuery version of

```js
cy.findByText('XXX').should('exist')
```

is

```js
!!Cypress.$(`*:contains("XXX")`).length
```

with the only difference that it does not fail if the element does not exist. As said before: I am used to leveraging `cy.getByText` but the native `cy.contains` does the same thing!

Once the index of the first rendered item is found, we only need to check the next rendered ones.

```js
.then(() =>
  items.findIndex(
    item => !!Cypress.$(`*:contains("${getItemText(item)}")`).length,
  )
)
// checks that the rendered items are not the initially rendered ones
.should('be.greaterThan', 10)
// checks the rendered items
.then(firstVisibleItemIndex => {
  const visibleItems = items.slice(
    firstVisibleItemIndex,
    firstVisibleItemIndex + visibleItemsAmount - 1,
  )
  visibleItems.forEach(item =>
    cy.findByText(getItemText(item)).should('be.visible'),
  )
})
```

[This is the recording of the test](https://www.youtube.com/watch?v=OEMkz_86bqY).

Please note that we do not care about the last half-visible item. The scope of the test is checking that the rendered items are not the first ones and that at least ten items are rendered, an 11th one does not need to be checked.

We can move the scrolling part of the test to a separated utility, something like

```js
const scrollVirtualList = ($list, deltaY = 1000) => {
  cy.wrap($list)
    .trigger('wheel', {
      deltaX: 0,
      deltaY,
    })
    .within(() => {
      // waits for the inertial scroll end
      let scrollbarY = Number.NEGATIVE_INFINITY
      getScrollbar().waitUntil(
        ($scrollbar) => {
          const newY = $scrollbar.offset().top
          const previousY = scrollbarY
          scrollbarY = newY
          return previousY === newY
        },
        {
          customMessage: 'The inertial scroll end',
        }
      )
    })
}
```

and we could do the same for finding the first rendered item

```js
const getFirstRenderedItemIndex = (items, getItemText) => {
  return items.findIndex((item) => !!Cypress.$(`*:contains("${getItemText(item)}")`).length)
}
```

The readability of the test benefits from this separation, take a look

```js
it('When the component is scrolled, then the rendered items are not the first ones', () => {
  cy.visit('/iframe.html?id=virtuallist--with-10000-items')

  cy.window()
    .its('storyData')
    .should((storyData) => {
      // the story must expose some variables
      expect(storyData.items).to.be.to.have.length(10000)
      expect(storyData.visibleItemsAmount).to.be.greaterThan(0)
      expect(storyData.getItemText).to.be.a('function')
    })
    .then(({ visibleItemsAmount, getItemText, items }) => {
      cy.findByTestId('VirtualList')
        // we leverage the new `scrollVirtualList` function
        .then(scrollVirtualList)
        .then(() => getFirstRenderedItemIndex(items, getItemText))
        .should('be.greaterThan', 10)
        .then((firstVisibleItemIndex) => {
          const visibleItems = items.slice(
            firstVisibleItemIndex,
            firstVisibleItemIndex + visibleItemsAmount - 1
          )
          visibleItems.forEach((item) => cy.findByText(getItemText(item)).should('be.visible'))
        })
    })
})
```

## Third test: selecting

The VirtualList component supports selection and **multi-item selection through key modifiers**. We only need to click items, click items with key modifiers, and check which are the selected items. What makes these operations hard?

- first of all: what “selected” means? From the user perspective, a selected item is a “highlighted” one but checking the style of an element is weak. We could add a `data-selected` attribute to the component…

- … But there is a structural problem: the items could not be rendered at all! If we click on the first item (seeing from the 1st to the 10th items), then we scroll about twenty items (seeing the from the 21st to the 30th items) and we click on items in the middle (the 25th one) pressing SHIFT, the items selected should be from the 1st to the 25th but the first twenty are not rendered, so we cannot retrieve the selected items by the rendered ones. Again, **we are going to use the variables exposed by the story**

This is the code of the story

```js
export const WithSelectionManagement = () => {
  const items = getStoryItems({ amount: 10000 })

  const [selectedItems, setSelectedItems] = React.useState([])

  const handleSelect = React.useCallback(({ newSelectedIds }) => setSelectedItems(newSelectedIds), [
    setSelectedItems,
  ])

  // exposing data for Cypress
  React.useEffect(() => {
    global.storyData = {
      items,
      getItemText,
      selectedItems,
    }
  }, [items, selectedItems])

  return (
    <>
      <h4>The buttons must be clickable, the CTRL/CMD, ALT, SHIFT keyboard modifiers must work</h4>
      <VirtualList
        items={items}
        selectedItemIds={selectedItems}
        getItemHeights={() => 30}
        RenderItem={createSelectableRenderItem({ height: 30 })}
        listHeight={300}
        onSelect={handleSelect}
      />
    </>
  )
}
```

Since the VirtualList component is controlled, it passes up the list of selected items—the `selectedItems` array—. The parent component—the story—exposes the array for Cypress to allow asserting about the selected items.
Please note: the component creation, with click management, has been moved to a dedicated higher-order function: `createSelectableRenderdItem`.

The test for selecting a single item is the following

```js
it('When the items are clicked, then they are selected', () => {
  cy.visit('/iframe.html?id=virtuallist--with-selection-management')

  cy.window()
    .its('storyData')
    .should((storyData) => {
      // the story must expose some variables
      expect(storyData.items).to.be.to.have.length.of.at.least(3)
      expect(storyData.getItemText).to.be.a('function')
      expect(storyData.selectedItems).to.be.an('array')
    })
    .then(({ getItemText, items }) => {
      cy.findByText(getItemText(items[0]))
        .click()
        .window()
        .its('storyData.selectedItems')
        .should('eql', [items[0].id])

      cy.findByText(getItemText(items[1]))
        .click()
        .window()
        .its('storyData.selectedItems')
        .should('eql', [items[1].id])
    })
})
```

All the assertions are on the exposed `selectedItems` array itself. We do not check if the rendered items are highlighted or not (highlighting the item is in charge of the component created by the story) but only that the VirtualList component manages correctly the items click.

The `selectedItems` array is not read at the beginning but it is read after every click because we need to check always the updated one, not the reference to the initial one (`selectedItems` is returned by `React.useState` so it is new after every selection update).

### Multi-selection assertions

The next step is checking that the VirtualList component manages correctly the usage of the Meta key. Clicking another item while the meta key is pressed should result in two selected items.

How could we keep the Meta key pressed with Cypress? It is just

```js
cy.get('body')
  // keeping pressed the meta (CMD) key
  .type('{meta}', { release: false })

// ...your test code...

cy.get('body')
  // releasing the meta (CMD) key
  .type('{meta}', { release: true })
```

Adding the item click would result in

```js
cy.get('body')
  // keeping pressed the meta (CMD) key
  .type('{meta}', { release: false })
  .findByText(getItemText(items[2]))
  .click()
  .window()
  .its('storyData.selectedItems')
  .should('eql', [items[1].id, items[2].id])
  .get('body')
  // releasing the meta (CMD) key
  .type('{meta}', { release: true })

  cy.get('body')
    .type('{shift}', { release: false })
    .findByText(getItemText(firstRenderedItem))
    .click()
    .window()
    .its('storyData.selectedItems')
    .should('eql', expectedSelectedItemIds)
    .get('body')
    .type('{shift}', { release: true })
  })
```

Here a screenshot of the result

![The controlled browser, all the assertion results on the left and the Storybook story with selected items on the right.](../../assets/images/cypress-storyboook/selection-test-result.png 'The first result of the test: the loaded story and the result of all the assertions.')_The first result of the test: the loaded story and the result of all the assertions._

### Scrolling and selecting

Scrolling the list is easy thanks to the `scrollVirtualList` utility, finding the first rendered item is done by the `getFirstRenderedItemIndex` one, we know how to keep a key pressed… So, testing the scrolling and clicking with the Shift modifier (which means selecting everything from the previous clicked element and the last one) should be just a matter of calculating all the (expected to be) selected items. The next code does only that, go on for the full code of the test

```js
cy.findAllByTestId('VirtualList')
  // scrolls the list
  .then(scrollVirtualList)
  .then(() => {
    // identifies the first rendered item (unknown in advance)
    const firstRenderedItemIndex = getFirstRenderedItemIndex(items, getItemText)
    const firstRenderedItem = items[firstRenderedItemIndex]

    // the tests is going to click on the first rendered item
    // keeping the SHIFT key pressed. All the items up to the first
    // rendered one should be selected
    const expectedSelectedItemIds = items
      .slice(0, firstRenderedItemIndex + 1)
      .map((item) => item.id)

    cy.get('body')
      .type('{shift}', { release: false })
      .findByText(getItemText(firstRenderedItem))
      .click()
      .window()
      .its('storyData.selectedItems')
      .should('eql', expectedSelectedItemIds)
      .get('body')
      .type('{shift}', { release: true })
  })
```

the full code of the test, checking for every key modifier, is long but quite repetitive

```js
it('When the items are clicked, then they are selected', () => {
  cy.visit('/iframe.html?id=virtuallist--with-selection-management')

  cy.window()
    .its('storyData')
    .should((storyData) => {
      // the story must expose some variables
      expect(storyData.items).to.be.to.have.length.of.at.least(3)
      expect(storyData.getItemText).to.be.a('function')
      expect(storyData.selectedItems).to.be.an('array')
    })
    .then(({ getItemText, items }) => {
      // first item click
      cy.findByText(getItemText(items[0]))
        .click()
        .window()
        .its('storyData.selectedItems')
        .should('eql', [items[0].id])

      // second item click
      cy.findByText(getItemText(items[1]))
        .click()
        .window()
        .its('storyData.selectedItems')
        .should('eql', [items[1].id])

      // third item click with Meta modifier
      cy.get('body')
        .type('{meta}', { release: false })
        .findByText(getItemText(items[2]))
        .click()
        .window()
        .its('storyData.selectedItems')
        .should('eql', [items[1].id, items[2].id])
        .get('body')
        .type('{meta}', { release: true })

      // first item click with Shift modifier
      cy.get('body')
        .type('{shift}', { release: false })
        .findByText(getItemText(items[0]))
        .click()
        .window()
        .its('storyData.selectedItems')
        .should('eql', [items[2].id, items[1].id, items[0].id])
        .get('body')
        .type('{shift}', { release: true })

      // second item click with Alt modifier
      cy.get('body')
        .type('{alt}', { release: false })
        .findByText(getItemText(items[1]))
        .click()
        .window()
        .its('storyData.selectedItems')
        .should('eql', [items[2].id, items[0].id])
        .get('body')
        .type('{alt}', { release: true })

      // scrolling
      cy.findAllByTestId('VirtualList')
        .then(scrollVirtualList)
        .then(() => {
          const firstRenderedItemIndex = getFirstRenderedItemIndex(items, getItemText)
          const firstRenderedItem = items[firstRenderedItemIndex]
          const expectedSelectedItemIds = items
            .slice(0, firstRenderedItemIndex + 1)
            .map((item) => item.id)

          // x-th item click with Shift modifier
          cy.get('body')
            .type('{shift}', { release: false })
            .findByText(getItemText(firstRenderedItem))
            .click()
            .window()
            .its('storyData.selectedItems')
            .should('eql', expectedSelectedItemIds)
            .get('body')
            .type('{shift}', { release: true })
        })
    })
})
```

[The test result is the following](https://www.youtube.com/watch?v=0DGHRJnWbHw).

As you can see, the Command Log on the left does not tell clearly what is happening. We could improve the speaking level of the test by adding some cy.log calls or, better, leveraging [Filip’s solution](https://medium.com/slido-dev-blog/cypress-tips-3-improve-your-error-screenshots-in-cypress-b3675968a190) to get the best out of Cypress logging.

## Optimizations

The faster the tests are, the better. My original test suite took almost 16 seconds to completely run. [Here is the recording](https://www.youtube.com/watch?v=EwBz844FuxE) (please note that it was the first test suite, with the 60 FPS test).

There are two main improvements areas:

- switching faster between stories (instead of reloading the page between the tests)

- speeding up the scrolling forcing the browser clock with Cypress

### Switching faster between stories

Kudos to Nicholas Boll and his [cypress-storybook](https://github.com/NicholasBoll/cypress-storybook) plugin that leverages the storybook APIs to load the desired story without reloading the whole page.

At the time of writing, all we need to do is:

- adding `import 'cypress-storybook/react'` to the Storybook configuration

- adding import `'cypress-storybook/cypress'` to the Cypress’ support/index.js file

- adding a `before` hook to the test file

```js
before(() => {
  // Visit the storybook iframe page once per file
  cy.visitStorybook()
})
```

- loading stories through `cy.loadStory('VirtualList', 'With 10000 items')` instead of using `cy.visit`

- updating the exposed variables, explained after the video

Doing so, the page is not reloaded for every test and the whole suite saves 3 seconds, take a look at [this video](https://www.youtube.com/watch?v=UJhPTJhDEFM).

Why do we need to update the variables by the stories? Well, if the page is not reloaded, we cannot be sure that the exposed variables are the desired ones, especially because almost every story exposes an `items` variable but the contents of the variable vary.

How could we distinguish the variables exposed by the stories? Well, exposing the name of the story too!

```js
React.useEffect(() => {
  global.storyData = {
    // the name of the story is exposed too
    storyName: 'With 10000 items',
    items,
    visibleItemsAmount: Math.ceil(listHeight / itemHeight),
    getItemText,
  }
}, [items])
```

Doing so, every test could check for the awaited name

```js
it('When the component receives 10000 items, then only the minimum number of items are rendered', () => {
  const story = 'With 10000 items'
  cy.loadStory('VirtualList', story)

  cy.window()
    .its('storyData')
    .should((storyData) => {
      // caring about the story name
      expect(storyData.storyName).to.eq(story)

      expect(storyData.items).to.be.to.have.length(10000)
      expect(storyData.visibleItemsAmount).to.be.greaterThan(0)
      expect(storyData.getItemText).to.be.a('function')
    })
    .then(({ visibleItemsAmount, getItemText, items }) => {
      // ... test code...
    })
})
```

leveraging the [Cypress retry-ability](https://docs.cypress.io/guides/core-concepts/retry-ability.html) to wait until all the assertions pass. This way we are sure the exposed variables are the correct ones.

13 seconds compared to the initial 16 seconds could not sound like a huge improvement… But it is! Because if we were testing a component without the inertial scroll (a form, for example) the gain would not have been from 16" to 13" but probably from 9" to 6" seconds! Trust me, **never underestimate test speed**…

### Speeding up the scroll by controlling the clock

The videos highlight that most of the test duration is spent waiting for the inertial scroll completion. There is nothing wrong about that but some test runners allow you to control time ticking, Cypress is one of those. Pushing time forward is fundamental when you need to test `setTimeout` or `setInterval` related stuff or animations like the inertial scroll.

The [official documentation](https://docs.cypress.io/api/commands/clock.html) has a lot of examples, but basic usage is enough for our needs. We need to call `cy.clock()` and then ticking time with `cy.tick(<milliseconds>`).

The first test commented with the new clock control

```js
it('When the component is scrolled, then the rendered items are not the first ones', () => {
  const story = 'With 10000 items'
  cy.loadStory('VirtualList', story)

  // take control of the browser clock
  cy.clock()

  cy.window()
    .its('storyData')
    .should((storyData) => {
      expect(storyData.storyName).to.eq(story)
      expect(storyData.items).to.be.to.have.length(10000)
      expect(storyData.visibleItemsAmount).to.be.greaterThan(0)
      expect(storyData.getItemText).to.be.a('function')
    })
    .then(({ visibleItemsAmount, getItemText, items }) => {
      // this test does not need the `scrollVirtualList` utility anymore
      cy.findByTestId('VirtualList')
        .trigger('wheel', {
          deltaX: 0,
          deltaY: 1000,
        })

        // ticking the clock by one second.
        // It jumps to the inertial scroll end.
        .tick(1000)

        .then(() => getFirstRenderedItemIndex(items, getItemText))
        .should('be.greaterThan', 10)
        .then((firstVisibleItemIndex) => {
          const visibleItems = items.slice(
            firstVisibleItemIndex,
            firstVisibleItemIndex + visibleItemsAmount - 1
          )
          visibleItems.forEach((item) => cy.findByText(getItemText(item)).should('be.visible'))
        })
    })
})
```

[That’s the result](https://www.youtube.com/watch?v=m6u0H8_jQuc).

As you can see, we jump at the end of the inertial scroll without waiting for its completion. Please note: the whole test duration is falsified by the screen recording, the test run without recording takes less time.

Remember that, if you use `cy.clock`, using `cy.tick` is not optional! If you do not tick the time manually, the list does not scroll at all because the clock is frozen! Take a look at what happens if you do not tick the clock

![The list stuck at the initial position and the failed test.](../../assets/images/cypress-storyboook/clock-without-tick.png 'The list is stuck at the initial scroll level, it did not scroll because we did not tick the clock.')_The list is stuck at the initial scroll level, it did not scroll because we did not tick the clock._

The `.should('be.greaterThan', 10)` assertion is not satisfied because the list does not scroll at all.

Clock control applied to almost all the tests dropped their duration 9 seconds. The final result in the next video

https://www.youtube.com/watch?v=Otf3J7qFAtI

The end result: **from the initial 16 seconds to 9 seconds**, great! The faster the tests are the more you are going to leverage them!

### “No preview” error

If you encounter this error

![The No Preview error of Storybook, shown into the Cypress test.](../../assets/images/cypress-storyboook/no-preview-error.png)

relaunching Cypress should be enough. Otherwise, relaunch Storybook. It happened to me just twice in some hours, so I have not deepened it too much yet.

## Conclusions

As a recap, the solutions listed above are:

- Leverage [cypress-storybook](https://github.com/NicholasBoll/cypress-storybook) to allow Cypress switching between stories quickly

- The stories should expose some global variables allowing Cypress to assert about data

- Speed up the test as much as you can, the inertial scroll in the example will not be awaited thanks to Cypress’ clock control

- Think if you want to test the rendered component, the story code, or both

- The tools are going to be more integrated, Component Testing is a hot topic currently

<!-- TODO: in the end, decide if you want to move all the resources to a common chapter too -->

<br /><br />

_Crossposted by [NoriSte](https://github.com/NoriSte) on [dev.to](https://dev.to/noriste/testing-a-virtual-list-component-with-cypress-and-storybook-3lam) and [Medium](https://medium.com/@NoriSte/testing-a-virtual-list-component-with-cypress-and-storybook-494dc2d1d26b)._



================================================
FILE: sections/tools/cypress-and-storybook.zh.md
================================================
# [过时] 使用 Cypress 和 Storybook 进行组件测试

*此部分已被标记为过时，因为它涉及到 Cypress 和 Storybook 的非常旧版本（它们现在都已完全支持组件测试）*

---

_*更新：在这个实验性方法之后，请查看“[使用 Cypress 进行 React 组件单元测试](./cypress-react-component-test.zh.md)”章节，随着 Cypress 4.5.0 的发布，一切都变得更加简化和有效！*_

_*更新 2：[Cypress 7 推出了全新的组件测试](https://docs.cypress.io/guides/component-testing/introduction#What-is-Component-Testing)支持，不要错过！还有其他令人振奋的消息，要感谢 Storybook 6.2 版本的发布！*_

## 为什么要孤立地测试组件？

组件是你应用程序的构建模块，Storybook 允许你在孤立的环境中构建它们，**检查**它们是否正常工作，并且是否与图形布局对齐，与团队共享等。基本上，Storybook 执行两种类型的组件检查：

- 视觉测试：使用[Percy](https://percy.io/)或[Applitools](https://applitools.com/)运行，两者都可以轻松集成到 Storybook 中以自动执行这些检查

- 功能测试：在组件故事中手动执行，为什么不也自动化呢？本章讨论了这个问题

## 组件测试工具

当前前端测试趋势有两个赢家：**[DOM 测试库](https://testing-library.com)** 和 **[Cypress](https://www.cypress.io/)**。它们是两个完全不同的工具，但在某些方面它们**重叠**。DOM 测试库明确用于通过第三方测试运行器（如[Jest](https://jestjs.io/)）正确且快速地测试组件，非常适合这样的场景。Cypress 则旨在以简单可靠的方式自动化浏览器。

为什么它们会有交集呢？因为从技术上讲，你可以使用 DOM 测试库测试整个应用程序，或者可以使用 Cypress 测试单个组件。

使用 **DOM 测试库** 测试整个应用程序：

- 优点：速度**非常快**

- 缺点：它渲染 HTML，但 HTML 不是由真实浏览器渲染的，因此**CSS 部分不起作用**

- 缺点：读取巨大的 HTML 而不是在浏览器中消耗结果很麻烦

- 缺点：第三方组件可能无法与 [jsdom](https://github.com/jsdom/jsdom) 环境完全兼容，或者在由 DOM 测试库渲染时无法按预期工作

使用 **Cypress** 测试组件：

- 优点：它自动化了一个**真实的浏览器**，组件在将要使用的相同环境中进行了测试

- 优点：你可以测试用户将要看到/使用的组件的方式

- 优点：你可以检查你的**Storybook 是否正常工作**。你的故事可能存在错误，因此拥有一些工作正常的组件并不能保证 Storybook 正常工作。而团队的其余成员可能将 Storybook 视为团队/公司的组件库。

- 缺点：**它需要一个运行的主机**/网站，允许你与组件本身进行交互（如 Storybook）

- 缺点：测试数百个组件可能会很慢

请注意：对于 Cypress，有 [Cypress Testing Library](https://testing-library.com/docs/cypress-testing-library/intro) 插件，它允许你利用 DOM 测试库的相同的 _findByText_、_findByPlaceholderText_、_findByTestId_ 等 API。我喜欢它，我总是使用它，但它们在 Cypress 内部工作，而不是在其他测试运行器中工作

## 一个真实的例子：虚拟列表

最近，我开发了一个 VirtualList 组件，并使用它来检查 Storybook 和 Cypress 如何一起工作。VirtualList 是一个只渲染可见项以确保最高性能的列表。查看 [React Virtualized](https://bvaughn.github.io/react-virtualized/#/components/List) 以了解其工作原理。除了虚拟化之外，我的 VirtualList 还处理项目的点击和项目的多选。

除了大

量的单元测试外，我想运行一些组件测试，但是如上所述，第三方库（比如我们使用的 [React Smooth Scrollbar](https://www.npmjs.com/package/react-smooth-scrollbar)）可能与 [React Testing Library](https://testing-library.com/docs/react-testing-library/intro)（DOM 测试库的 React 版本）不兼容，因此 Cypress 是唯一的选择。

## 测试挑战

使用 Cypress 在 Storybook 中测试组件而不是运行标准的 E2E 测试有哪些最大的挑战？与使用 [React Testing Library](https://testing-library.com/docs/react-testing-library/intro)（DOM 测试库的 React 版本）进行标准组件测试相比，有什么挑战？

### 数据源控制

使用 Cypress，我们习惯于加载整个应用程序，通过静态固件（在 [UI 集成测试](../testing-strategy/component-vs-integration-vs-e2e-testing.zh.md) 的情况下）或读取/拦截后端数据（在 [E2E 测试](../testing-strategy/component-vs-integration-vs-e2e-testing.zh.md) 的情况下）来控制数据，并使用此数据来断言 UI 是否正常工作。因此，我们可以控制，或者至少了解，UI 将要使用的数据。**不了解数据将意味着没有断言**。
但在（无状态）组件故事中，数据直接由代表故事并渲染组件的组件传递给组件。为了了解数据并对由故事组件显示的内容进行适当的断言，**数据需要由故事暴露并由 Cypress 读取**。

请注意：如果 Cypress 测试与故事的组件位于同一个存储库中，你可以从故事文件中导入数据，但下面显示的示例来自不在故事存储库中的测试。

### 隐藏内容

**虚拟列表会从 DOM 中删除不可见的组件**。这对测试意味着什么？我们不能指望所有元素都存在于 HTML 中的事实上。无论是 React Testing Library 还是 Cypress 都不能完全利用它们来理解虚拟列表的工作方式，因为一旦需要断言一个在可见区域之外的项的存在，就无法利用通常的 _cy.contains_ / _findByText 等_ 实用工具：因为这些项根本不存在。

VirtualList 是一个受控组件，因此它会通知父组件有哪些被渲染的项以及哪些是选中的项。在标准的 [组件测试](../testing-strategy/component-vs-integration-vs-e2e-testing.zh.md) 中，我们可以断言传递给 VirtualList 组件的上下文和下行的 props，故事直接控制这些 props，但是再次，Cypress 需要读取这些数据，因此故事必须将其暴露出来。

### 我们是在测试故事还是组件？

区别可能微妙。由于 VirtualList 是一个受控组件，故事的组件对其进行控制。故事组件内部的控制逻辑是需要测试的吗？控制组件和被控制组件是否可分离？可能不太可能。

标准测试有两个角色——测试运行器和受控组件——而使用 Cypress 与 Storybook 时有**三个角色——测试运行器、故事和受控组件**——。因此，如果组件测试控制组件并直接访问回调数据，Cypress 需要故事组件正常工作。

### 滚动和渲染项控制

VirtualList 组件利用惯性滚动，并且由于故事添加了成千上万个要渲染的项以完全显示 VirtualList 的潜力，所以滚动 VirtualList 可能会导致测试和下一个测试之间的渲染项略有不同。因此，我认为我们不能提前知道在滚动列表后将渲染哪些项（例如从第 100 个到第 110 个，或从第 101 个到第 111 个）。

为什么？因为**我讨厌基于脆弱假设的易碎测试**。测试不应该设计成可以抵御每一种可能的变化，而是必须足够健壮，能够经受小的变化。对于 VirtualList 测试来说，这意味着一旦滚动，将直接从 HTML 中检索渲染的项。我们将在后面深入探讨。

## 请给出代码

我们要编写的第一个测试需要检查，如果列表收到了 10000 个项目，只渲染其中的一小部分。这是 Virtual List 的基本功能。

首先是 RenderItem 组件，它只是交替更改颜色以直观标识行

```js
// every `item` is an { id: string, name: string}
const getItemText = (item) => `id: ${item.id} - ${item.name}`

const RenderItem = ({ item }) => {
  return (
    <div
      style={{
        height: '30px',
        backgroundColor: parseInt(item.id) % 2 ? '#FAFAFA' : '#EEE',
      }}
    >
      {getItemText(item)}
    </div>
  )
}
```

我们将处理的原始故事如下

```js
// `getStoryItems` allows to create a high amount of items, it's used by every story
export const With10000Items = () => {
  return (
    <>
      <h4>The scroll must be fluid</h4>
      <VirtualList
        items={getStoryItems({ amount: 10000 })}
        getItemHeights={() => 30}
        RenderItem={RenderItem}
        listHeight={300}
      />
    </>
  )
}
With10000Items.story = {
  name: 'With 10000 items',
}
```

我们需要调整故事以全局公开以下内容：

- `items` 数组：Cypress 测试需要知道用于填充列表的数据

- `getItemText` 函数：这样 Cypress 测试就无需关心如何从项目获取渲染的文本。Cypress 需要将项目转换为文本，以从其文本中检索渲染的项目，避免使用 `data-test` 属性

- 可见项目的数量：Cypress 测试需要断言哪些项目被渲染，哪些没有

以下是经过更新以通过全局 `storyData` 变量公开变量的故事：

```js
export const With10000Items = () => {
  const itemHeight = 30
  const listHeight = 300
  const items = React.useMemo(() => getStoryItems({ amount: 10000 }), [])

  // exposing data for Cypress
  React.useEffect(() => {
    // global is `window`
    global.storyData = {
      items,
      visibleItemsAmount: Math.ceil(listHeight / itemHeight),
      getItemText,
    }
  }, [items])

  return (
    <>
      <h4>The scroll must be fluid</h4>
      <VirtualList
        items={items}
        getItemHeights={() => itemHeight}
        RenderItem={RenderItem}
        listHeight={listHeight}
      />
    </>
  )
}
With10000Items.story = {
  name: 'With 10000 items',
}
```

### Cypress 的测试

测试将执行以下操作：

- 访问 Storybook 页面

- 收集公开的数据

- 检查渲染的项目

第一和第二点的代码如下：

```js
it('When the component receives 10000 items, then only the minimum number of items are rendered', () => {
  cy.visit('/iframe.html?id=virtuallist--with-10000-items')

  cy.window()
    .its('storyData')
    .should((storyData) => {
      // the story must expose some variables
      expect(storyData.items).to.be.to.have.length(10000)
      expect(storyData.visibleItemsAmount).to.be.greaterThan(0)
      expect(storyData.getItemText).to.be.a('function')
    })
    .then(() => {
      // the test code
    })
})
```

为什么要断言公开的 `storyData`？因为错误的 `storyData` 会导致测试失败，如果测试失败，它必须直接引导我们找到问题。如果组件渲染因为错误的 `storyData` 而失败，我们的测试根本不应该运行。这可以被视为**与数据相关的冒烟测试**。

现在，测试的缺失部分：检查哪些项目被渲染，哪些没有被渲染。

```js
it('When the component receives 10000 items, then only the minimum number of items are rendered', () => {
  cy.visit('/iframe.html?id=virtuallist--with-10000-items')

  cy.window()
    .its('storyData')
    .should((storyData) => {
      // the story must expose some variables
      expect(storyData.items).to.be.to.have.length(10000)
      expect(storyData.visibleItemsAmount).to.be.greaterThan(0)
      expect(storyData.getItemText).to.be.a('function')
    })
    .then(({ visibleItemsAmount, getItemText, items }) => {
      // items visibility check
      const visibleItems = items.slice(0, visibleItemsAmount - 1)
      visibleItems.forEach((item) => {
        cy.findByText(getItemText(item)).should('be.visible')
      })

      // first not-rendered item check
      cy.findByText(getItemText(items[visibleItemsAmount])).should('not.exist')
    })
})
```

- 我们使用公开的 `visibleItemsAmount` 变量来仅检索已渲染的项目

  const visibleItems = items.slice(0, visibleItemsAmount - 1)

- 我们使用公开的 `getItemText` 函数从页面中检索每个项目

  cy.findByText(getItemText(item))

- 我们断言所有预期可见的项目

  cy.findByText(getItemText(item)).should('be.visible')

- 我们断言下一个项目在页面中不存在

```js
cy.findByText(getItemText(items[visibleItemsAmount])).should('not.exist')
```

请注意，`cy.findByText` Cypress 命令来源于… [Cypress Testing Library](https://testing-library.com/docs/cypress-testing-library/intro) 😊，这是我最喜欢的检索页面元素的方式，因为它的行为就像用户一样：通过文本内容读取/检索元素。我使用它而不是 `cy.contains`，但它们执行相同的功能。

这就是结果：

![Cypress 受控浏览器，左侧是所有断言结果，右侧是 Storybook 故事。](../../assets/images/cypress-storyboook/list-test.png '第一个测试的结果：加载的故事和所有断言的结果。')_第一个测试的结果：加载的故事和所有断言的结果。_

这个测试足以检查虚拟列表是否只渲染了最小数量的项目。

最初，我试图检查在虚拟列表滚动时浏览器是否以 60 FPS 运行。为什么？因为**UI 测试必须检查用户所见的内容，以与用户相同的方式使用 UI**。从用户的角度来看，虚拟列表的唯一目标是必须流畅运行，无论列表中包含多少项目。但是可靠地测量 FPS 难度很大，因为测量结果会受到以下影响：

- 您使用的 Cypress 命令：每个 Cypress 动作都会减慢浏览器的速度

- 用于运行测试的机器（或 Docker 镜像）的资源数量

由于不可能获得可靠的计数 — 一些初始值将被丢弃等等 — 我决定仅检查渲染的项目数量。如果我确信只有 10000 项中的 10 项被渲染，那么我确信列表运行流畅。总的来说：记住**脆弱的测试比缺失的测试更糟糕**。

## 第二个测试：滚动

首先要说明：VirtualList 组件使用 [Smooth Scrollbar](https://idiotwu.github.io/smooth-scrollbar/)，Smooth Scrollbar 已经有了自己的测试，因此我们主要关注的是 VirtualList 组件如何响应滚动。在使用**第三方库**时，你不需要测试该库是否有效。该库**应该有自己的测试**，如果没有，就换个库吧！千万别为第三方库编写测试。

滚动测试的步骤包括：

- 触发滚动

- 等待滚动结束

- 检查渲染的项

因此，触发滚动的测试代码如下

```js
// triggers the wheel event
cy.findByTestId('VirtualList').trigger('wheel', {
  deltaX: 0,
  deltaY: 1000,
})
```

请注意，`VirtusList` 组件应该在渲染时生成一个带有 `data-test="VirtualList"` 属性的 DOM 元素。其余的由 Cypress 处理，`trigger` 直接映射了 [jQuery trigger API](https://api.jquery.com/trigger/)（Cypress 利用 jQuery 来尽量缩短测试代码）。再次强调一下：Cypress 的本地等价于 `cy.findByTestId('VirtualList')` 是 `cy.get('[data-testid=VirtualList]')`。

至于“等待滚动结束”的部分，我们将使用 [Cypress waitUntil](https://github.com/NoriSte/cypress-wait-until) 插件。为什么我们应该使用 waitUntil 插件而不是等待固定时间的原因在 [等待，不要让你的 E2E 测试休眠](../generic-best-practices/await-dont-sleep.zh.md) 章节中有详细的解释。
自定义等待的代码如下：

```js
// waits until the scrollbar handle stops
let scrollbarHandleY = Number.NEGATIVE_INFINITY
cy.get('.scrollbar-thumb-y').waitUntil(
  ($scrollbarHandle) => {
    const [newY, previousY] = [$scrollbarHandle.offset().top, scrollbarHandleY]
    scrollbarHandleY = newY
    return previousY === newY
  },
  {
    customMessage: 'The inertial scroll ends',
  }
)
```

因此，我们确保测试等待了正确的时间。

### 检查渲染的项目

这意味着：

- 查找第一个已渲染的项目

- 检查第一个已渲染的项目是否不是第一个项目。虚拟列表开始渲染从第 0 到 10 个项目。一旦滚动，它必须已渲染第 X 到 X+10 个项目。我们并不知道 X 的具体值，也并不关心，否则测试将与确切的已渲染项目绑定在一起。第一个已渲染的项目是第 60 或第 61 个并不重要。检查确切的已渲染项目超出了这个通用滚动测试的范围。测试的稳定性对我们有利。

- 一旦找到第一个已渲染的项目，我们检查接下来的十个项目是否都已渲染

我们将逐步进行每个步骤，测试的最终代码如下：

```js
it('When the component is scrolled, then the rendered items are not the first ones', () => {
  cy.visit('/iframe.html?id=virtuallist--with-10000-items')

  cy.window()
    .its('storyData')
    .should((storyData) => {
      // the story must expose some variables
      expect(storyData.items).to.be.to.have.length(10000)
      expect(storyData.visibleItemsAmount).to.be.greaterThan(0)
      expect(storyData.getItemText).to.be.a('function')
    })
    .then(({ visibleItemsAmount, getItemText, items }) => {
      // triggers the wheel event
      cy.findByTestId('VirtualList').trigger('wheel', {
        deltaX: 0,
        deltaY: 1000,
      })

      // waits until the scrollbar handle stops
      let scrollbarHandleY = Number.NEGATIVE_INFINITY
      cy.get('.scrollbar-thumb-y')
        .waitUntil(
          ($scrollbarHandle) => {
            const [newY, previousY] = [$scrollbarHandle.offset().top, scrollbarHandleY]
            scrollbarHandleY = newY
            return previousY === newY
          },
          {
            customMessage: 'The inertial scroll ends',
          }
        )
        // (manually) looks for the first rendered element
        .then(() =>
          items.findIndex((item) => !!Cypress.$(`*:contains("${getItemText(item)}")`).length)
        )
        // checks that the rendered items are not the initially rendered ones
        .should('be.greaterThan', 10)
        // checks the rendered items
        .then((firstVisibleItemIndex) => {
          const visibleItems = items.slice(
            firstVisibleItemIndex,
            firstVisibleItemIndex + visibleItemsAmount - 1
          )
          visibleItems.forEach((item) => cy.findByText(getItemText(item)).should('be.visible'))
        })
    })
})
```

逐步进行：检索第一个已渲染项目的代码如下：

```js
items.findIndex((item) => !!Cypress.$(`*:contains("${getItemText(item)}")`).length)
```

为什么不使用 `cy.findByText` 命令来检索呢？因为在 Cypress 中，每个 `cy.get` 命令（也是 `cy.findByText` 命令核心的一部分）都内置了断言，[在官方文档中查看](https://docs.cypress.io/api/commands/get.html#Assertions)。基本上，如果页面上不存在该元素，`cy.get` 将导致测试失败。但由于我们需要浏览未渲染的项目，直到找到第一个已渲染的项目，我们应该手动进行。Cypress.\$ 是 jQuery 的全局实例，`cy.findByText("XXX")` 的 jQuery 版本是 `Cypress.$(`\*:contains("XXX")`)`，而且 jQuery 版本如下：

```js
cy.findByText('XXX').should('exist')
```

是

```js
!!Cypress.$(`*:contains("XXX")`).length
```

唯一的区别是如果元素不存在，它不会导致失败。正如前面所说：我习惯使用 `cy.getByText`，但本地的 `cy.contains` 也能达到同样的效果！

一旦找到第一个已渲染项目的索引，我们只需检查接下来的已渲染项目。

```js
.then(() =>
  items.findIndex(
    item => !!Cypress.$(`*:contains("${getItemText(item)}")`).length,
  )
)
// checks that the rendered items are not the initially rendered ones
.should('be.greaterThan', 10)
// checks the rendered items
.then(firstVisibleItemIndex => {
  const visibleItems = items.slice(
    firstVisibleItemIndex,
    firstVisibleItemIndex + visibleItemsAmount - 1,
  )
  visibleItems.forEach(item =>
    cy.findByText(getItemText(item)).should('be.visible'),
  )
})
```

[这是测试的录像视频](https://www.youtube.com/watch?v=OEMkz_86bqY)。

请注意，我们不关心最后半个可见的项目。测试的范围是检查已渲染的项目是否不是第一个，并且至少有十个项目已被渲染，不需要检查第 11 个项目。

我们可以将测试的滚动部分移到一个独立的实用程序，类似于：

```js
const scrollVirtualList = ($list, deltaY = 1000) => {
  cy.wrap($list)
    .trigger('wheel', {
      deltaX: 0,
      deltaY,
    })
    .within(() => {
      // waits for the inertial scroll end
      let scrollbarY = Number.NEGATIVE_INFINITY
      getScrollbar().waitUntil(
        ($scrollbar) => {
          const newY = $scrollbar.offset().top
          const previousY = scrollbarY
          scrollbarY = newY
          return previousY === newY
        },
        {
          customMessage: 'The inertial scroll end',
        }
      )
    })
}
```

而且我们可以对查找第一个已渲染项目的过程采用相同的方法。

```js
const getFirstRenderedItemIndex = (items, getItemText) => {
  return items.findIndex((item) => !!Cypress.$(`*:contains("${getItemText(item)}")`).length)
}
```

这种分离的方式有助于测试的可读性，看一下：

```js
it('When the component is scrolled, then the rendered items are not the first ones', () => {
  cy.visit('/iframe.html?id=virtuallist--with-10000-items')

  cy.window()
    .its('storyData')
    .should((storyData) => {
      // the story must expose some variables
      expect(storyData.items).to.be.to.have.length(10000)
      expect(storyData.visibleItemsAmount).to.be.greaterThan(0)
      expect(storyData.getItemText).to.be.a('function')
    })
    .then(({ visibleItemsAmount, getItemText, items }) => {
      cy.findByTestId('VirtualList')
        // we leverage the new `scrollVirtualList` function
        .then(scrollVirtualList)
        .then(() => getFirstRenderedItemIndex(items, getItemText))
        .should('be.greaterThan', 10)
        .then((firstVisibleItemIndex) => {
          const visibleItems = items.slice(
            firstVisibleItemIndex,
            firstVisibleItemIndex + visibleItemsAmount - 1
          )
          visibleItems.forEach((item) => cy.findByText(getItemText(item)).should('be.visible'))
        })
    })
})
```

## 第三个测试：选择

VirtualList 组件通过键盘修饰键支持选择和**多项选择**。我们只需点击项目，用键盘修饰键点击项目，并检查哪些项目被选中。这些操作有什么难点呢？

- 首先：什么是“已选择”？从用户的角度来看，已选择的项目是“突出显示”的项目，但检查元素的样式并不可靠。我们可以为组件添加一个 `data-selected` 属性…

- … 但存在一个结构性的问题：项目可能根本没有被渲染！如果我们点击第一个项目（从第 1 个到第 10 个项目可见），然后滚动大约 20 个项目（从第 21 个到第 30 个项目可见），并按住 SHIFT 键点击中间的项目（第 25 个项目），则所选项目应该是从第 1 个到第 25 个，但前 20 个项目没有被渲染，因此我们无法通过已渲染的项目来检索已选择的项目。同样，**我们将使用故事中公开的变量**

这是故事的代码：

```js
export const WithSelectionManagement = () => {
  const items = getStoryItems({ amount: 10000 })

  const [selectedItems, setSelectedItems] = React.useState([])

  const handleSelect = React.useCallback(({ newSelectedIds }) => setSelectedItems(newSelectedIds), [
    setSelectedItems,
  ])

  // exposing data for Cypress
  React.useEffect(() => {
    global.storyData = {
      items,
      getItemText,
      selectedItems,
    }
  }, [items, selectedItems])

  return (
    <>
      <h4>The buttons must be clickable, the CTRL/CMD, ALT, SHIFT keyboard modifiers must work</h4>
      <VirtualList
        items={items}
        selectedItemIds={selectedItems}
        getItemHeights={() => 30}
        RenderItem={createSelectableRenderItem({ height: 30 })}
        listHeight={300}
        onSelect={handleSelect}
      />
    </>
  )
}
```

由于 VirtualList 组件是受控组件，它会将所选项目的列表——`selectedItems` 数组——传递给上层。父组件——即故事——向 Cypress 公开了该数组，以便进行所选项目的断言。
请注意：组件的创建，包括点击管理，已经移到了一个专用的高阶函数中：`createSelectableRenderdItem`。

选择单个项目的测试如下：

```js
it('When the items are clicked, then they are selected', () => {
  cy.visit('/iframe.html?id=virtuallist--with-selection-management')

  cy.window()
    .its('storyData')
    .should((storyData) => {
      // the story must expose some variables
      expect(storyData.items).to.be.to.have.length.of.at.least(3)
      expect(storyData.getItemText).to.be.a('function')
      expect(storyData.selectedItems).to.be.an('array')
    })
    .then(({ getItemText, items }) => {
      cy.findByText(getItemText(items[0]))
        .click()
        .window()
        .its('storyData.selectedItems')
        .should('eql', [items[0].id])

      cy.findByText(getItemText(items[1]))
        .click()
        .window()
        .its('storyData.selectedItems')
        .should('eql', [items[1].id])
    })
})
```

所有的断言都在公开的 `selectedItems` 数组本身上。我们不检查已渲染的项目是否被突出显示（突出显示项目的责任属于故事创建的组件），而是仅仅检查 VirtualList 组件是否正确处理了项目的点击。

`selectedItems` 数组不是在开始时读取的，而是在每次点击后读取，因为我们需要始终检查更新后的数组，而不是对初始数组的引用（`selectedItems` 由 `React.useState` 返回，因此在每次选择更新后都是新的）。

### 多项选择的断言

接下来的步骤是检查 VirtualList 组件是否正确处理了使用 Meta 键。在按住 Meta 键的情况下单击另一个项目应该导致两个项目被选中。

我们如何在 Cypress 中保持按住 Meta 键呢？只需：

```js
cy.get('body')
  // keeping pressed the meta (CMD) key
  .type('{meta}', { release: false })

// ...your test code...

cy.get('body')
  // releasing the meta (CMD) key
  .type('{meta}', { release: true })
```

添加项目点击将导致：

```js
cy.get('body')
  // keeping pressed the meta (CMD) key
  .type('{meta}', { release: false })
  .findByText(getItemText(items[2]))
  .click()
  .window()
  .its('storyData.selectedItems')
  .should('eql', [items[1].id, items[2].id])
  .get('body')
  // releasing the meta (CMD) key
  .type('{meta}', { release: true })

  cy.get('body')
    .type('{shift}', { release: false })
    .findByText(getItemText(firstRenderedItem))
    .click()
    .window()
    .its('storyData.selectedItems')
    .should('eql', expectedSelectedItemIds)
    .get('body')
    .type('{shift}', { release: true })
  })
```

这是测试结果的屏幕截图

![受控浏览器，左侧是所有断言结果，右侧是 Storybook 故事和选定的项目。](../../assets/images/cypress-storyboook/selection-test-result.png '测试的第一个结果：加载的故事和所有断言的结果。')_测试的第一个结果：加载的故事和所有断言的结果。_

### 滚动和选择

通过 `scrollVirtualList` 实用程序轻松滚动列表，通过 `getFirstRenderedItemIndex` 完成查找第一个已渲染项目，我们知道如何保持按键按下... 因此，测试滚动并带有 Shift 修饰键的点击（这意味着选择从先前点击的元素到最后一个元素的所有内容）应该只是计算所有（预计的）已选择项目的问题。下面的代码正是这样，继续查看完整的测试代码。

```js
cy.findAllByTestId('VirtualList')
  // scrolls the list
  .then(scrollVirtualList)
  .then(() => {
    // identifies the first rendered item (unknown in advance)
    const firstRenderedItemIndex = getFirstRenderedItemIndex(items, getItemText)
    const firstRenderedItem = items[firstRenderedItemIndex]

    // the tests is going to click on the first rendered item
    // keeping the SHIFT key pressed. All the items up to the first
    // rendered one should be selected
    const expectedSelectedItemIds = items
      .slice(0, firstRenderedItemIndex + 1)
      .map((item) => item.id)

    cy.get('body')
      .type('{shift}', { release: false })
      .findByText(getItemText(firstRenderedItem))
      .click()
      .window()
      .its('storyData.selectedItems')
      .should('eql', expectedSelectedItemIds)
      .get('body')
      .type('{shift}', { release: true })
  })
```

测试的完整代码，对每个键盘修饰键进行检查，可能会比较冗长但相当重复。

```js
it('When the items are clicked, then they are selected', () => {
  cy.visit('/iframe.html?id=virtuallist--with-selection-management')

  cy.window()
    .its('storyData')
    .should((storyData) => {
      // the story must expose some variables
      expect(storyData.items).to.be.to.have.length.of.at.least(3)
      expect(storyData.getItemText).to.be.a('function')
      expect(storyData.selectedItems).to.be.an('array')
    })
    .then(({ getItemText, items }) => {
      // first item click
      cy.findByText(getItemText(items[0]))
        .click()
        .window()
        .its('storyData.selectedItems')
        .should('eql', [items[0].id])

      // second item click
      cy.findByText(getItemText(items[1]))
        .click()
        .window()
        .its('storyData.selectedItems')
        .should('eql', [items[1].id])

      // third item click with Meta modifier
      cy.get('body')
        .type('{meta}', { release: false })
        .findByText(getItemText(items[2]))
        .click()
        .window()
        .its('storyData.selectedItems')
        .should('eql', [items[1].id, items[2].id])
        .get('body')
        .type('{meta}', { release: true })

      // first item click with Shift modifier
      cy.get('body')
        .type('{shift}', { release: false })
        .findByText(getItemText(items[0]))
        .click()
        .window()
        .its('storyData.selectedItems')
        .should('eql', [items[2].id, items[1].id, items[0].id])
        .get('body')
        .type('{shift}', { release: true })

      // second item click with Alt modifier
      cy.get('body')
        .type('{alt}', { release: false })
        .findByText(getItemText(items[1]))
        .click()
        .window()
        .its('storyData.selectedItems')
        .should('eql', [items[2].id, items[0].id])
        .get('body')
        .type('{alt}', { release: true })

      // scrolling
      cy.findAllByTestId('VirtualList')
        .then(scrollVirtualList)
        .then(() => {
          const firstRenderedItemIndex = getFirstRenderedItemIndex(items, getItemText)
          const firstRenderedItem = items[firstRenderedItemIndex]
          const expectedSelectedItemIds = items
            .slice(0, firstRenderedItemIndex + 1)
            .map((item) => item.id)

          // x-th item click with Shift modifier
          cy.get('body')
            .type('{shift}', { release: false })
            .findByText(getItemText(firstRenderedItem))
            .click()
            .window()
            .its('storyData.selectedItems')
            .should('eql', expectedSelectedItemIds)
            .get('body')
            .type('{shift}', { release: true })
        })
    })
})
```

[测试结果如下](https://www.youtube.com/watch?v=0DGHRJnWbHw)。

正如您所看到的，左侧的 Command Log 没有清楚地显示发生了什么。我们可以通过添加一些 `cy.log` 调用来提高测试的可读性，或者更好地利用 [Filip 的解决方案](https://medium.com/slido-dev-blog/cypress-tips-3-improve-your-error-screenshots-in-cypress-b3675968a190) 来充分利用 Cypress 的日志记录。

## 优化

测试运行得越快越好。我的原始测试套件花了将近 16 秒才能完全运行。[这里是视频录像](https://www.youtube.com/watch?v=EwBz844FuxE)（请注意，这是第一个测试套件，带有 60 FPS 测试）。

有两个主要的优化方向：

- 在故事之间更快地切换（而不是在测试之间重新加载页面）

- 通过 Cypress 强制浏览器时钟来加速滚动

### 在故事之间更快地切换

感谢 Nicholas Boll 和他的 [cypress-storybook](https://github.com/NicholasBoll/cypress-storybook) 插件，该插件利用 storybook APIs 在不重新加载整个页面的情况下加载所需的故事。

截至撰写本文时，我们只需要执行以下操作：

- 在 Storybook 配置中添加 `import 'cypress-storybook/react'`

- 在 Cypress 的 support/index.js 文件中添加 `import 'cypress-storybook/cypress'`

- 在测试文件中添加一个 `before` 钩子

```js
before(() => {
  // Visit the storybook iframe page once per file
  cy.visitStorybook()
})
```

- 通过 `cy.loadStory('VirtualList', 'With 10000 items')` 加载故事，而不是使用 `cy.visit`

- 在视频之后解释的公开变量上进行更新

这样做的话，页面在每个测试中都不会重新加载，整个测试套件节省了 3 秒，可以查看[这个视频](https://www.youtube.com/watch?v=UJhPTJhDEFM)。

我们为什么需要根据故事更新变量呢？嗯，如果页面没有重新加载，我们无法确保公开的变量是所需的变量，特别是因为几乎每个故事都会公开一个 `items` 变量，但变量的内容会有所不同。

我们如何区分故事公开的变量呢？嗯，公开故事名称就可以了！

```js
React.useEffect(() => {
  global.storyData = {
    // the name of the story is exposed too
    storyName: 'With 10000 items',
    items,
    visibleItemsAmount: Math.ceil(listHeight / itemHeight),
    getItemText,
  }
}, [items])
```

这样一来，每个测试都可以检查期望的名称。

```js
it('When the component receives 10000 items, then only the minimum number of items are rendered', () => {
  const story = 'With 10000 items'
  cy.loadStory('VirtualList', story)

  cy.window()
    .its('storyData')
    .should((storyData) => {
      // caring about the story name
      expect(storyData.storyName).to.eq(story)

      expect(storyData.items).to.be.to.have.length(10000)
      expect(storyData.visibleItemsAmount).to.be.greaterThan(0)
      expect(storyData.getItemText).to.be.a('function')
    })
    .then(({ visibleItemsAmount, getItemText, items }) => {
      // ... test code...
    })
})
```

利用 [Cypress 重试性](https://docs.cypress.io/guides/core-concepts/retry-ability.html) 来等待所有断言通过。这样我们确保公开的变量是正确的。

13 秒与最初的 16 秒相比可能听起来并不是巨大的改进… 但它是！因为如果我们在测试没有惯性滚动的组件（例如表单）的情况下，收益可能不是从 16 秒到 13 秒，而更有可能是从 9 秒到 6 秒！相信我，**永远不要低估测试速度**…

### 通过控制时钟加速滚动

视频突显了大部分测试持续时间都花在等待惯性滚动完成上。这并没有错，但一些测试运行器允许您控制时间流逝，Cypress 就是其中之一。在需要测试 `setTimeout` 或 `setInterval` 相关内容或惯性滚动之类的动画时，推动时间前进是至关重要的。

[官方文档](https://docs.cypress.io/api/commands/clock.html)中有很多示例，但对我们的需求来说，基本用法就足够了。我们需要调用 `cy.clock()`，然后使用 `cy.tick(<毫秒>)` 推动时间。

第一个使用新时钟控制的测试已注释。

```js
it('When the component is scrolled, then the rendered items are not the first ones', () => {
  const story = 'With 10000 items'
  cy.loadStory('VirtualList', story)

  // take control of the browser clock
  cy.clock()

  cy.window()
    .its('storyData')
    .should((storyData) => {
      expect(storyData.storyName).to.eq(story)
      expect(storyData.items).to.be.to.have.length(10000)
      expect(storyData.visibleItemsAmount).to.be.greaterThan(0)
      expect(storyData.getItemText).to.be.a('function')
    })
    .then(({ visibleItemsAmount, getItemText, items }) => {
      // this test does not need the `scrollVirtualList` utility anymore
      cy.findByTestId('VirtualList')
        .trigger('wheel', {
          deltaX: 0,
          deltaY: 1000,
        })

        // ticking the clock by one second.
        // It jumps to the inertial scroll end.
        .tick(1000)

        .then(() => getFirstRenderedItemIndex(items, getItemText))
        .should('be.greaterThan', 10)
        .then((firstVisibleItemIndex) => {
          const visibleItems = items.slice(
            firstVisibleItemIndex,
            firstVisibleItemIndex + visibleItemsAmount - 1
          )
          visibleItems.forEach((item) => cy.findByText(getItemText(item)).should('be.visible'))
        })
    })
})
```

[这是测试结果](https://www.youtube.com/watch?v=m6u0H8_jQuc)。

正如您所看到的，我们在惯性滚动结束时立即跳过。请注意：整个测试持续时间被屏幕录制所虚构，没有录制时测试所需的时间更短。

请记住，如果您使用了 `cy.clock`，使用 `cy.tick` 是强制的！如果您不手动进行时间推进，列表根本不会滚动，因为时钟被冻结了！看看如果不推进时钟会发生什么

![列表停留在初始位置和失败的测试。](../../assets/images/cypress-storyboook/clock-without-tick.png '_列表停留在初始滚动水平位置，因为我们没有推进时钟。')_列表停留在初始滚动水平位置，因为我们没有推进时钟._

`.should('be.greaterThan', 10)` 的断言未满足，因为列表根本没有滚动。

对几乎所有测试应用时钟控制，其持续时间减少了 9 秒。最终结果在下一个视频中

https://www.youtube.com/watch?v=Otf3J7qFAtI

最终结果：**从最初的 16 秒到 9 秒**，很棒！测试运行得越快，你就能更好地利用它们！

### “No preview”错误

如果遇到此错误

![Storybook 的“无预览”错误，显示在 Cypress 测试中。](../../assets/images/cypress-storyboook/no-preview-error.png)

重新启动 Cypress 应该足够了。否则，请重新启动 Storybook。这在几小时内仅发生了两次，所以我还没有深入研究它。

## 结论

简而言之，上述列出的解决方案是：

- 利用 [cypress-storybook](https://github.com/NicholasBoll/cypress-storybook) 允许 Cypress 快速切换故事

- 故事应该公开一些全局变量，允许 Cypress 进行数据断言

- 尽可能加速测试，例如在示例中，由于 Cypress 的时钟控制，惯性滚动不会等待

- 考虑是否要测试渲染的组件、故事代码或两者兼而有之

- 工具将更加集成，组件测试是目前的热门话题

<!-- TODO: 最后决定是否将所有资源移动到共同章节 -->

<br /><br />

_由 [NoriSte](https://github.com/NoriSte) 在 [dev.to](https://dev.to/noriste/testing-a-virtual-list-component-with-cypress-and-storybook-3lam) 和 [Medium](https://medium.com/@NoriSte/testing-a-virtual-list-component-with-cypress-and-storybook-494dc2d1d26b)上进行联合发表._



================================================
FILE: sections/tools/cypress-react-component-test.md
================================================
# [OBSOLETE] Unit Testing React components with Cypress

*This section is now marked as obsolete because it refers to a very old version of Cypress (that now fully supports component tests).*

---

_**UPDATE**: [Cypress 10 is out with Component Testing integrated with E2E testing](https://www.cypress.io/blog/2022/06/01/cypress-10-release/), please check it out and ignore all the configuration steps reported below since they are outdated!_

---

_**UPDATE**: [Cypress 7 is out with a brand-new Component Test](https://docs.cypress.io/guides/component-testing/introduction#What-is-Component-Testing) support, check it out! And other exciting news is on the way thanks to [Storybook 6.2 release](https://twitter.com/NoriSte/status/1378204109841571840)!_

---

Now that unit testing React component is possible with Cypress, this is an extending chapter of the [Testing a component with Cypress and Storybook](./cypress-and-storybook.md) one.

The goal of the previous chapter was to run some experiments in the **React Component Testing world**, a really important topic nowadays.

The motivations were pretty simple:

- you probably already have [Storybook](https://storybook.js.org/) in action in your team (if not, consider adding it!)

- you could be not familiar with testing components with [Testing Library](https://testing-library.com/) or you could be biased about JSDom or you could want to test your UI components in a real browser, not in a simulated DOM environment

- you could be familiar with [Cypress](https://www.cypress.io/) or [TestCafé](https://devexpress.github.io/testcafe/) (if not, consider them for your UI tests) and you could want to use just a single tool for your tests

And the approach was simple too:

- exposing the story’ props to the testing tool, used to control the rendered component

- pick up them from Cypress/TestCafé, automating user actions and asserting about the contents of the props

But there were **some caveats**…

- performance: in the [chapter](https://github.com/NoriSte/all-my-contributions), I put some extra-efforts to minimize the impact of story switching slowness

- **testing and stories coupling**: since Storybook is consumed even by Cypress, stories are going to be accountable not only for sharing the design system across the team but for the component tests too

- **callback testing got tough**: checking the params and the calls of the callback props is difficult

Some of the problems of my experiment could be mitigated by [daedalius approach](./cypress-and-storybook-exposing-component-from-story.md) but the solution is not optimal yet, but then…

## Cypress 4.5.0 has been released

On April, 28th, Cypress 4.5.0 has been released, the only released feature is the following

> Cypress now supports the execution of component tests using framework-specific adaptors when setting the experimentalComponentTesting configuration option to true. For more details see the [cypress-react-unit-test](https://github.com/bahmutov/cypress-react-unit-test) and [cypress-vue-unit-test](https://github.com/bahmutov/cypress-vue-unit-test) repos.

What does it mean? That Cypress can now directly mount a React component giving the **[cypress-react-unit-test](https://github.com/bahmutov/cypress-react-unit-test)** a new birth! Before Cypress 4.5.0 release, the plugin was pretty limited but now it has first-class support! In fact, the cypress-react-unit-test is now rock-solid and a meaningful plugin.

## Testing the VirtualList component: second episode

The component is always the same, the VirtualList, read more about it in [the previous chapter](./cypress-and-storybook.md). We need to set up both the [cypress-react-unit-test](https://github.com/bahmutov/cypress-react-unit-test) and the TypeScript conversion (the component is written in TypeScript, it is part of a [Lerna](https://github.com/lerna/lerna) monorepo, and it is compiled with Webpack). Both the steps are straightforward but if the plugin has an [installation-dedicated section in its documentation](https://github.com/bahmutov/cypress-react-unit-test#install), the TypeScript compilation could not be obvious because there are, outdated or partial, a lot of different approaches and resources.
The most concise yet effective solution is [André Pena’s one](https://stackoverflow.com/a/60017105/700707), so all I had to do is:

- adding a _cypress/webpack.config.js_ file

```js
module.exports = {
  mode: 'development',
  devtool: false,
  resolve: {
    extensions: ['.ts', '.tsx', '.js'],
  },
  module: {
    rules: [
      {
        test: /\.tsx?$/,
        exclude: [/node_modules/],
        use: [
          {
            loader: 'ts-loader',
            options: {
              // skip typechecking for speed
              transpileOnly: true,
            },
          },
        ],
      },
    ],
  },
}
```

- adding a _cypress/tsconfig.json_ file

```json
{
  "extends": "../tsconfig.json",
  "compilerOptions": {
    "types": ["cypress", "cypress-wait-until"]
  }
}
```

please note that:

- the ../tsconfig.json file is the same used by the React app

- [cypress-wait-until](https://github.com/NoriSte/cypress-wait-until) is not mandatory but I use it a lot and it is one of the most installed plugins for Cypress

The above transpiling-related files, along with the following cypress.json file

```json
{
  "experimentalComponentTesting": true,
  "componentFolder": "cypress/component"
}
```

are enough to start playing with a _cypress/component/VirtualList.spec.tsx_ test! From the previous chapter, the first test was the standard rendering, the _“When the component receives 10000 items, then only the minimum number of items are rendered”_ test, et voilà:

```typescript
/// <reference types="Cypress" />
/// <reference types="cypress-wait-until" />

import React from 'react'
import { mount } from 'cypress-react-unit-test'
import '[@testing](http://twitter.com/testing)-library/cypress/add-commands'

import { VirtualList } from '../../src/atoms/VirtualList'
import { getStoryItems } from '../../stories/atoms/VirtualList/utils'

describe('VirtualList', () => {
  it('When the list receives 10000 items, then only the minimum number of them are rendered', () => {
    // Arrange
    const itemsAmount = 10000
    const itemHeight = 30
    const listHeight = 300
    const items = getStoryItems({ amount: itemsAmount })
    const visibleItemsAmount = listHeight / itemHeight

    // Act
    mount(
      <VirtualList
        items={items}
        getItemHeights={() => itemHeight}
        RenderItem={createRenderItem({ height: itemHeight })}
        listHeight={listHeight}
      />
    )

    // Assert
    const visibleItems = items.slice(0, visibleItemsAmount - 1)
    itemsShouldBeVisible(visibleItems)

    // first not-rendered item check
    cy.findByText(getItemText(items[visibleItemsAmount])).should('not.exist')
  })
})
```

Compared to the Storybook-related chapter:

- the

```js
/// <reference types="Cypress" />
/// <reference types="cypress-wait-until" />
```

at the beginning are needed to let VSCode correctly leverage TypeScript suggestions and error reporting

- we use cypress-react-unit-test’ mount API to mount the component, nothing especially new if you are used to the [Testing Library APIs](https://testing-library.com/docs/react-testing-library/api)

Nothing more, the Cypress test continues the same as the Storybook-related one 😊

### Callback Testing

Porting all the tests from the [previous chapter](./cypress-and-storybook.md) is quite easy, what was missing is the callback testing part of the “selection test”.

Creating a _WithSelectionManagement_ wrapper component that renders the _VirtualList_ one and manages items selection is quite easy and we can pass it our stub and assert about it

```typescript
it('When the items are clicked, then they are selected', () => {
  const itemHeight = 30
  const listHeight = 300
  let testItems

  const WithSelectionManagement: React.FC<{
    testHandleSelect: (newSelectedIds: ItemId[]) => {}
  }> = (props) => {
    const { testHandleSelect } = props
    const items = getStoryItems({ amount: 10000 })

    const [selectedItems, setSelectedItems] = React.useState<(string | number)[]>([])

    const handleSelect = React.useCallback<(params: OnSelectCallbackParams<StoryItem>) => void>(
      ({ newSelectedIds }) => {
        setSelectedItems(newSelectedIds)
        testHandleSelect(newSelectedIds)
      },
      [setSelectedItems, testHandleSelect]
    )

    React.useEffect(() => {
      testItems = items
    }, [items])

    return (
      <VirtualList
        items={items}
        getItemHeights={() => itemHeight}
        listHeight={listHeight}
        RenderItem={createSelectableRenderItem({ height: itemHeight })}
        selectedItemIds={selectedItems}
        onSelect={handleSelect}
      />
    )
  }
  WithSelectionManagement.displayName = 'WithSelectionManagement'

  mount(<WithSelectionManagement testHandleSelect={cy.stub().as('handleSelect')} />)

  cy.then(() => expect(testItems).to.have.length.greaterThan(0))
  cy.wrap(testItems).then(() => {
    cy.findByText(getItemText(testItems[0])).click()
    cy.get('[@handleSelect](http://twitter.com/handleSelect)').should((stub) => {
      expect(stub).to.have.been.calledOnce
      expect(stub).to.have.been.calledWith([testItems[0].id])
    })
  })
})
```

Please refer to the full SinonJS (wrapped and used by Cypress) [Stub](https://sinonjs.org/releases/v9.0.2/stubs/)/[Spy](https://sinonjs.org/releases/v9.0.2/spies/) documentation for the full APIs.

## Conclusions

Take a look at the result in [this video](https://youtu.be/yVL-yRT5hFQ). The test lasts now less than seven seconds, without depending nor loading Storybook, leveraging first-class Cypress support.

What’s next? The [cypress-react-unit-test](https://github.com/bahmutov/cypress-react-unit-test) plugin is quite stable and useful now, a whole new world of experiments is open and a lot of small-to-medium projects could choose to leverage Cypress as a single testing tool.

<!-- TODO: in the end, decide if you want to move all the resources to a common chapter too -->

<br /><br />

_Crossposted by [NoriSte](https://github.com/NoriSte) on [dev.to](https://dev.to/noriste/unit-testing-react-components-with-cypress-5fk2) and [Medium](https://medium.com/@NoriSte/unit-testing-react-components-with-cypress-4d4cf8cd59a0)._



================================================
FILE: sections/tools/cypress-react-component-test.zh.md
================================================
[Binary file]


================================================
FILE: sections/tools/ui-testing-problems-cypress.md
================================================
> [!NOTE]
> All the modern front-end testing tools (Playwright, Storybook, Cypress, TestCafé) all have the similar functionalities and UI tools, so this same contents applies to all of them, not just Cypress.


# Some UI testing problems and the Cypress way

_Call for contributors: are you a TestCafé expert? I would like to split the "problems" section from the "how Cypress solves them" one, and add a section dedicated to how TestCafé solves them!_

Testing a front-end application brings some challenges that the “classic” tests have not: you need to **orchestrate a real browser**. Browsers are heavy applications by definition, and you need to launch them, manage them through a made on purpose library, leverage some APIs to automate the same kind of interactions the user would do, and then check if the state of front-end application (essentially what it shows) is the same you expect it to have.

This process and the involved steps are what make UI testing hard. The main problems are:

- **Everything** is asynchronous: the user-simulated interactions are asynchronous, the UI reacts asynchronously, the browser reacts asynchronously, the tool you use to orchestrate and communicate with the browser is asynchronous

```js
await page.goto(url);
await page.click('[data-test="contact-us-button"]');
await expect(page).toMatch("Contact Us");
```

And, as soon as you need something more complicated, await-ing everything leads you to deeply manage promises and recursive promises.

- **You automate user flows**: so you need to reproduce user flows, inspect automatic user flows, debug failing (and automatic, and super fast) user flows.
  Imagine being side by side with a colleague of yours that has a problem, you ask him to make something so you can inspect the issue directly with his browser DevTools but he **does not stop to click/type when you need to inspect the problem**. This is the kind of situation you need to face when something does not go as expected with a UI test. Pausing/stopping a running flow is hard and you need to relaunch the same tests a lot of times

- There are a lot of cases, in a web application, that can interfere with an element’ interactivity: its internal state, its markup properties, its visual appearance, the appearance of other elements, etc. Some of them are easy to be discovered (a “disabled” attribute for example) but some are not (another element with a higher z-index value). More in general, **it is hard to debug the causes**, because you need to double-check the element itself, the whole page, the tool that automates the interactions, etc.

Automating and testing a front-end application is hard but there are some tools that do not alleviate the pain and some other that give you superpowers, go on!

### Common tools

To automate and test a front-end application you need two different tools:

- A test runner: the one that takes care of executing the test itself

- A browser automation tool: something that exposes some APIs to interact with a launched on purpose browser

The tools are independent and while the test runner of your choice (Jest, for example) runs in the terminal (and gives you all the test feedback), the second one (Selenium or Puppeteer) opens a browser, executes the commands written in the test, and gives back the result.

![There is two-way communication between the terminal-based test runner and the browser automation tool.](../../assets/images/ui-testing-problems-cypress/terminal-and-browser.jpg)_There is two-way communication between the terminal-based test runner and the browser automation tool._

**The two tools are detached** and this complicates a lot of things! The actions that run in the browser are really fast! You can slow down them but you cannot pause or stop them! Or, better, I mean not interactively… Because you obviously can **jump back and forth** from the code editor, change the test commenting everything after the step you want to inspect, re-launching the test and checking what happened. But this is not an ideal flow. And since the test is a little program, you know that you need to repeat this step a lot of times…

Another problem arises while running a test in an above-described way: you typically log in to the terminal (where the test runner works) while the actions happen in the browser. **How could you connect them?** Do you add timestamp logging both in the terminal and in the browser console? Do you add a fixed-div above your front-end application that shows you the name of the running test? Connecting what happens in the browser with what you do (or log) through the terminal is hard, too.

Last but not least: when you debug the test in the terminal, you are not debugging real DOM elements, but serialized/referenced ones. There is not any kind of two-way interactivity between the terminal and the browser and so you cannot leverage the browser DevTools the way you are used to doing.

Trust me, understanding why a test is failing or why the browser does not what you expect it to do is really hard this way. But you must face that in all the three different phases of the test-consuming process:

- 1: while you initially write the test

- 2: while the test fails and you cannot send anything to production

- 3: while you need to update them because the specifications changed

Step #1 and #3 are pretty similar, #3 could be faster but #1 could be exhausting. #2 will make you hate UI testing literally if the tools you are using do not help you…

## Test runner purposes

Stop for a moment and think about what the mentioned tools try to accomplish, starting from the test runners.

Test runners are made for managing unit tests. You can use/plug them the way you want, obviously, but they are made essentially for super-fast (and parallelized) small-function invocations. They do not have browser-like DevTools but **the main problem is test timeouts**. Every test has a timeout and it is completely reasonable. Thanks to the timeout, if a test takes too long, the test runner kills it.

But what happens when you combine the test timeout with the UI-testing needs? As you know, a user flow could last really long. For a lot of reasons:

- The interaction themselves could be really long and involve tens of clicking, typing, calculations, waitings, etc.

- There is a lot of stuff that **cannot be controlled (from a duration perspective)** at all: XHR requests above all! You cannot know how much the Docker container (or the staging server) could take to respond. And if the back-end is not dockerized you have to face network slowness too

These examples show you how unpredictable could be a UI test. The solution could seem handy: incrementing the test timeout! But this is the worst solution, it does not work because:

- Test timeouts are the guillotine that could save you a lot of time when something goes wrong. If you set the timeout to one minute you are going to **wait one more minute** (60 seconds!!!!) if a single test does not work as expected. Test excessive durations are one of the main reasons developers hate tests because pipelines last forever. Nonetheless: in some particular scenarios, you cannot be sure 60 seconds are enough… Think about AWS lambdas wake-up time in case of slow servers, mixed with network problems…

- What about the debugging process? Remember that when the test is killed because of the timeout, the automated browser is closed automatically...

Last but not least, remember that you need to have DOM-related assertions. In a UI test, you do not treat objects, arrays, and primitives, but you manage essentially DOM elements. Assertions like “I expect the element is equal to…” does not work, while it works for unit testing, obviously. This problem is usually solved with external plugins.

## Browser automation tool purposes

Selenium and Puppeteer aim for an easy, magics-free, UI automation experience. They are not meant to test the UI, but only to automate the user interactions. **Automating and testing overlap** in some ways but they are not the same. Both try to understand if a button is clickable and try to click it, but while the former fail, the latter tries to tell you why it failed. While the former tells you that an element is not on the page, the latter tells you that it is not on the page because the previous XHR request failed.

We were used to putting together a test runner with a browser automation tool and try to get the best of them, but suffering from what two non-integrated and different tools could not offer.

Speaking again about the test (and the app under test) debuggability: in order to slow down/debug/pause/stop/make-them-working, etc. you need to “sleep” the tests a lot of times. It is a common practice, both because it solves problems in the short term, and sometimes because you do not have alternatives (read the [Await, don't sleep](../generic-best-practices/await-dont-sleep.md) section). Unfortunately, add some **“sleep” steps makes the tests worse and worse**, slower and slower. As I wrote previously: test slowness is one of the most common flaws that brings developers to hate UI tests.

More: **what happens when a test fails?** What you can do to understand the problem before understanding how to fix the bug? If you are lucky enough to discover the broken test locally, your pains are limited. But if the test fails in a pipeline, how could you know what happened if you do not have a UI? Have you added some parachute automate screenshot? Is there anything that speaks better than a screenshot? Unfortunately not…

You need even to leverage third-party debugging tools (React DevTools, Vue DevTools, etc.) but their installation process onto the controlled browser is not the handiest in the world.

Last but not least: stubbing the server and asserting about the XHR requests could be considered testing implementation details… But I do not think so, for two reasons:

- While speaking about blackbox testing, we refer to the (good) practice of avoiding to test how something works, concentrating only on what it does. Applied to a front-end application, it means testing just the functionalities that the app exposes to the user, not how the app exposes it (it does not matter if it works with React or Vue.js, if it saves data into localStorage or sessionStorage). The same could be applied to the client/server communication but understanding that something did not happen because of a wrong XHR request could be hard (especially when you run the automated browser in headless mode). While the help you get from asserting about the request payload, the response payload, the response status, etc., is priceless (**always care about how much a test drives you to identify the problem in case of failures**).

- You do not need to do that if you test the client/server contract with Pact or a similar tool, but do you have these kinds of tests in your workflow?

- If you are a front-end developer, you know that you cannot always work after the back-enders completed their work. But if they provide you the whole JSON responses, stubbing the back-end allows you to complete all the front-end coding jobs, leaving the last mile of work to check that everything works as expected when you integrate the front-end with the back-end. It is a matter of productivity.

## Implicit testing challenges

The above considerations create another problem: **the test code should be as simple as possible**. Tests allow you to check that everything works as expected but they are little programs after all. And so, you need to maintain them, over time. And since you need to understand them in a while (it is unfeasible if you need hours to understand why and how a test works, tests must help you, not complicate your life like bad code could do), their code should not be complicated (read the [Software tests as a documentation tool](../testing-perks/tests-as-documentation.md) section).

But, tools that are not created for a difficult task like UI testing, do not help you writing simple tests code. And your testing life gets harder, again… Hence you are condemned to spend a lot of time debugging a failing test instead of understanding what did not work in your front-end application (assuming that something broke…). **The result is fewer test trustability**…

## Cypress to the rescue

Do not worry, I have not reported this dramatic situation for the sake of your sadness 😉 but just to get you aware that you do not need generic tools mixed together, you need something made on purpose! Two tools come to my mind: [Cypress](https://www.cypress.io/) and [TestCafé](https://devexpress.github.io/testcafe/). Both are super valid since they have just one goal in mind: reinventing (or fixing?) the UI testing world.

I concentrate on Cypress and I compare them later.
How does Cypress solve all the above problems? First of all…

## Cypress has a UI

Yes, you start Cypress through the terminal, but you consume it [through its UI](https://docs.cypress.io/guides/core-concepts/test-runner.html)! And the UI is side-by-side with your application! Take a look at this preview

![The [Command Log UI](https://docs.cypress.io/guides/core-concepts/test-runner.html) (on the left) runs alongside your front-end application (on the right).](../../assets/images/ui-testing-problems-cypress/cypress-preview.png)_The [Command Log UI](https://docs.cypress.io/guides/core-concepts/test-runner.html) (on the left) runs alongside your front-end application (on the right)._

What does it mean? What are the main [Command Log UI](https://docs.cypress.io/guides/core-concepts/test-runner.html) features?

- **You have direct feedback for what Cypress is doing**. Every time you ask Cypress to interact with the page through its commands (cy.click , cy.type, etc.), Cypress adds a log to the Test Runner. This verbose automatic logging is really helpful both while writing your test and while debugging it. It seriously improves your productivity, both because it is automatic and because it is side-by-side with your application.

But, as I told you, the lack of retroactive debuggability is a big missing while writing UI tests… Let me introduce you…

- **Interactive time-traveling**: not sure how the app reached a particular command or how the test failed? Would you take a look at the UI at a previous step? That is why the Command Log is interactive! You can hover the various logged steps and see how the app looks at a particular step! Or, obviously, you can pin a step and inspect the DOM, check how the app looks before/after the step, etc. This is another life-saver feature, both at the first approach (debugging a test when you do not know the testing tool could be a nightmare) and in the day-by-day testing work. It makes test inspection so handy that you completely forget how was testing without it. Watch it in action [in this video](https://www.youtube.com/watch?v=C62rYlmKLho&feature=youtu.be).

Others Command Log utilities are:

- Command’ rich log: clicking on command shows a more detailed log into the browser DevTools

- Assertion inspection: clicking on an assertion shows both the expected value and the result in the browser DevTools. You do not need to relaunch the test with more verbose logging

- If you spy XHR calls the Command Log shows a resume of the spied/stubbed calls and how many times they have been called

… and more, take a look at [its capabilities in the official Cypress docs](https://docs.cypress.io/guides/core-concepts/test-runner.html#Command-Log).

## Cypress commands

**Commands are asynchronous** by default, take a look at the next snippet

```js
cy.visit(url);
cy.click('[data-test="contact-us-button"]');
cy.contains("Contact Us").should("be.visible");
```

Do you notice any await? No and the reason is straightforward: why should you manage awaits while everything in the UI needs to be awaited? Cypress “waits” for you, which means that if a DOM element is not ready when you try to interact with it, no problem! Cypress retries (by default for 4 seconds) until it can interact with the element (the user way, so only if the element is visible, is not disabled, is not covered, etc.). So you can **avoid facing the front-end intrinsic asynchronicity** at all!

The above feature has one more effect: do you remember the not-so-good test timeout? Well, forget about it! In Cypress, **tests do not have timeouts**! You avoid to guess (and continuously adapt based on the needs) test duration, every command has its own timeout! If something goes wrong, the test fails soon! And if the test goes well, it does not risk to face the test timeout guillotine!

Last but not least: DOM-related commands report **DOM-related errors** the way you need. Take a look at the following example:

![Cypress reports clearly the problem from a user/DOM perspective.](../../assets/images/ui-testing-problems-cypress/dom-error.png)_Cypress reports clearly the problem from a user/DOM perspective._

It is pretty clear the reason why the user could not type into the input element. Cypress is not the only tool that has commands that act as the user would do, but its speaking errors are quite uncommon.

## Test quality

There are a lot of common mistakes that developers do while testing. Some mistakes are negligible but some are not. Cypress enforces you avoiding some mistakes, how?

- With **AAA-quality [documentation](https://docs.cypress.io/guides/overview/why-cypress.html)**: take a look at it, it contains a lot of [best practices and anti-patterns too](https://docs.cypress.io/guides/references/best-practices.html). Everyone agrees about the quality of the documentation

- **Resetting the state**: the tests do not share the state because cookies, localStorage, etc. are all reset before every test. You obviously can create smart commands that allow you to keep the tests independent (the real problem sharing the state is the independence of the tests, take a look at an [example from one of my courses](https://noriste.github.io/reactjsday-2019-testing-course/book/sharing-authentication-state.html)) but you cannot skip the reset. It is a pro, trust me 😉

- Removing the possibility of restoring a test, is an assertion fails, you cannot go ahead. You do need to make your test more stable, even if sometimes it could seem hard. This is a winning choice, otherwise, you would have been allowed to write bad tests

- **With a lot of awaiting helpers**: [retry-ability](https://docs.cypress.io/guides/core-concepts/retry-ability.html#Commands-vs-assertions) and [automatic waitings](https://docs.cypress.io/api/commands/wait.html#Syntax) are life-savers that allow you to care about your app and your test, not about waiting elements and stuff. Cypress allows you to wait for DOM elements, XHR requests, page loads, and it **adapts the timeout** based on the need (an XHR request or a page-load could last longer than an input element appearing) without the need for fixed-time sleep (again, read the [Await, don't sleep](../generic-best-practices/await-dont-sleep.md) section).
  And if you need to write a custom waiting, my [cy.waitUntil plugin](https://github.com/NoriSte/cypress-wait-until) is what you need 😉

## Productivity

Cypress wins on another, really important, topic: productivity. Read how in the dedicated section: [Use your testing tool as your primary development tool](../generic-best-practices/use-your-testing-tool-as-your-primary-development-tool.md).

## Debugging

I explained above why debugging a test could be a nightmare without some dedicated features. There are two kinds of failing test debugging:

- While you are writing the tests

- While the tests fail in a CI/CD pipeline

Cypress has two amazing solutions:

- [Play/pause](https://docs.cypress.io/api/commands/pause.html) functionality\*\*: both programmatically and through the UI, you can pause the test and resume it. And yes, it offers even step-by-step navigation, the same way you are used to placing a breakpoint in your code and process one step at a time. Use play/pause twice and you cannot write a test without it anymore 😊
  Play/pause and time-traveling offer an amazing experience and get you to forget at all about the common time-consuming debugging pains

- **Automatic screenshots and videos**: if a test fails, Cypress saves a screenshot of the last step of the test. Sometimes, the last step allows you to understand what happened (especially if you added a lot of speaking assertions, [here you can read](https://noriste.github.io/reactjsday-2019-testing-course/book/utility-in-case-of-failure.html) what you risk without good step-by-step assertions) but if a screenshot does not help you so much… Cypress records a video of the whole test, including the Test Runner UI. Sometimes, automatic recordings allowed me to discover CI-related issues in the easiest possible way.

## FAQ

I presented Cypress as a perfect tool, now I anticipate some common questions they ask me:

- Is Cypress free?
  Yes, free, open-source, MIT-licensed. You have to pay only if you want to leverage its [Dashboard service](https://www.cypress.io/dashboard/). In one sentence: do you want Cypress to host the videos of your tests? You have to pay, otherwise, everything is free

- Does Cypress support browser apart from Chrome-like ones?
  At the time of writing (Jan 21st, 2020), Firefox and Edge support are in beta.

- I cited TestCafé, what are the main differences?

* **TestCafé has not something like the Test Runner UI**, a big missing IMHO
* TestCafé waits until the DOM element timeouts expire while Cypress waits up to the same timeouts. So, with TestCafé, you have to manually calibrate waitings to avoid long-running tests, with Cypress you can forget about it
* TestCafé has not full XHR requests inspection, it is arguable but I think it is an important feature to have highly reliable tests and useful error reporting
* **TestCafé supports all the existing browsers**! This is a unique feature, Cypress does not support all the browsers and will not support mobile ones. Note that cross-browser needs are pretty overestimated but if you really need it, TestCafé is the perfect tool for you

- Has Cypress flaws? Obviously! It has a [historical issue with window.fetch](https://github.com/cypress-io/cypress/issues/95#issuecomment-343214638) that forces you to use Axios or to [add a workaround](https://dev.to/matsilva/fetch-api-gotcha-in-cypress-io-and-how-to-fix-it-7ah) and you could need some extra-step for managing OAuth since your app runs in an iframe. But it is nonetheless one of the most loved tools for UI Testing

- More in general: remember that we are speaking about UI testing and Cypress is particularly good at doing it. If you just need to automate a browser (for data scraping or whatever) do not use it!

## Conclusions

As a recap, the problems and the solutions listed above are:

- Everything is asynchronous in the front-end testing, Cypress manages it almost transparently

- Step-by-step debugging: Cypress’ time-traveling and play/pause functionalities are your best friends

- Cypress gives clear errors in case of failures

- Debug made handy, identifying flaws is not a nightmare thanks to the side-by-side test/app running

- Auto-screenshot and videos in case of failures

- Cypress tests have not timeouts, Cypress commands have

- Cypress allows you to work completely without a back-end the easiest possible way

- Cypress has a lot of features that improve your productivity

- Cypress is made wit one goal in mind: making UI testing easy

### References

[Mastering UI Testing - conference video](https://www.youtube.com/watch?v=RwWz4hllDtg)

<!-- TODO: in the end, decide if you want to move all the resources to a common chapter too -->



================================================
FILE: sections/tools/ui-testing-problems-cypress.zh.md
================================================
[Binary file]


================================================
FILE: sections/tools/visual-regression-testing.md
================================================
# Visual Regression Testing

<br/><br/>

### One Paragraph Explainer

A visual regression test checks what the user will see after any code changes have been executed by comparing screenshots taken before and after code changes. It is the primary way to validate regressions in CSS, but it is also useful for covering viewport & cross browser/device combinations, as well as localization. Think of Jest Snapshots, but instead of comparing the DOM as text, it is an actual screen shot comparison.

A visual regression process looks like the following:

1. Record the base snapshot (initial execution).
2. Execute the visual test again, compare to the base snapshot (subsequent executions).

   - If the new snapshot matches the base snapshot, accept.
   - Else, set the new base snapshot, or it is a visual regression defect.

The visual regression tools will find any and every pixel diffs. This may get hectic the bigger the snapshot, and as the number of snapshots increase. **The big selling point of visual snapshot services is the AI; the AI is trainable over time and we can train it to ignore petty snapshot diffs we might not care for**. Be mindful that given a snapshot name, we can train the AI to be really bad by accepting any diff. Therefore we need to take care not to thumbs up valid failures. We can reset the training by changing the snapshot name, viewport, or any part of the code.

Without the AI, we would have to manually accept or reject every petty false negative. Without built-in cross browser & cross viewport tests, our test suite would multiply combinatorially, whether local or CI. Check out the talk [Writing Tests for CSS](https://www.youtube.com/watch?v=Dl_XMd_1F6E) by Gil Tayar.

**The second selling point of services is how they can address cross viewport and browser concerns with a single test, so that we do not have to repeat the same test with different variants in CI**.

### Example: Cypress examples with Percy and Applitools

> All the code samples can be found in [this repo](https://github.com/muratkeremozcan/react-hooks-in-action-with-cypress) where we have a ReactJS application with visual tests for Percy as well as their Applitool mirrors.

We will go through two popular services, Percy and Applitools, and showcase how services can save bandwidth with the maintenance of visual snapshots. We will also cover how they can be a force multiplier when we are concerned with cross browser and viewport combinations.

Visual regression testing with services has a common flow:

- Record a default snapshot and compare that default with the new, in subsequent test executions. We have to accept the initial snapshot once.
- From then on, new snapshots matching the default get auto-accepted.

- Non-matching new snapshots prompt a notification on the web interface; we either have to reject or accept this new baseline. If we reject, it is a defect. If we accept we have a new base line and the cycle continues.

Suppose we want to verify the user's avatar.

![user-avatar](../../assets/images/visual-testing/user-avatar.png)

#### Percy flow:

- Here is [a simple test](https://github.com/muratkeremozcan/react-hooks-in-action-with-cypress/blob/main/cypress/e2e/ui-integration/user-context-retainment.spec.js) that verifies the avatar.

```javascript
// cypress/e2e/ui-integration/user-context-retainment.spec.js
describe("User selection retainment between routes", () => {
  before(() => {
    cy.stubNetwork();
    cy.visit("/");
  });

  it("Should keep the user context between routes - full snapshot", () => {
    cy.fixture("users").then((users) => {
      cy.get(".user-picker").select(users[3].name);
      cy.contains("Users").click();

      cy.wait("@userStub");
      cy.url().should("contain", "/users");
      cy.get(".item-header").contains(users[3].name);

      // the visual test - full snapshot
      cy.percySnapshot("User selection retainment between routes"); // <--
    });
  });

  it("Should keep the user context between routes - css-focused snapshot", () => {
    cy.fixture("users").then((users) => {
      cy.get(".user-picker").select(users[3].name);
      cy.contains("Users").click();

      cy.wait("@userStub");
      cy.url().should("contain", "/users");
      cy.get(".item-header").contains(users[3].name);

      // the visual test - using custom command for css selector focus // <--
      cy.get('[data-cy="user-details"]').percySnapshotElement(
        "user details with custom selector"
      );
    });
  });
});
```

In the first test we see the first one-liner taking a full screen shot. In the subsequent test we see a snapshot of the `user-details` selector. Selector focused snapshots are not natively supported in Percy, therefore [a custom command](https://github.com/muratkeremozcan/react-hooks-in-action-with-cypress/blob/main/cypress/support/commands.js#L112) `percySnapshotElement` is used.

> To actually run a visual diff, we need a Percy account and token. Visual testing only runs when hooked up to this account and executed via `cy run`. The focus is the CI. Take a look at the [Sign up section](https://dev.to/muratkeremozcan/painlessly-setup-cypress-percy-with-github-actions-in-minutes-1aki#sign-up) for elaborate details.

Once we execute the test, the initial snapshot looks like so in the Percy interface. **We introduced one-liner tests, and the test ran against 4 browsers and 2 viewports; 8 combinations we did not have to worry about in CI**. Mind that every resolution x browser consumes quota; if we were testing 2 viewports and 4 browsers, the one-liner would consume 8 credits.

![Percy initial](../../assets/images/visual-testing/percy-initial.png)

In subsequent tests if there is a visual diff (for instance if we turn off the backend and cannot render the image) we will see a visual diff indicator in the Percy Interface. Here we can also verify the diff between browsers and viewports.

![Visual diff](../../assets/images/visual-testing/percy-visual-diff.png)

At this point we can train the AI to be not very good and auto-accept the broken avatar image in the future. However, you can imagine pesky pixel diffs that we do not care about. That is where **visual regression services save bandwidth; the maintenance of visual snapshots**.

> Percy has the perk of keeping things simple. However the CI setup is the extra we have to work with. Here is a GitHub Action CI [example](https://github.com/muratkeremozcan/react-hooks-in-action-with-cypress/blob/main/.github/workflows/main.yml#L113). For all details of setting up Percy, take a look at the [blog post guide](https://dev.to/muratkeremozcan/painlessly-setup-cypress-percy-with-github-actions-in-minutes-1aki#sign-up).

### Applitools flow

Here is [the same test written with Applitools](https://github.com/muratkeremozcan/react-hooks-in-action-with-cypress/blob/main/cypress/e2e/ui-integration/user-context-retainment-applitools.spec.js).

```javascript
// Applitools version of the visual test
// cypress/e2e/ui-integration/user-context-retainment-applitools.spec.js
describe("User selection retainment between routes", () => {
  before(() => {
    // Each test should open its own Eyes for its own snapshots
    cy.eyesOpen({
      appName: "hooks-in-action",
      testName: Cypress.currentTest.title,
    });

    cy.stubNetwork();
    cy.visit("/");
  });

  it("Should keep the user context between routes - full snapshot", () => {
    cy.fixture("users").then((users) => {
      cy.get(".user-picker").select(users[3].name);
      cy.contains("Users").click();

      cy.wait("@userStub");
      cy.url().should("contain", "/users");
      cy.get(".item-header").contains(users[3].name);

      // full page test // <--
      cy.eyesCheckWindow({
        tag: "User selection retainment between routes",
        target: "window",
        matchLevel: "Layout",
      });
    });
  });

  it("Should keep the user context between routes - css focused snapshot", () => {
    cy.fixture("users").then((users) => {
      cy.get(".user-picker").select(users[3].name);
      cy.contains("Users").click();

      cy.wait("@userStub");
      cy.url().should("contain", "/users");
      cy.get(".item-header").contains(users[3].name);

      // partial page test // <--
      cy.eyesCheckWindow({
        tag: "user details with custom selector",
        target: "region",
        selector: '[data-cy="user-details"]',

        // if fully is true (default) then the snapshot is of the entire page,
        // if fully is false then snapshot is of the viewport.
        fully: false,
      });
    });
  });

  afterEach(() => {
    cy.eyesClose();
  });
});
```

We realize the additional `cy.eyesOpen` and `cy.eyesClose` commands that need to execute in the beginning and end of the test. We also see ` cy.eyesCheckWindow` is very customizable, not needing a custom command as in Percy.

> For details about setting up Applitools, and comparisons to Percy, check out [this blog post](https://dev.to/muratkeremozcan/setup-cypress-applitools-with-github-actions-a-comparison-of-applitools-vs-percy-in-a-mid-size-app-43ij).

Similar to Percy, with Applitools our test executes cross browser & viewport, and records the base snapshot.

![applitools ui](../../assets/images/visual-testing/applitools-ui.png)

When / if there is a visual diff, there is a clear indicator in the web interface.

![applitools-failure](../../assets/images/visual-testing/applitools-failure.png)

Here is a side by side comparison of the Percy vs Applitools code.

![percy-vs-applitools](../../assets/images/visual-testing/percy-vs-applitools.png)

Overall Applitools is strong on configurability while Percy is strong on simplicity. The UX is leaner and easier to use on Percy side, while on Applitools the UX is busier in comparison, but it has improved much over the years. Percy certainly has less code, not having to "open" and "close" eyes and being able to fire off the main command is a big win. For local developer experience, Applitools is the winner; being able to execute the tests with Cypress open mode vs elaborate CLI commands is huge win. Failing an actual visual diff in the test runner, vs the visual failures being only on the web UI in Percy's case, is also a win for Applitools. For CI, not having to configure any yml makes Applitools the winner there as well. Another win is for being able to take snapshots of sub-sections of the UI via selectors; this feature is built-in to Applitools while with Percy it has to be custom command that is not sure to work everywhere in the real world.

|                           | Percy                                       | Applitools                        |
| ------------------------- | ------------------------------------------- | --------------------------------- |
| **Code**                  | Less code                                   | More configurable                 |
| **UX**                    | Lean                                        | Less lean, but got better         |
| **Local**                 | Only headless                               | Also works with Cypress Open Mode |
| **CI**                    | There is yml required                       | No yml                            |
| **Config**                | Mostly On web app, viewport config is local | Local file                        |
| **Sub-section-snapshots** | Custom Command, might not work everywhere   | Built-in                          |
| **Visual diff AI**        | need more time for an opinion               | need more time for an opinion     |

Visual testing does not come for free; performing it without a service consumes continuous engineer bandwidth. **With CI, services save us costs on viewport & browser combinations**, all services we testing fulfill this need equally. **The greatest distinction between visual services is how good the AI is in helping us not worry about visual test maintenance**. We believe that the most significant decision maker would be a long term trial (4-8 weeks) of both tools in an internal app, side by side. This would help evaluate which tool has the better AI allowing for less maintenance with visual testing, which is the biggest deterrent for technically savvy teams incorporating the test strategy into their portfolio.



================================================
FILE: sections/tools/visual-regression-testing.zh.md
================================================
[Binary file]

